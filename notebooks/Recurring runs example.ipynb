{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Periodic download of IEX stock-ticker data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read IEX API credentials from `~/.config/iex.ini`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "config_path = Path.home() / '.config' / 'iex.ini'\n",
    "\n",
    "from configparser import ConfigParser\n",
    "config = ConfigParser()\n",
    "config.read(str(config_path))\n",
    "iex_config = config['iex']\n",
    "\n",
    "api = 'https://cloud.iexapis.com'\n",
    "public_key = iex_config['public_key']\n",
    "secret_key = iex_config['secret_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers = sorted(\"MMM ABT ABBV ABMD ACN ATVI ADBE AMD AAP AES AMG AFL A APD AKAM ALK ALB ARE ALXN ALGN ALLE AGN ADS LNT ALL GOOGL GOOG MO AMZN AMCR AEE AAL AEP AXP AIG AMT AWK AMP ABC AME AMGN APH ADI ANSS ANTM AON AOS APA AIV AAPL AMAT APTV ADM ARNC ANET AJG AIZ ATO T ADSK ADP AZO AVB AVY BKR BLL BAC BK BAX BBT BDX BRK.B BBY BIIB BLK HRB BA BKNG BWA BXP BSX BMY AVGO BR BF.B CHRW COG CDNS CPB COF CPRI CAH KMX CCL CAT CBOE CBRE CBS CDW CE CELG CNC CNP CTL CERN CF SCHW CHTR CVX CMG CB CHD CI XEC CINF CTAS CSCO C CFG CTXS CLX CME CMS KO CTSH CL CMCSA CMA CAG CXO COP ED STZ COO CPRT GLW CTVA COST COTY CCI CSX CMI CVS DHI DHR DRI DVA DE DAL XRAY DVN FANG DLR DFS DISCA DISCK DISH DG DLTR D DOV DOW DTE DUK DRE DD DXC ETFC EMN ETN EBAY ECL EIX EW EA EMR ETR EOG EFX EQIX EQR ESS EL EVRG ES RE EXC EXPE EXPD EXR XOM FFIV FB FAST FRT FDX FIS FITB FE FRC FISV FLT FLIR FLS FMC F FTNT FTV FBHS FOXA FOX BEN FCX GPS GRMN IT GD GE GIS GM GPC GILD GL GPN GS GWW HAL HBI HOG HIG HAS HCA HCP HP HSIC HSY HES HPE HLT HFC HOLX HD HON HRL HST HPQ HUM HBAN HII IEX IDXX INFO ITW ILMN IR INTC ICE IBM INCY IP IPG IFF INTU ISRG IVZ IPGP IQV IRM JKHY JEC JBHT SJM JNJ JCI JPM JNPR KSU K KEY KEYS KMB KIM KMI KLAC KSS KHC KR LB LHX LH LRCX LW LVS LEG LDOS LEN LLY LNC LIN LKQ LMT L LOW LYB MTB MAC M MRO MPC MKTX MAR MMC MLM MAS MA MKC MXIM MCD MCK MDT MRK MET MTD MGM MCHP MU MSFT MAA MHK TAP MDLZ MNST MCO MS MOS MSI MSCI MYL NDAQ NOV NTAP NFLX NWL NEM NWSA NWS NEE NLSN NKE NI NBL JWN NSC NTRS NOC NCLH NRG NUE NVDA NVR ORLY OXY OMC OKE ORCL PCAR PKG PH PAYX PYPL PNR PBCT PEP PKI PRGO PFE PM PSX PNW PXD PNC PPG PPL PFG PG PGR PLD PRU PEG PSA PHM PVH QRVO PWR QCOM DGX RL RJF RTN O REG REGN RF RSG RMD RHI ROK ROL ROP ROST RCL CRM SBAC SLB STX SEE SRE SHW SPG SWKS SLG SNA SO LUV SPGI SWK SBUX STT SYK STI SIVB SYMC SYF SNPS SYY TMUS TROW TTWO TPR TGT TEL FTI TFX TXN TXT TMO TIF TWTR TJX TSCO TDG TRV TRIP TSN UDR ULTA USB UAA UA UNP UAL UNH UPS URI UTX UHS UNM VFC VLO VAR VTR VRSN VRSK VZ VRTX VIAB V VNO VMC WAB WMT WBA DIS WM WAT WEC WCG WFC WELL WDC WU WRK WY WHR WMB WLTW WYNN XEL XRX XLNX XYL YUM ZBH ZION ZTS\".split(\" \"))\n",
    "num_tickers = len(tickers)\n",
    "num_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl = tickers.index('AAPL'); aapl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2019, 10, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "from datetime import timedelta as Δ\n",
    "\n",
    "time = datetime.now\n",
    "now = time()\n",
    "today = now.date()\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.cwd() / 'data'\n",
    "data_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import executable as python\n",
    "!{python} -m pip install -Uq requests\n",
    "from requests import get as GET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def fetch(date_str, ticker):\n",
    "    out_path = data_dir / ('%s-%s' % (date_str, ticker))\n",
    "    if out_path.exists():\n",
    "        return True\n",
    "\n",
    "    print('Fetching data for %s from %s' % (ticker, date_str))\n",
    "\n",
    "    url = f'https://cloud.iexapis.com/stable/stock/{ticker}/chart/date/{date_str}?token={secret_key}'\n",
    "    resp = GET(url)\n",
    "    resp.raise_for_status()\n",
    "    with out_path.open('wb') as f:\n",
    "        f.write(resp.content)\n",
    "\n",
    "    data = json.loads(resp.content)\n",
    "    if data:\n",
    "        return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.22 s, sys: 387 ms, total: 1.61 s\n",
      "Wall time: 1.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "end_date = today\n",
    "start_date = datetime(2019, 8, 1).date()\n",
    "N = 32\n",
    "\n",
    "def get_dates(start_date, end_date, step=1):\n",
    "    date = start_date\n",
    "    while date != end_date:\n",
    "        if date.weekday() <= 4:\n",
    "            yield date\n",
    "        date += Δ(days=step)\n",
    "\n",
    "dates = list(get_dates(start_date, end_date))\n",
    "\n",
    "for date in dates:\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers = N) as p:\n",
    "        results = p.map(lambda ticker: fetch(date_str, ticker), tickers)\n",
    "    \n",
    "    found_data = True in results\n",
    "    if not found_data:\n",
    "        print('No data found for %s; breaking' % date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{python} -m pip install -Uq pandas\n",
    "from pandas import DataFrame as DF, read_csv, read_json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes = 390  # [9:30am,4:00pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [ 'open', 'close', 'high', 'low', 'average', 'volume', 'notional', 'numberOfTrades' ]\n",
    "cols = [ 'datetime', 'ticker' ] + features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_arr(date, ticker):\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "    out_path = data_dir / ('%s-%s' % (date_str, ticker))\n",
    "    if not out_path.exists():\n",
    "        arr = zeros((minutes, len(features)))\n",
    "        arr[:] = nan\n",
    "        return arr\n",
    "    df = read_json(out_path)\n",
    "    if df.empty:\n",
    "        arr = zeros((minutes, len(features)))\n",
    "        arr[:] = nan\n",
    "        return arr\n",
    "    arr = df[features].values\n",
    "    assert arr.shape == (minutes, len(features))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{python} -m pip install -Uq numpy\n",
    "import numpy as np\n",
    "from numpy import array, nan, zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_date_arr(date):\n",
    "    arr = array([ \n",
    "        load_data_arr(start_date, ticker) \n",
    "        for ticker in tickers \n",
    "    ]) \\\n",
    "    .reshape((\n",
    "        minutes, \n",
    "        len(tickers), \n",
    "        len(features),\n",
    "    ))\n",
    "    assert arr.shape == (minutes, num_tickers, len(features))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{python} -m pip install -Uq joblib\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import count_nonzero as cnz, isnan as na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'AAPL'\n",
    "num_tickers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 390, 8)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl = array([ load_data_arr(date, ticker) for date in dates ]); aapl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24960,)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = aapl.shape\n",
    "aapl = aapl.reshape((shape[0] * shape[1], shape[2]))\n",
    "aapl = aapl[:, 4]\n",
    "shape = aapl.shape; shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24959,), (24959,))"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.roll(avgs, -1)\n",
    "y = y[:-1]\n",
    "x = aapl[:-1]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24939, 20), (24939,))"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window = 20\n",
    "n = x.shape[0]\n",
    "x = np.array([ x[i:(i+window)] for i in range(n-window) ])\n",
    "y = y[window:]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18463, 20), (18463,))"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = np.logical_and([ (cnz(na(row)) == 0) for row in x ], ~na(y))\n",
    "y = y[idxs]\n",
    "x = x[idxs]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18463, 20), (18463,))"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181.3834607423043"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = aapl[~na(aapl)]\n",
    "u = np.mean(vals)\n",
    "mean((vals-u)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213.7095086060606, 10.457293365325054, 109.35498452847138)"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(ty), std(ty), mean((ty-mean(ty))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx, ty = x.copy(), y.copy()\n",
    "tx = tx.reshape(tx.shape + (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import shuffle, permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = permutation(len(tx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10237,  6810, 14076, ...,  6777,  9412,  7458])"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = tx[p]\n",
    "ty = ty[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18463, 20, 1), (18463,))"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx.shape, ty.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216.49239711856143, 12.845915614509657)"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(tx[:, -1, 0]), std(tx[:, -1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216.49476580187402, 12.847432764781418)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(ty), std(ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.0011608429716223373, 0.9990599002951742, -4.658571096991829e-16, 1.0)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = mean(ty)\n",
    "s = std(ty)\n",
    "tx = (tx - u) / s\n",
    "ty = (ty - u) / s\n",
    "mean(tx), std(tx), mean(ty), std(ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_18 (SimpleRNN)    (None, 8)                 80        \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(window, 1)),\n",
    "    SimpleRNN(8, input_shape=(window, 1)),\n",
    "    Dense(1),\n",
    "])\n",
    "model.build()\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16616 samples, validate on 1847 samples\n",
      "Epoch 1/100\n",
      "16616/16616 [==============================] - 3s 172us/sample - loss: 0.1358 - val_loss: 0.0071\n",
      "Epoch 2/100\n",
      "16616/16616 [==============================] - 2s 105us/sample - loss: 0.0055 - val_loss: 0.0033\n",
      "Epoch 3/100\n",
      "16616/16616 [==============================] - 2s 103us/sample - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 4/100\n",
      "16616/16616 [==============================] - 2s 105us/sample - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 5/100\n",
      "16616/16616 [==============================] - 2s 106us/sample - loss: 0.0012 - val_loss: 8.1338e-04\n",
      "Epoch 6/100\n",
      "16616/16616 [==============================] - 2s 105us/sample - loss: 9.8808e-04 - val_loss: 7.0622e-04\n",
      "Epoch 7/100\n",
      "16616/16616 [==============================] - 2s 108us/sample - loss: 8.6920e-04 - val_loss: 6.3083e-04\n",
      "Epoch 8/100\n",
      "16616/16616 [==============================] - 2s 123us/sample - loss: 7.9034e-04 - val_loss: 5.6041e-04\n",
      "Epoch 9/100\n",
      "16616/16616 [==============================] - 2s 130us/sample - loss: 7.2115e-04 - val_loss: 5.2011e-04\n",
      "Epoch 10/100\n",
      "16616/16616 [==============================] - 2s 115us/sample - loss: 6.6477e-04 - val_loss: 4.8926e-04\n",
      "Epoch 11/100\n",
      "16616/16616 [==============================] - 2s 117us/sample - loss: 6.3110e-04 - val_loss: 4.4774e-04\n",
      "Epoch 12/100\n",
      "16616/16616 [==============================] - 2s 107us/sample - loss: 5.8791e-04 - val_loss: 4.4129e-04\n",
      "Epoch 13/100\n",
      "16616/16616 [==============================] - 2s 119us/sample - loss: 5.6169e-04 - val_loss: 4.0900e-04\n",
      "Epoch 14/100\n",
      "16616/16616 [==============================] - 2s 109us/sample - loss: 5.4773e-04 - val_loss: 4.4913e-04\n",
      "Epoch 15/100\n",
      "16616/16616 [==============================] - 2s 104us/sample - loss: 5.2421e-04 - val_loss: 3.8589e-04\n",
      "Epoch 16/100\n",
      "16616/16616 [==============================] - 2s 115us/sample - loss: 5.1530e-04 - val_loss: 3.6299e-04\n",
      "Epoch 17/100\n",
      "16616/16616 [==============================] - 2s 122us/sample - loss: 5.0288e-04 - val_loss: 4.0027e-04\n",
      "Epoch 18/100\n",
      "16616/16616 [==============================] - 2s 114us/sample - loss: 4.9804e-04 - val_loss: 4.2106e-04\n",
      "Epoch 19/100\n",
      "16616/16616 [==============================] - 2s 105us/sample - loss: 4.9030e-04 - val_loss: 3.4516e-04\n",
      "Epoch 20/100\n",
      "16616/16616 [==============================] - 2s 102us/sample - loss: 4.7493e-04 - val_loss: 3.3560e-04\n",
      "Epoch 21/100\n",
      "16616/16616 [==============================] - 2s 110us/sample - loss: 4.7480e-04 - val_loss: 3.5623e-04\n",
      "Epoch 22/100\n",
      "16616/16616 [==============================] - 2s 110us/sample - loss: 4.6641e-04 - val_loss: 3.3049e-04\n",
      "Epoch 23/100\n",
      "16616/16616 [==============================] - 2s 109us/sample - loss: 4.5776e-04 - val_loss: 3.3824e-04\n",
      "Epoch 24/100\n",
      "16616/16616 [==============================] - 2s 105us/sample - loss: 4.6092e-04 - val_loss: 3.3542e-04\n",
      "Epoch 25/100\n",
      "16616/16616 [==============================] - 2s 109us/sample - loss: 4.6639e-04 - val_loss: 3.5018e-04\n",
      "Epoch 26/100\n",
      "16616/16616 [==============================] - 2s 111us/sample - loss: 4.4709e-04 - val_loss: 3.2514e-04\n",
      "Epoch 27/100\n",
      "16616/16616 [==============================] - 2s 107us/sample - loss: 4.4711e-04 - val_loss: 3.3583e-04\n",
      "Epoch 28/100\n",
      "16616/16616 [==============================] - 2s 105us/sample - loss: 4.4760e-04 - val_loss: 3.5696e-04\n",
      "Epoch 29/100\n",
      "16616/16616 [==============================] - 2s 107us/sample - loss: 4.5010e-04 - val_loss: 3.5086e-04\n",
      "Epoch 30/100\n",
      "16616/16616 [==============================] - 2s 109us/sample - loss: 4.4181e-04 - val_loss: 3.3572e-04\n",
      "Epoch 31/100\n",
      "16616/16616 [==============================] - 2s 107us/sample - loss: 4.3893e-04 - val_loss: 3.3126e-04\n",
      "Epoch 32/100\n",
      "16616/16616 [==============================] - 2s 109us/sample - loss: 4.3707e-04 - val_loss: 3.1959e-04\n",
      "Epoch 33/100\n",
      "16616/16616 [==============================] - 2s 107us/sample - loss: 4.4119e-04 - val_loss: 4.1689e-04\n",
      "Epoch 34/100\n",
      "16616/16616 [==============================] - 2s 106us/sample - loss: 4.3714e-04 - val_loss: 3.7162e-04\n",
      "Epoch 35/100\n",
      "16616/16616 [==============================] - 2s 107us/sample - loss: 4.3880e-04 - val_loss: 3.3397e-04\n",
      "Epoch 36/100\n",
      "16616/16616 [==============================] - 2s 108us/sample - loss: 4.3914e-04 - val_loss: 3.5572e-04\n",
      "Epoch 37/100\n",
      "16616/16616 [==============================] - 2s 110us/sample - loss: 4.2976e-04 - val_loss: 3.3954e-04\n",
      "Epoch 38/100\n",
      "16616/16616 [==============================] - 2s 103us/sample - loss: 4.3193e-04 - val_loss: 3.4169e-04\n",
      "Epoch 39/100\n",
      "16616/16616 [==============================] - 2s 104us/sample - loss: 4.3533e-04 - val_loss: 3.2622e-04\n",
      "Epoch 40/100\n",
      "16616/16616 [==============================] - 2s 110us/sample - loss: 4.3028e-04 - val_loss: 3.3371e-04\n",
      "Epoch 41/100\n",
      "16616/16616 [==============================] - 2s 115us/sample - loss: 4.3055e-04 - val_loss: 3.5733e-04\n",
      "Epoch 42/100\n",
      "16616/16616 [==============================] - 2s 122us/sample - loss: 4.3173e-04 - val_loss: 3.2325e-04\n",
      "Epoch 43/100\n",
      "16616/16616 [==============================] - 2s 111us/sample - loss: 4.3758e-04 - val_loss: 3.7894e-04\n",
      "Epoch 44/100\n",
      "16616/16616 [==============================] - 2s 110us/sample - loss: 4.3216e-04 - val_loss: 3.2432e-04\n",
      "Epoch 45/100\n",
      "16616/16616 [==============================] - 2s 109us/sample - loss: 4.3073e-04 - val_loss: 3.1934e-04\n",
      "Epoch 46/100\n",
      "16616/16616 [==============================] - 2s 103us/sample - loss: 4.3533e-04 - val_loss: 3.4324e-04\n",
      "Epoch 47/100\n",
      "16616/16616 [==============================] - 2s 106us/sample - loss: 4.2535e-04 - val_loss: 3.3507e-04\n",
      "Epoch 48/100\n",
      "16616/16616 [==============================] - 2s 110us/sample - loss: 4.3791e-04 - val_loss: 3.5065e-04\n",
      "Epoch 49/100\n",
      "16616/16616 [==============================] - 2s 113us/sample - loss: 4.2951e-04 - val_loss: 3.3746e-04\n",
      "Epoch 50/100\n",
      "16616/16616 [==============================] - 2s 108us/sample - loss: 4.3026e-04 - val_loss: 3.1806e-04\n",
      "Epoch 51/100\n",
      "16616/16616 [==============================] - 2s 106us/sample - loss: 4.2659e-04 - val_loss: 3.2337e-04\n",
      "Epoch 52/100\n",
      "16616/16616 [==============================] - 2s 106us/sample - loss: 4.3287e-04 - val_loss: 3.2575e-04\n",
      "Epoch 53/100\n",
      "16616/16616 [==============================] - 2s 104us/sample - loss: 4.3028e-04 - val_loss: 3.2635e-04\n",
      "Epoch 54/100\n",
      "16616/16616 [==============================] - 2s 110us/sample - loss: 4.3129e-04 - val_loss: 3.2879e-04\n",
      "Epoch 55/100\n",
      "16616/16616 [==============================] - 2s 115us/sample - loss: 4.2936e-04 - val_loss: 3.7744e-04\n",
      "Epoch 56/100\n",
      "16616/16616 [==============================] - 2s 107us/sample - loss: 4.2859e-04 - val_loss: 3.2721e-04\n",
      "Epoch 57/100\n",
      "16616/16616 [==============================] - 2s 110us/sample - loss: 4.2349e-04 - val_loss: 3.3179e-04\n",
      "Epoch 58/100\n",
      "16616/16616 [==============================] - 2s 106us/sample - loss: 4.2930e-04 - val_loss: 3.1551e-04\n",
      "Epoch 59/100\n",
      "16616/16616 [==============================] - 2s 106us/sample - loss: 4.3284e-04 - val_loss: 3.1979e-04\n",
      "Epoch 60/100\n",
      "16616/16616 [==============================] - 2s 110us/sample - loss: 4.2222e-04 - val_loss: 3.1941e-04\n",
      "Epoch 61/100\n",
      "16616/16616 [==============================] - 2s 113us/sample - loss: 4.2325e-04 - val_loss: 3.3035e-04\n",
      "Epoch 62/100\n",
      "16616/16616 [==============================] - 2s 110us/sample - loss: 4.2424e-04 - val_loss: 3.2824e-04\n",
      "Epoch 63/100\n",
      "16616/16616 [==============================] - 2s 106us/sample - loss: 4.2224e-04 - val_loss: 3.2771e-04\n",
      "Epoch 64/100\n",
      "16616/16616 [==============================] - 2s 106us/sample - loss: 4.2433e-04 - val_loss: 3.7223e-04\n",
      "Epoch 65/100\n",
      "16616/16616 [==============================] - 2s 112us/sample - loss: 4.3146e-04 - val_loss: 3.2256e-04\n",
      "Epoch 66/100\n",
      "16616/16616 [==============================] - 2s 106us/sample - loss: 4.3220e-04 - val_loss: 3.2516e-04\n",
      "Epoch 67/100\n",
      "16616/16616 [==============================] - 2s 112us/sample - loss: 4.2687e-04 - val_loss: 3.9110e-04\n",
      "Epoch 68/100\n",
      "16616/16616 [==============================] - 2s 107us/sample - loss: 4.2331e-04 - val_loss: 3.2443e-04\n",
      "Epoch 69/100\n",
      "16616/16616 [==============================] - 2s 106us/sample - loss: 4.2665e-04 - val_loss: 3.2358e-04\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.2121e-04 - val_loss: 3.7281e-04\n",
      "Epoch 71/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.2115e-04 - val_loss: 3.2273e-04\n",
      "Epoch 72/100\n",
      "16616/16616 [==============================] - 2s 106us/sample - loss: 4.3038e-04 - val_loss: 3.1394e-04\n",
      "Epoch 73/100\n",
      "16616/16616 [==============================] - 2s 111us/sample - loss: 4.2707e-04 - val_loss: 3.3663e-04\n",
      "Epoch 74/100\n",
      "16616/16616 [==============================] - 2s 102us/sample - loss: 4.2659e-04 - val_loss: 3.3296e-04\n",
      "Epoch 75/100\n",
      "16616/16616 [==============================] - 2s 97us/sample - loss: 4.1816e-04 - val_loss: 3.1465e-04\n",
      "Epoch 76/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.2188e-04 - val_loss: 3.2588e-04\n",
      "Epoch 77/100\n",
      "16616/16616 [==============================] - 2s 99us/sample - loss: 4.2407e-04 - val_loss: 4.6162e-04\n",
      "Epoch 78/100\n",
      "16616/16616 [==============================] - 2s 98us/sample - loss: 4.2735e-04 - val_loss: 3.1358e-04\n",
      "Epoch 79/100\n",
      "16616/16616 [==============================] - 2s 105us/sample - loss: 4.1974e-04 - val_loss: 3.1457e-04\n",
      "Epoch 80/100\n",
      "16616/16616 [==============================] - 2s 105us/sample - loss: 4.2582e-04 - val_loss: 3.1910e-04\n",
      "Epoch 81/100\n",
      "16616/16616 [==============================] - 2s 98us/sample - loss: 4.2754e-04 - val_loss: 3.4229e-04\n",
      "Epoch 82/100\n",
      "16616/16616 [==============================] - 2s 97us/sample - loss: 4.2344e-04 - val_loss: 3.5989e-04\n",
      "Epoch 83/100\n",
      "16616/16616 [==============================] - 2s 96us/sample - loss: 4.2377e-04 - val_loss: 3.3437e-04\n",
      "Epoch 84/100\n",
      "16616/16616 [==============================] - 2s 104us/sample - loss: 4.2821e-04 - val_loss: 3.2389e-04\n",
      "Epoch 85/100\n",
      "16616/16616 [==============================] - 2s 108us/sample - loss: 4.2442e-04 - val_loss: 3.5434e-04\n",
      "Epoch 86/100\n",
      "16616/16616 [==============================] - 2s 110us/sample - loss: 4.2169e-04 - val_loss: 3.2923e-04\n",
      "Epoch 87/100\n",
      "16616/16616 [==============================] - 2s 103us/sample - loss: 4.2214e-04 - val_loss: 3.2741e-04\n",
      "Epoch 88/100\n",
      "16616/16616 [==============================] - 2s 106us/sample - loss: 4.2290e-04 - val_loss: 3.1410e-04\n",
      "Epoch 89/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.2204e-04 - val_loss: 3.1415e-04\n",
      "Epoch 90/100\n",
      "16616/16616 [==============================] - 2s 98us/sample - loss: 4.2080e-04 - val_loss: 3.3951e-04\n",
      "Epoch 91/100\n",
      "16616/16616 [==============================] - 2s 98us/sample - loss: 4.2400e-04 - val_loss: 3.1429e-04\n",
      "Epoch 92/100\n",
      "16616/16616 [==============================] - 2s 111us/sample - loss: 4.2298e-04 - val_loss: 3.5096e-04\n",
      "Epoch 93/100\n",
      "16616/16616 [==============================] - 2s 103us/sample - loss: 4.2545e-04 - val_loss: 3.2565e-04\n",
      "Epoch 94/100\n",
      "16616/16616 [==============================] - 2s 101us/sample - loss: 4.2445e-04 - val_loss: 3.1562e-04\n",
      "Epoch 95/100\n",
      "16616/16616 [==============================] - 2s 99us/sample - loss: 4.1757e-04 - val_loss: 3.2313e-04\n",
      "Epoch 96/100\n",
      "16616/16616 [==============================] - 2s 101us/sample - loss: 4.2094e-04 - val_loss: 3.1599e-04\n",
      "Epoch 97/100\n",
      "16616/16616 [==============================] - 2s 104us/sample - loss: 4.2189e-04 - val_loss: 3.3701e-04\n",
      "Epoch 98/100\n",
      "16616/16616 [==============================] - 2s 98us/sample - loss: 4.2638e-04 - val_loss: 3.1579e-04\n",
      "Epoch 99/100\n",
      "16616/16616 [==============================] - 2s 126us/sample - loss: 4.1832e-04 - val_loss: 3.1029e-04\n",
      "Epoch 100/100\n",
      "16616/16616 [==============================] - 2s 109us/sample - loss: 4.2467e-04 - val_loss: 3.1147e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14bbb3210>"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_split=0.1,\n",
    "          batch_size=50,\n",
    "          epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, array([[3.1837869],\n",
       "        [3.1837869],\n",
       "        [3.1837869],\n",
       "        [3.1837869],\n",
       "        [3.1837869],\n",
       "        [3.1837869],\n",
       "        [3.1837869],\n",
       "        [3.1837869],\n",
       "        [3.1837869],\n",
       "        [3.1837869]], dtype=float32))"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px = model.predict(vx)\n",
    "px.max() - px.min(), px[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16616 samples, validate on 1847 samples\n",
      "Epoch 1/100\n",
      "16616/16616 [==============================] - 2s 102us/sample - loss: 4.2894e-04 - val_loss: 3.3389e-04\n",
      "Epoch 2/100\n",
      "16616/16616 [==============================] - 2s 105us/sample - loss: 4.2687e-04 - val_loss: 3.5705e-04\n",
      "Epoch 3/100\n",
      "16616/16616 [==============================] - 2s 104us/sample - loss: 4.2241e-04 - val_loss: 3.0987e-04\n",
      "Epoch 4/100\n",
      "16616/16616 [==============================] - 2s 102us/sample - loss: 4.2127e-04 - val_loss: 4.5202e-04\n",
      "Epoch 5/100\n",
      "16616/16616 [==============================] - 2s 115us/sample - loss: 4.2379e-04 - val_loss: 3.1529e-04\n",
      "Epoch 6/100\n",
      "16616/16616 [==============================] - 2s 114us/sample - loss: 4.1759e-04 - val_loss: 3.1581e-04\n",
      "Epoch 7/100\n",
      "16616/16616 [==============================] - 2s 111us/sample - loss: 4.1895e-04 - val_loss: 3.5720e-04\n",
      "Epoch 8/100\n",
      "16616/16616 [==============================] - 2s 111us/sample - loss: 4.1947e-04 - val_loss: 3.4010e-04\n",
      "Epoch 9/100\n",
      "16616/16616 [==============================] - 2s 102us/sample - loss: 4.2528e-04 - val_loss: 3.1221e-04\n",
      "Epoch 10/100\n",
      "16616/16616 [==============================] - 2s 96us/sample - loss: 4.2104e-04 - val_loss: 3.4561e-04\n",
      "Epoch 11/100\n",
      "16616/16616 [==============================] - 2s 97us/sample - loss: 4.2750e-04 - val_loss: 3.0993e-04\n",
      "Epoch 12/100\n",
      "16616/16616 [==============================] - 2s 102us/sample - loss: 4.2313e-04 - val_loss: 3.3095e-04\n",
      "Epoch 13/100\n",
      "16616/16616 [==============================] - 2s 103us/sample - loss: 4.2196e-04 - val_loss: 3.2475e-04\n",
      "Epoch 14/100\n",
      "16616/16616 [==============================] - 2s 103us/sample - loss: 4.2284e-04 - val_loss: 3.8004e-04\n",
      "Epoch 15/100\n",
      "16616/16616 [==============================] - 2s 112us/sample - loss: 4.2542e-04 - val_loss: 3.4441e-04\n",
      "Epoch 16/100\n",
      "16616/16616 [==============================] - 2s 104us/sample - loss: 4.2323e-04 - val_loss: 3.2379e-04\n",
      "Epoch 17/100\n",
      "16616/16616 [==============================] - 2s 104us/sample - loss: 4.1670e-04 - val_loss: 3.6675e-04\n",
      "Epoch 18/100\n",
      "16616/16616 [==============================] - 2s 103us/sample - loss: 4.1790e-04 - val_loss: 3.1048e-04\n",
      "Epoch 19/100\n",
      "16616/16616 [==============================] - 2s 104us/sample - loss: 4.1749e-04 - val_loss: 3.1673e-04\n",
      "Epoch 20/100\n",
      "16616/16616 [==============================] - 2s 99us/sample - loss: 4.2291e-04 - val_loss: 3.0824e-04\n",
      "Epoch 21/100\n",
      "16616/16616 [==============================] - 2s 114us/sample - loss: 4.1681e-04 - val_loss: 3.6390e-04\n",
      "Epoch 22/100\n",
      "16616/16616 [==============================] - 2s 101us/sample - loss: 4.1974e-04 - val_loss: 3.1432e-04\n",
      "Epoch 23/100\n",
      "16616/16616 [==============================] - 2s 101us/sample - loss: 4.2199e-04 - val_loss: 3.1521e-04\n",
      "Epoch 24/100\n",
      "16616/16616 [==============================] - 2s 103us/sample - loss: 4.2254e-04 - val_loss: 3.2199e-04\n",
      "Epoch 25/100\n",
      "16616/16616 [==============================] - 2s 102us/sample - loss: 4.1809e-04 - val_loss: 3.2624e-04\n",
      "Epoch 26/100\n",
      "16616/16616 [==============================] - 2s 107us/sample - loss: 4.1751e-04 - val_loss: 3.0943e-04\n",
      "Epoch 27/100\n",
      "16616/16616 [==============================] - 2s 101us/sample - loss: 4.2326e-04 - val_loss: 3.1783e-04\n",
      "Epoch 28/100\n",
      "16616/16616 [==============================] - 2s 108us/sample - loss: 4.1591e-04 - val_loss: 3.1101e-04\n",
      "Epoch 29/100\n",
      "16616/16616 [==============================] - 2s 103us/sample - loss: 4.1939e-04 - val_loss: 3.2831e-04\n",
      "Epoch 30/100\n",
      "16616/16616 [==============================] - 2s 102us/sample - loss: 4.1559e-04 - val_loss: 3.1076e-04\n",
      "Epoch 31/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.2317e-04 - val_loss: 3.1672e-04\n",
      "Epoch 32/100\n",
      "16616/16616 [==============================] - 2s 102us/sample - loss: 4.1486e-04 - val_loss: 3.3590e-04\n",
      "Epoch 33/100\n",
      "16616/16616 [==============================] - 2s 99us/sample - loss: 4.1551e-04 - val_loss: 3.1278e-04\n",
      "Epoch 34/100\n",
      "16616/16616 [==============================] - 2s 109us/sample - loss: 4.2282e-04 - val_loss: 3.6104e-04\n",
      "Epoch 35/100\n",
      "16616/16616 [==============================] - 2s 99us/sample - loss: 4.1978e-04 - val_loss: 3.0794e-04\n",
      "Epoch 36/100\n",
      "16616/16616 [==============================] - 2s 101us/sample - loss: 4.2035e-04 - val_loss: 3.1417e-04\n",
      "Epoch 37/100\n",
      "16616/16616 [==============================] - 2s 101us/sample - loss: 4.2345e-04 - val_loss: 3.1669e-04\n",
      "Epoch 38/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.1724e-04 - val_loss: 3.2038e-04\n",
      "Epoch 39/100\n",
      "16616/16616 [==============================] - 2s 104us/sample - loss: 4.3407e-04 - val_loss: 3.1568e-04\n",
      "Epoch 40/100\n",
      "16616/16616 [==============================] - 2s 121us/sample - loss: 4.2342e-04 - val_loss: 3.6991e-04\n",
      "Epoch 41/100\n",
      "16616/16616 [==============================] - 2s 106us/sample - loss: 4.1775e-04 - val_loss: 3.2459e-04\n",
      "Epoch 42/100\n",
      "16616/16616 [==============================] - 2s 103us/sample - loss: 4.1966e-04 - val_loss: 3.1174e-04\n",
      "Epoch 43/100\n",
      "16616/16616 [==============================] - 2s 103us/sample - loss: 4.2168e-04 - val_loss: 3.1070e-04\n",
      "Epoch 44/100\n",
      "16616/16616 [==============================] - 2s 105us/sample - loss: 4.1936e-04 - val_loss: 3.1160e-04\n",
      "Epoch 45/100\n",
      "16616/16616 [==============================] - 2s 105us/sample - loss: 4.1521e-04 - val_loss: 3.1514e-04\n",
      "Epoch 46/100\n",
      "16616/16616 [==============================] - 2s 111us/sample - loss: 4.1622e-04 - val_loss: 3.1681e-04\n",
      "Epoch 47/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.1663e-04 - val_loss: 3.1661e-04\n",
      "Epoch 48/100\n",
      "16616/16616 [==============================] - 2s 98us/sample - loss: 4.1901e-04 - val_loss: 3.3583e-04\n",
      "Epoch 49/100\n",
      "16616/16616 [==============================] - 2s 96us/sample - loss: 4.2564e-04 - val_loss: 3.0722e-04\n",
      "Epoch 50/100\n",
      "16616/16616 [==============================] - 2s 102us/sample - loss: 4.1667e-04 - val_loss: 3.0557e-04\n",
      "Epoch 51/100\n",
      "16616/16616 [==============================] - 2s 101us/sample - loss: 4.1701e-04 - val_loss: 3.4401e-04\n",
      "Epoch 52/100\n",
      "16616/16616 [==============================] - 2s 107us/sample - loss: 4.1632e-04 - val_loss: 3.1968e-04\n",
      "Epoch 53/100\n",
      "16616/16616 [==============================] - 2s 102us/sample - loss: 4.2016e-04 - val_loss: 3.3534e-04\n",
      "Epoch 54/100\n",
      "16616/16616 [==============================] - 2s 98us/sample - loss: 4.2282e-04 - val_loss: 3.0643e-04\n",
      "Epoch 55/100\n",
      "16616/16616 [==============================] - 2s 128us/sample - loss: 4.1555e-04 - val_loss: 3.3008e-04\n",
      "Epoch 56/100\n",
      "16616/16616 [==============================] - 2s 117us/sample - loss: 4.2232e-04 - val_loss: 3.3055e-04\n",
      "Epoch 57/100\n",
      "16616/16616 [==============================] - 2s 117us/sample - loss: 4.1985e-04 - val_loss: 3.1222e-04\n",
      "Epoch 58/100\n",
      "16616/16616 [==============================] - 2s 125us/sample - loss: 4.1626e-04 - val_loss: 3.1890e-04\n",
      "Epoch 59/100\n",
      "16616/16616 [==============================] - 2s 105us/sample - loss: 4.1633e-04 - val_loss: 3.6767e-04\n",
      "Epoch 60/100\n",
      "16616/16616 [==============================] - 2s 114us/sample - loss: 4.1604e-04 - val_loss: 3.1622e-04\n",
      "Epoch 61/100\n",
      "16616/16616 [==============================] - 2s 115us/sample - loss: 4.1960e-04 - val_loss: 3.2160e-04\n",
      "Epoch 62/100\n",
      "16616/16616 [==============================] - 2s 106us/sample - loss: 4.1547e-04 - val_loss: 3.1119e-04\n",
      "Epoch 63/100\n",
      "16616/16616 [==============================] - 2s 102us/sample - loss: 4.1926e-04 - val_loss: 3.0572e-04\n",
      "Epoch 64/100\n",
      "16616/16616 [==============================] - 2s 121us/sample - loss: 4.1903e-04 - val_loss: 3.1517e-04\n",
      "Epoch 65/100\n",
      "16616/16616 [==============================] - 2s 110us/sample - loss: 4.1719e-04 - val_loss: 3.1805e-04\n",
      "Epoch 66/100\n",
      "16616/16616 [==============================] - 2s 108us/sample - loss: 4.2109e-04 - val_loss: 3.0757e-04\n",
      "Epoch 67/100\n",
      "16616/16616 [==============================] - 2s 115us/sample - loss: 4.1464e-04 - val_loss: 3.2707e-04\n",
      "Epoch 68/100\n",
      "16616/16616 [==============================] - 2s 101us/sample - loss: 4.1864e-04 - val_loss: 3.1188e-04\n",
      "Epoch 69/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.1440e-04 - val_loss: 3.1884e-04\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16616/16616 [==============================] - 2s 116us/sample - loss: 4.1350e-04 - val_loss: 3.1096e-04\n",
      "Epoch 71/100\n",
      "16616/16616 [==============================] - 2s 121us/sample - loss: 4.1962e-04 - val_loss: 3.4905e-04\n",
      "Epoch 72/100\n",
      "16616/16616 [==============================] - 2s 99us/sample - loss: 4.1595e-04 - val_loss: 3.2436e-04\n",
      "Epoch 73/100\n",
      "16616/16616 [==============================] - 2s 103us/sample - loss: 4.1525e-04 - val_loss: 3.0448e-04\n",
      "Epoch 74/100\n",
      "16616/16616 [==============================] - 2s 108us/sample - loss: 4.1804e-04 - val_loss: 3.1468e-04\n",
      "Epoch 75/100\n",
      "16616/16616 [==============================] - 2s 99us/sample - loss: 4.1328e-04 - val_loss: 3.1161e-04\n",
      "Epoch 76/100\n",
      "16616/16616 [==============================] - 2s 108us/sample - loss: 4.1595e-04 - val_loss: 3.0744e-04\n",
      "Epoch 77/100\n",
      "16616/16616 [==============================] - 2s 102us/sample - loss: 4.2167e-04 - val_loss: 3.7376e-04\n",
      "Epoch 78/100\n",
      "16616/16616 [==============================] - 2s 99us/sample - loss: 4.1717e-04 - val_loss: 3.1855e-04\n",
      "Epoch 79/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.1512e-04 - val_loss: 3.1566e-04\n",
      "Epoch 80/100\n",
      "16616/16616 [==============================] - 2s 98us/sample - loss: 4.2133e-04 - val_loss: 3.0638e-04\n",
      "Epoch 81/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.1655e-04 - val_loss: 3.3063e-04\n",
      "Epoch 82/100\n",
      "16616/16616 [==============================] - 2s 106us/sample - loss: 4.1737e-04 - val_loss: 3.1472e-04\n",
      "Epoch 83/100\n",
      "16616/16616 [==============================] - 2s 96us/sample - loss: 4.1384e-04 - val_loss: 3.0394e-04\n",
      "Epoch 84/100\n",
      "16616/16616 [==============================] - 2s 98us/sample - loss: 4.1420e-04 - val_loss: 3.1166e-04\n",
      "Epoch 85/100\n",
      "16616/16616 [==============================] - 2s 101us/sample - loss: 4.1971e-04 - val_loss: 3.4811e-04\n",
      "Epoch 86/100\n",
      "16616/16616 [==============================] - 2s 102us/sample - loss: 4.2047e-04 - val_loss: 3.0987e-04\n",
      "Epoch 87/100\n",
      "16616/16616 [==============================] - 2s 101us/sample - loss: 4.2175e-04 - val_loss: 3.1658e-04\n",
      "Epoch 88/100\n",
      "16616/16616 [==============================] - 2s 101us/sample - loss: 4.1630e-04 - val_loss: 3.6820e-04\n",
      "Epoch 89/100\n",
      "16616/16616 [==============================] - 2s 109us/sample - loss: 4.2257e-04 - val_loss: 3.1775e-04\n",
      "Epoch 90/100\n",
      "16616/16616 [==============================] - 2s 98us/sample - loss: 4.1254e-04 - val_loss: 3.5093e-04\n",
      "Epoch 91/100\n",
      "16616/16616 [==============================] - 2s 97us/sample - loss: 4.2074e-04 - val_loss: 3.1559e-04\n",
      "Epoch 92/100\n",
      "16616/16616 [==============================] - 2s 103us/sample - loss: 4.1639e-04 - val_loss: 3.1727e-04\n",
      "Epoch 93/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.2056e-04 - val_loss: 3.7239e-04\n",
      "Epoch 94/100\n",
      "16616/16616 [==============================] - 2s 102us/sample - loss: 4.1951e-04 - val_loss: 3.1615e-04\n",
      "Epoch 95/100\n",
      "16616/16616 [==============================] - 2s 111us/sample - loss: 4.1314e-04 - val_loss: 3.1278e-04\n",
      "Epoch 96/100\n",
      "16616/16616 [==============================] - 2s 101us/sample - loss: 4.1293e-04 - val_loss: 3.6068e-04\n",
      "Epoch 97/100\n",
      "16616/16616 [==============================] - 2s 101us/sample - loss: 4.1530e-04 - val_loss: 3.5885e-04\n",
      "Epoch 98/100\n",
      "16616/16616 [==============================] - 2s 97us/sample - loss: 4.1916e-04 - val_loss: 3.2749e-04\n",
      "Epoch 99/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.1500e-04 - val_loss: 3.3003e-04\n",
      "Epoch 100/100\n",
      "16616/16616 [==============================] - 2s 110us/sample - loss: 4.2010e-04 - val_loss: 3.3296e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x5c0ae8350>"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_split=0.1,\n",
    "          batch_size=50,\n",
    "          epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, array([[3.0964377],\n",
       "        [3.0964377],\n",
       "        [3.0964377],\n",
       "        [3.0964377],\n",
       "        [3.0964377],\n",
       "        [3.0964377],\n",
       "        [3.0964377],\n",
       "        [3.0964377],\n",
       "        [3.0964377],\n",
       "        [3.0964377]], dtype=float32))"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px = model.predict(vx)\n",
    "px.max() - px.min(), px[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16616 samples, validate on 1847 samples\n",
      "Epoch 1/100\n",
      "16616/16616 [==============================] - 2s 106us/sample - loss: 4.2299e-04 - val_loss: 3.4078e-04\n",
      "Epoch 2/100\n",
      "16616/16616 [==============================] - 2s 106us/sample - loss: 4.1597e-04 - val_loss: 3.2294e-04\n",
      "Epoch 3/100\n",
      "16616/16616 [==============================] - 2s 107us/sample - loss: 4.1245e-04 - val_loss: 3.1159e-04\n",
      "Epoch 4/100\n",
      "16616/16616 [==============================] - 2s 139us/sample - loss: 4.1542e-04 - val_loss: 3.7195e-04\n",
      "Epoch 5/100\n",
      "16616/16616 [==============================] - 2s 119us/sample - loss: 4.1562e-04 - val_loss: 3.5060e-04\n",
      "Epoch 6/100\n",
      "16616/16616 [==============================] - 2s 112us/sample - loss: 4.1648e-04 - val_loss: 3.1148e-04\n",
      "Epoch 7/100\n",
      "16616/16616 [==============================] - 2s 101us/sample - loss: 4.1597e-04 - val_loss: 3.0837e-04\n",
      "Epoch 8/100\n",
      "16616/16616 [==============================] - 2s 107us/sample - loss: 4.1508e-04 - val_loss: 3.1068e-04\n",
      "Epoch 9/100\n",
      "16616/16616 [==============================] - 2s 115us/sample - loss: 4.1894e-04 - val_loss: 3.3025e-04\n",
      "Epoch 10/100\n",
      "16616/16616 [==============================] - 2s 120us/sample - loss: 4.1561e-04 - val_loss: 3.4583e-04\n",
      "Epoch 11/100\n",
      "16616/16616 [==============================] - 2s 119us/sample - loss: 4.1842e-04 - val_loss: 3.3512e-04\n",
      "Epoch 12/100\n",
      "16616/16616 [==============================] - 2s 110us/sample - loss: 4.1596e-04 - val_loss: 3.4836e-04\n",
      "Epoch 13/100\n",
      "16616/16616 [==============================] - 2s 97us/sample - loss: 4.1675e-04 - val_loss: 3.0468e-04\n",
      "Epoch 14/100\n",
      "16616/16616 [==============================] - 2s 99us/sample - loss: 4.1596e-04 - val_loss: 3.0827e-04\n",
      "Epoch 15/100\n",
      "16616/16616 [==============================] - 2s 97us/sample - loss: 4.1702e-04 - val_loss: 3.0469e-04\n",
      "Epoch 16/100\n",
      "16616/16616 [==============================] - 2s 96us/sample - loss: 4.1726e-04 - val_loss: 3.9930e-04\n",
      "Epoch 17/100\n",
      "16616/16616 [==============================] - 2s 102us/sample - loss: 4.2149e-04 - val_loss: 3.1591e-04\n",
      "Epoch 18/100\n",
      "16616/16616 [==============================] - 2s 107us/sample - loss: 4.1523e-04 - val_loss: 3.0885e-04\n",
      "Epoch 19/100\n",
      "16616/16616 [==============================] - 2s 115us/sample - loss: 4.1627e-04 - val_loss: 3.0539e-04\n",
      "Epoch 20/100\n",
      "16616/16616 [==============================] - 2s 105us/sample - loss: 4.1470e-04 - val_loss: 3.2652e-04\n",
      "Epoch 21/100\n",
      "16616/16616 [==============================] - 2s 117us/sample - loss: 4.1427e-04 - val_loss: 3.1452e-04\n",
      "Epoch 22/100\n",
      "16616/16616 [==============================] - 2s 105us/sample - loss: 4.1611e-04 - val_loss: 3.1239e-04\n",
      "Epoch 23/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.1890e-04 - val_loss: 3.2862e-04\n",
      "Epoch 24/100\n",
      "16616/16616 [==============================] - 2s 109us/sample - loss: 4.1707e-04 - val_loss: 3.0788e-04\n",
      "Epoch 25/100\n",
      "16616/16616 [==============================] - 2s 98us/sample - loss: 4.1187e-04 - val_loss: 3.1691e-04\n",
      "Epoch 26/100\n",
      "16616/16616 [==============================] - 2s 104us/sample - loss: 4.1301e-04 - val_loss: 3.1843e-04\n",
      "Epoch 27/100\n",
      "16616/16616 [==============================] - 2s 122us/sample - loss: 4.1916e-04 - val_loss: 3.1516e-04\n",
      "Epoch 28/100\n",
      "16616/16616 [==============================] - 2s 102us/sample - loss: 4.1620e-04 - val_loss: 3.1227e-04\n",
      "Epoch 29/100\n",
      "16616/16616 [==============================] - 2s 110us/sample - loss: 4.1634e-04 - val_loss: 3.0859e-04\n",
      "Epoch 30/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.1906e-04 - val_loss: 3.1260e-04\n",
      "Epoch 31/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.1261e-04 - val_loss: 3.3174e-04\n",
      "Epoch 32/100\n",
      "16616/16616 [==============================] - 2s 102us/sample - loss: 4.2169e-04 - val_loss: 3.4321e-04\n",
      "Epoch 33/100\n",
      "16616/16616 [==============================] - 2s 108us/sample - loss: 4.1272e-04 - val_loss: 3.5176e-04\n",
      "Epoch 34/100\n",
      "16616/16616 [==============================] - 2s 107us/sample - loss: 4.1767e-04 - val_loss: 3.2815e-04\n",
      "Epoch 35/100\n",
      "16616/16616 [==============================] - 2s 110us/sample - loss: 4.1711e-04 - val_loss: 3.1514e-04\n",
      "Epoch 36/100\n",
      "16616/16616 [==============================] - 2s 107us/sample - loss: 4.1331e-04 - val_loss: 3.0549e-04\n",
      "Epoch 37/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.2001e-04 - val_loss: 3.3299e-04\n",
      "Epoch 38/100\n",
      "16616/16616 [==============================] - 2s 98us/sample - loss: 4.1641e-04 - val_loss: 3.0828e-04\n",
      "Epoch 39/100\n",
      "16616/16616 [==============================] - 2s 101us/sample - loss: 4.1409e-04 - val_loss: 3.0207e-04\n",
      "Epoch 40/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.1354e-04 - val_loss: 3.1886e-04\n",
      "Epoch 41/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.2270e-04 - val_loss: 3.1062e-04\n",
      "Epoch 42/100\n",
      "16616/16616 [==============================] - 2s 112us/sample - loss: 4.1732e-04 - val_loss: 3.1401e-04\n",
      "Epoch 43/100\n",
      "16616/16616 [==============================] - 2s 101us/sample - loss: 4.1137e-04 - val_loss: 3.7658e-04\n",
      "Epoch 44/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.1941e-04 - val_loss: 3.0810e-04\n",
      "Epoch 45/100\n",
      "16616/16616 [==============================] - 2s 98us/sample - loss: 4.1291e-04 - val_loss: 3.3425e-04\n",
      "Epoch 46/100\n",
      "16616/16616 [==============================] - 2s 98us/sample - loss: 4.1503e-04 - val_loss: 3.0351e-04\n",
      "Epoch 47/100\n",
      "16616/16616 [==============================] - 2s 104us/sample - loss: 4.1609e-04 - val_loss: 3.2743e-04\n",
      "Epoch 48/100\n",
      "16616/16616 [==============================] - 2s 112us/sample - loss: 4.1201e-04 - val_loss: 3.1610e-04\n",
      "Epoch 49/100\n",
      "16616/16616 [==============================] - 2s 103us/sample - loss: 4.2283e-04 - val_loss: 3.1525e-04\n",
      "Epoch 50/100\n",
      "16616/16616 [==============================] - 2s 101us/sample - loss: 4.1807e-04 - val_loss: 3.1104e-04\n",
      "Epoch 51/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.1444e-04 - val_loss: 3.2644e-04\n",
      "Epoch 52/100\n",
      "16616/16616 [==============================] - 2s 101us/sample - loss: 4.1277e-04 - val_loss: 3.2041e-04\n",
      "Epoch 53/100\n",
      "16616/16616 [==============================] - 2s 103us/sample - loss: 4.1402e-04 - val_loss: 3.1229e-04\n",
      "Epoch 54/100\n",
      "16616/16616 [==============================] - 2s 102us/sample - loss: 4.1227e-04 - val_loss: 3.0289e-04\n",
      "Epoch 55/100\n",
      "16616/16616 [==============================] - 2s 108us/sample - loss: 4.1652e-04 - val_loss: 3.2277e-04\n",
      "Epoch 56/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.1522e-04 - val_loss: 3.0609e-04\n",
      "Epoch 57/100\n",
      "16616/16616 [==============================] - 2s 104us/sample - loss: 4.1711e-04 - val_loss: 3.1942e-04\n",
      "Epoch 58/100\n",
      "16616/16616 [==============================] - 2s 111us/sample - loss: 4.1814e-04 - val_loss: 3.0555e-04\n",
      "Epoch 59/100\n",
      "16616/16616 [==============================] - 2s 104us/sample - loss: 4.1800e-04 - val_loss: 3.3609e-04\n",
      "Epoch 60/100\n",
      "16616/16616 [==============================] - 2s 101us/sample - loss: 4.1594e-04 - val_loss: 3.2488e-04\n",
      "Epoch 61/100\n",
      "16616/16616 [==============================] - 2s 108us/sample - loss: 4.1760e-04 - val_loss: 3.0500e-04\n",
      "Epoch 62/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.1119e-04 - val_loss: 3.0628e-04\n",
      "Epoch 63/100\n",
      "16616/16616 [==============================] - 2s 102us/sample - loss: 4.1551e-04 - val_loss: 3.4381e-04\n",
      "Epoch 64/100\n",
      "16616/16616 [==============================] - 2s 103us/sample - loss: 4.1421e-04 - val_loss: 3.0640e-04\n",
      "Epoch 65/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.1748e-04 - val_loss: 3.1832e-04\n",
      "Epoch 66/100\n",
      "16616/16616 [==============================] - 2s 103us/sample - loss: 4.1102e-04 - val_loss: 3.1135e-04\n",
      "Epoch 67/100\n",
      "16616/16616 [==============================] - 2s 107us/sample - loss: 4.1284e-04 - val_loss: 3.1157e-04\n",
      "Epoch 68/100\n",
      "16616/16616 [==============================] - 2s 98us/sample - loss: 4.1644e-04 - val_loss: 3.0353e-04\n",
      "Epoch 69/100\n",
      "16616/16616 [==============================] - 2s 103us/sample - loss: 4.1995e-04 - val_loss: 3.0787e-04\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.1679e-04 - val_loss: 3.1907e-04\n",
      "Epoch 71/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.1914e-04 - val_loss: 3.1735e-04\n",
      "Epoch 72/100\n",
      "16616/16616 [==============================] - 2s 109us/sample - loss: 4.1079e-04 - val_loss: 3.0955e-04\n",
      "Epoch 73/100\n",
      "16616/16616 [==============================] - 2s 105us/sample - loss: 4.1715e-04 - val_loss: 3.1463e-04\n",
      "Epoch 74/100\n",
      "16616/16616 [==============================] - 2s 109us/sample - loss: 4.1839e-04 - val_loss: 3.1894e-04\n",
      "Epoch 75/100\n",
      "16616/16616 [==============================] - 2s 98us/sample - loss: 4.1477e-04 - val_loss: 3.0855e-04\n",
      "Epoch 76/100\n",
      "16616/16616 [==============================] - 2s 98us/sample - loss: 4.1918e-04 - val_loss: 3.2298e-04\n",
      "Epoch 77/100\n",
      "16616/16616 [==============================] - 2s 101us/sample - loss: 4.1868e-04 - val_loss: 3.2306e-04\n",
      "Epoch 78/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.1367e-04 - val_loss: 3.0536e-04\n",
      "Epoch 79/100\n",
      "16616/16616 [==============================] - 2s 101us/sample - loss: 4.1275e-04 - val_loss: 3.2249e-04\n",
      "Epoch 80/100\n",
      "16616/16616 [==============================] - 2s 111us/sample - loss: 4.1343e-04 - val_loss: 3.4919e-04\n",
      "Epoch 81/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.1172e-04 - val_loss: 3.2448e-04\n",
      "Epoch 82/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.1230e-04 - val_loss: 3.1176e-04\n",
      "Epoch 83/100\n",
      "16616/16616 [==============================] - 2s 99us/sample - loss: 4.1433e-04 - val_loss: 3.2354e-04\n",
      "Epoch 84/100\n",
      "16616/16616 [==============================] - 2s 99us/sample - loss: 4.1423e-04 - val_loss: 3.0541e-04\n",
      "Epoch 85/100\n",
      "16616/16616 [==============================] - 2s 139us/sample - loss: 4.1492e-04 - val_loss: 3.0550e-04\n",
      "Epoch 86/100\n",
      "16616/16616 [==============================] - 2s 131us/sample - loss: 4.1755e-04 - val_loss: 3.1861e-04\n",
      "Epoch 87/100\n",
      "16616/16616 [==============================] - 2s 107us/sample - loss: 4.1607e-04 - val_loss: 3.0374e-04\n",
      "Epoch 88/100\n",
      "16616/16616 [==============================] - 2s 107us/sample - loss: 4.1304e-04 - val_loss: 3.1066e-04\n",
      "Epoch 89/100\n",
      "16616/16616 [==============================] - 2s 101us/sample - loss: 4.2094e-04 - val_loss: 3.1011e-04\n",
      "Epoch 90/100\n",
      "16616/16616 [==============================] - 2s 100us/sample - loss: 4.1696e-04 - val_loss: 3.1024e-04\n",
      "Epoch 91/100\n",
      "16616/16616 [==============================] - 2s 118us/sample - loss: 4.1724e-04 - val_loss: 3.2371e-04\n",
      "Epoch 92/100\n",
      "16616/16616 [==============================] - 2s 103us/sample - loss: 4.1382e-04 - val_loss: 3.1517e-04\n",
      "Epoch 93/100\n",
      "16616/16616 [==============================] - 2s 97us/sample - loss: 4.1422e-04 - val_loss: 3.0780e-04\n",
      "Epoch 94/100\n",
      "16616/16616 [==============================] - 2s 110us/sample - loss: 4.1517e-04 - val_loss: 3.1527e-04\n",
      "Epoch 95/100\n",
      "16616/16616 [==============================] - 2s 105us/sample - loss: 4.1319e-04 - val_loss: 3.2449e-04\n",
      "Epoch 96/100\n",
      "16616/16616 [==============================] - 2s 104us/sample - loss: 4.1608e-04 - val_loss: 3.0757e-04\n",
      "Epoch 97/100\n",
      "16616/16616 [==============================] - 2s 102us/sample - loss: 4.1443e-04 - val_loss: 3.5705e-04\n",
      "Epoch 98/100\n",
      "16616/16616 [==============================] - 2s 121us/sample - loss: 4.1857e-04 - val_loss: 3.0867e-04\n",
      "Epoch 99/100\n",
      "16616/16616 [==============================] - 2s 98us/sample - loss: 4.1514e-04 - val_loss: 3.2326e-04\n",
      "Epoch 100/100\n",
      "16616/16616 [==============================] - 2s 101us/sample - loss: 4.1090e-04 - val_loss: 3.3748e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, array([[3.0330584],\n",
       "        [3.0330584],\n",
       "        [3.0330584],\n",
       "        [3.0330584],\n",
       "        [3.0330584],\n",
       "        [3.0330584],\n",
       "        [3.0330584],\n",
       "        [3.0330584],\n",
       "        [3.0330584],\n",
       "        [3.0330584]], dtype=float32))"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_split=0.1,\n",
    "          batch_size=50,\n",
    "          epochs=100)\n",
    "\n",
    "px = model.predict(vx)\n",
    "px.max() - px.min(), px[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.0330584],\n",
       "       [3.0330584],\n",
       "       [3.0330584],\n",
       "       [3.0330584],\n",
       "       [3.0330584],\n",
       "       [3.0330584],\n",
       "       [3.0330584],\n",
       "       [3.0330584],\n",
       "       [3.0330584],\n",
       "       [3.0330584]], dtype=float32)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = int(0.9 * n)\n",
    "t_x = tx[:tn]\n",
    "t_y = ty[:tn]\n",
    "vx = tx[tn:]\n",
    "vy = ty[tn:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.196154096003038"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean((vy-px[0])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18463"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = ty.shape[0]; n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000402426388567365"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(((ty - tx[:, -1, 0])**2)[:tn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003908392597167753"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean((ty - tx[:, :, 0])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{python} -m pip install -Uq scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=18463, minmax=(-1.8482109411745973, 2.5711155530369467), mean=-4.658571096991829e-16, variance=1.000054165312534, skewness=0.4224378456946355, kurtosis=-0.5468299941299617)"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18463,)"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ty.hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 8), (8, 8), (8,), (8, 1), (1,)]"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = model.get_weights()\n",
    "[ r.shape for r in w ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AAPL-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24960, 8)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = aapl.shape\n",
    "aapl = aapl.reshape((shape[0] * shape[1], shape[2]))\n",
    "shape = aapl.shape; shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([214.718, 215.417, 215.43 , ..., 243.282, 243.258, 243.297])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgs = aapl[:, 4]; avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24959, 8), (24959,))"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.roll(avgs, -1)\n",
    "y = y[:-1]\n",
    "x = aapl[:-1]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24939, 20, 8), (24939,))"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window = 20\n",
    "n = x.shape[0]\n",
    "x = np.array([ x[i:(i+window)] for i in range(n-window) ])\n",
    "y = y[window:]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18463, 20, 8), (18463,))"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = np.logical_and([ (cnz(na(row)) == 0) for row in x ], ~na(y))\n",
    "y = y[idxs]\n",
    "x = x[idxs]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = x.shape[0]\n",
    "val = 1963\n",
    "trn = n - val\n",
    "tx, ty = x[:trn], y[:trn]\n",
    "vx, vy = x[trn:], y[trn:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18463,), (18463,))"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,-1,4].shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([214.435, 214.594, 214.476, ..., 243.282, 243.258, 243.297])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.059, -0.289, -0.041, ...,  0.202,  0.161, -0.015])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06451057146725886"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = x[:,-1,4] - y\n",
    "np.mean(d**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(16500, 20, 8), (16500,), (1963, 20, 8), (1963,)]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ a.shape for a in [tx,ty,vx,vy] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 32)                5248      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 5,281\n",
      "Trainable params: 5,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    LSTM(32, input_shape=(window, len(features))),\n",
    "    Dense(1),\n",
    "])\n",
    "model.build()\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/20\n",
      "16500/16500 [==============================] - 5s 308us/sample - loss: 44988.6397 - val_loss: 55906.6671\n",
      "Epoch 2/20\n",
      "16500/16500 [==============================] - 3s 171us/sample - loss: 43137.6257 - val_loss: 53393.1119\n",
      "Epoch 3/20\n",
      "16500/16500 [==============================] - 3s 175us/sample - loss: 41233.0813 - val_loss: 51560.3246\n",
      "Epoch 4/20\n",
      "16500/16500 [==============================] - 3s 179us/sample - loss: 39622.2297 - val_loss: 49728.6806\n",
      "Epoch 5/20\n",
      "16500/16500 [==============================] - 3s 174us/sample - loss: 37480.2085 - val_loss: 46678.4399\n",
      "Epoch 6/20\n",
      "16500/16500 [==============================] - 3s 170us/sample - loss: 35155.7298 - val_loss: 44440.6561\n",
      "Epoch 7/20\n",
      "16500/16500 [==============================] - 3s 172us/sample - loss: 33338.3102 - val_loss: 42551.0105\n",
      "Epoch 8/20\n",
      "16500/16500 [==============================] - 3s 180us/sample - loss: 31739.7855 - val_loss: 40770.5517\n",
      "Epoch 9/20\n",
      "16500/16500 [==============================] - 3s 172us/sample - loss: 30224.1840 - val_loss: 39065.1387\n",
      "Epoch 10/20\n",
      "16500/16500 [==============================] - 3s 170us/sample - loss: 28771.3893 - val_loss: 37419.8548\n",
      "Epoch 11/20\n",
      "16500/16500 [==============================] - 3s 175us/sample - loss: 27371.4636 - val_loss: 35826.1798\n",
      "Epoch 12/20\n",
      "16500/16500 [==============================] - 3s 178us/sample - loss: 26018.5757 - val_loss: 34275.5493\n",
      "Epoch 13/20\n",
      "16500/16500 [==============================] - 3s 169us/sample - loss: 24708.2888 - val_loss: 32771.7443\n",
      "Epoch 14/20\n",
      "16500/16500 [==============================] - 3s 170us/sample - loss: 23439.9464 - val_loss: 31309.1213\n",
      "Epoch 15/20\n",
      "16500/16500 [==============================] - 3s 169us/sample - loss: 22210.9555 - val_loss: 29886.4189\n",
      "Epoch 16/20\n",
      "16500/16500 [==============================] - 3s 181us/sample - loss: 21020.0687 - val_loss: 28501.9039\n",
      "Epoch 17/20\n",
      "16500/16500 [==============================] - 3s 184us/sample - loss: 19866.3794 - val_loss: 27155.1668\n",
      "Epoch 18/20\n",
      "16500/16500 [==============================] - 3s 172us/sample - loss: 18749.2058 - val_loss: 25845.0854\n",
      "Epoch 19/20\n",
      "16500/16500 [==============================] - 3s 171us/sample - loss: 17668.0538 - val_loss: 24571.6055\n",
      "Epoch 20/20\n",
      "16500/16500 [==============================] - 3s 180us/sample - loss: 16622.4917 - val_loss: 23334.2280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13e944d10>"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/20\n",
      "16500/16500 [==============================] - 3s 196us/sample - loss: 15612.2131 - val_loss: 22132.6820\n",
      "Epoch 2/20\n",
      "16500/16500 [==============================] - 3s 177us/sample - loss: 14636.8450 - val_loss: 20966.6546\n",
      "Epoch 3/20\n",
      "16500/16500 [==============================] - 3s 169us/sample - loss: 13696.1606 - val_loss: 19835.6729\n",
      "Epoch 4/20\n",
      "16500/16500 [==============================] - 3s 168us/sample - loss: 12789.9664 - val_loss: 18739.8554\n",
      "Epoch 5/20\n",
      "16500/16500 [==============================] - 3s 167us/sample - loss: 11918.1591 - val_loss: 17679.0931\n",
      "Epoch 6/20\n",
      "16500/16500 [==============================] - 3s 189us/sample - loss: 11080.4502 - val_loss: 16653.1755\n",
      "Epoch 7/20\n",
      "16500/16500 [==============================] - 3s 164us/sample - loss: 10276.5481 - val_loss: 15661.6208\n",
      "Epoch 8/20\n",
      "16500/16500 [==============================] - 3s 161us/sample - loss: 9506.3863 - val_loss: 14704.9840\n",
      "Epoch 9/20\n",
      "16500/16500 [==============================] - 3s 179us/sample - loss: 8769.7136 - val_loss: 13782.2635\n",
      "Epoch 10/20\n",
      "16500/16500 [==============================] - 3s 193us/sample - loss: 8066.3573 - val_loss: 12893.6561\n",
      "Epoch 11/20\n",
      "16500/16500 [==============================] - 3s 160us/sample - loss: 7396.1374 - val_loss: 12039.4758\n",
      "Epoch 12/20\n",
      "16500/16500 [==============================] - 3s 169us/sample - loss: 6758.8128 - val_loss: 11218.9557\n",
      "Epoch 13/20\n",
      "16500/16500 [==============================] - 3s 178us/sample - loss: 6154.0822 - val_loss: 10432.2643\n",
      "Epoch 14/20\n",
      "16500/16500 [==============================] - 3s 161us/sample - loss: 5581.6903 - val_loss: 9678.9815\n",
      "Epoch 15/20\n",
      "16500/16500 [==============================] - 3s 168us/sample - loss: 5041.4148 - val_loss: 8958.9880\n",
      "Epoch 16/20\n",
      "16500/16500 [==============================] - 3s 162us/sample - loss: 4532.8922 - val_loss: 8272.3027\n",
      "Epoch 17/20\n",
      "16500/16500 [==============================] - 3s 172us/sample - loss: 4055.7866 - val_loss: 7618.3019\n",
      "Epoch 18/20\n",
      "16500/16500 [==============================] - 3s 165us/sample - loss: 3609.8117 - val_loss: 6997.2377\n",
      "Epoch 19/20\n",
      "16500/16500 [==============================] - 3s 168us/sample - loss: 3194.5773 - val_loss: 6408.5697\n",
      "Epoch 20/20\n",
      "16500/16500 [==============================] - 3s 164us/sample - loss: 2809.5651 - val_loss: 5852.0548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14c24cd50>"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/20\n",
      "16500/16500 [==============================] - 3s 175us/sample - loss: 2454.3287 - val_loss: 5327.2482\n",
      "Epoch 2/20\n",
      "16500/16500 [==============================] - 3s 177us/sample - loss: 2128.3118 - val_loss: 4833.9684\n",
      "Epoch 3/20\n",
      "16500/16500 [==============================] - 3s 178us/sample - loss: 1830.9780 - val_loss: 4372.2482\n",
      "Epoch 4/20\n",
      "16500/16500 [==============================] - 3s 159us/sample - loss: 1561.7360 - val_loss: 3941.0871\n",
      "Epoch 5/20\n",
      "16500/16500 [==============================] - 3s 161us/sample - loss: 1319.8299 - val_loss: 3540.4152\n",
      "Epoch 6/20\n",
      "16500/16500 [==============================] - 3s 167us/sample - loss: 1104.4000 - val_loss: 3169.9071\n",
      "Epoch 7/20\n",
      "16500/16500 [==============================] - 3s 174us/sample - loss: 914.5995 - val_loss: 2829.1018\n",
      "Epoch 8/20\n",
      "16500/16500 [==============================] - 3s 161us/sample - loss: 749.3585 - val_loss: 2516.5574\n",
      "Epoch 9/20\n",
      "16500/16500 [==============================] - 3s 162us/sample - loss: 607.5209 - val_loss: 2233.0698\n",
      "Epoch 10/20\n",
      "16500/16500 [==============================] - 3s 162us/sample - loss: 487.8236 - val_loss: 1977.0174\n",
      "Epoch 11/20\n",
      "16500/16500 [==============================] - 3s 166us/sample - loss: 388.9023 - val_loss: 1748.5269\n",
      "Epoch 12/20\n",
      "16500/16500 [==============================] - 3s 161us/sample - loss: 309.1250 - val_loss: 1546.3894\n",
      "Epoch 13/20\n",
      "16500/16500 [==============================] - 3s 168us/sample - loss: 246.5982 - val_loss: 1369.7267\n",
      "Epoch 14/20\n",
      "16500/16500 [==============================] - 3s 159us/sample - loss: 199.2696 - val_loss: 1217.6282\n",
      "Epoch 15/20\n",
      "16500/16500 [==============================] - 3s 172us/sample - loss: 165.0059 - val_loss: 1089.2970\n",
      "Epoch 16/20\n",
      "16500/16500 [==============================] - 3s 161us/sample - loss: 141.5290 - val_loss: 983.3937\n",
      "Epoch 17/20\n",
      "16500/16500 [==============================] - 3s 161us/sample - loss: 126.4880 - val_loss: 898.6555\n",
      "Epoch 18/20\n",
      "16500/16500 [==============================] - 3s 172us/sample - loss: 117.6403 - val_loss: 832.9713\n",
      "Epoch 19/20\n",
      "16500/16500 [==============================] - 3s 178us/sample - loss: 112.9066 - val_loss: 784.6077\n",
      "Epoch 20/20\n",
      "16500/16500 [==============================] - 3s 178us/sample - loss: 110.6566 - val_loss: 750.5994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14c4cf390>"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/20\n",
      "16500/16500 [==============================] - 3s 183us/sample - loss: 109.7586 - val_loss: 729.1833\n",
      "Epoch 2/20\n",
      "16500/16500 [==============================] - 3s 166us/sample - loss: 109.4629 - val_loss: 717.4735\n",
      "Epoch 3/20\n",
      "16500/16500 [==============================] - 3s 163us/sample - loss: 109.3833 - val_loss: 711.8775\n",
      "Epoch 4/20\n",
      "16500/16500 [==============================] - 3s 161us/sample - loss: 109.3683 - val_loss: 708.9282\n",
      "Epoch 5/20\n",
      "16500/16500 [==============================] - 3s 168us/sample - loss: 109.3620 - val_loss: 706.8166\n",
      "Epoch 6/20\n",
      "16500/16500 [==============================] - 3s 169us/sample - loss: 109.3614 - val_loss: 707.7023\n",
      "Epoch 7/20\n",
      "16500/16500 [==============================] - 3s 165us/sample - loss: 109.3625 - val_loss: 708.9257\n",
      "Epoch 8/20\n",
      "16500/16500 [==============================] - 3s 162us/sample - loss: 109.3665 - val_loss: 706.3144\n",
      "Epoch 9/20\n",
      "16500/16500 [==============================] - 3s 171us/sample - loss: 109.3630 - val_loss: 705.9467\n",
      "Epoch 10/20\n",
      "16500/16500 [==============================] - 3s 159us/sample - loss: 109.3650 - val_loss: 705.4353\n",
      "Epoch 11/20\n",
      "16500/16500 [==============================] - 3s 158us/sample - loss: 109.3717 - val_loss: 706.7183\n",
      "Epoch 12/20\n",
      "16500/16500 [==============================] - 3s 170us/sample - loss: 109.3653 - val_loss: 707.8912\n",
      "Epoch 13/20\n",
      "16500/16500 [==============================] - 3s 177us/sample - loss: 109.3689 - val_loss: 707.3366\n",
      "Epoch 14/20\n",
      "16500/16500 [==============================] - 3s 165us/sample - loss: 109.3651 - val_loss: 706.8102\n",
      "Epoch 15/20\n",
      "16500/16500 [==============================] - 3s 162us/sample - loss: 109.3672 - val_loss: 709.3584\n",
      "Epoch 16/20\n",
      "16500/16500 [==============================] - 3s 162us/sample - loss: 109.3759 - val_loss: 707.5535\n",
      "Epoch 17/20\n",
      "16500/16500 [==============================] - 3s 170us/sample - loss: 109.3658 - val_loss: 703.7241\n",
      "Epoch 18/20\n",
      "16500/16500 [==============================] - 3s 162us/sample - loss: 109.3665 - val_loss: 710.2617\n",
      "Epoch 19/20\n",
      "16500/16500 [==============================] - 3s 159us/sample - loss: 109.3739 - val_loss: 704.9416\n",
      "Epoch 20/20\n",
      "16500/16500 [==============================] - 3s 161us/sample - loss: 109.3710 - val_loss: 708.1722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14c59a090>"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_14 (SimpleRNN)    (None, 32)                1312      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    SimpleRNN(32, input_shape=(window, len(features))),\n",
    "    Dense(1),\n",
    "])\n",
    "model.build()\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/20\n",
      "16500/16500 [==============================] - 3s 205us/sample - loss: 43744.4861 - val_loss: 52791.8456\n",
      "Epoch 2/20\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 39417.0714 - val_loss: 48090.3541\n",
      "Epoch 3/20\n",
      "16500/16500 [==============================] - 2s 135us/sample - loss: 35407.1841 - val_loss: 43707.5682\n",
      "Epoch 4/20\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 31693.2392 - val_loss: 39619.5789\n",
      "Epoch 5/20\n",
      "16500/16500 [==============================] - 2s 110us/sample - loss: 28255.7276 - val_loss: 35809.1404\n",
      "Epoch 6/20\n",
      "16500/16500 [==============================] - 2s 110us/sample - loss: 25077.8794 - val_loss: 32258.6856\n",
      "Epoch 7/20\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 22145.1686 - val_loss: 28954.1052\n",
      "Epoch 8/20\n",
      "16500/16500 [==============================] - 2s 111us/sample - loss: 19444.3579 - val_loss: 25884.8197\n",
      "Epoch 9/20\n",
      "16500/16500 [==============================] - 2s 113us/sample - loss: 16964.7800 - val_loss: 23039.3409\n",
      "Epoch 10/20\n",
      "16500/16500 [==============================] - 2s 112us/sample - loss: 14691.7711 - val_loss: 20387.1877\n",
      "Epoch 11/20\n",
      "16500/16500 [==============================] - 2s 112us/sample - loss: 12623.9145 - val_loss: 17959.4870\n",
      "Epoch 12/20\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 10750.1104 - val_loss: 15730.2055\n",
      "Epoch 13/20\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 9062.0190 - val_loss: 13690.9536\n",
      "Epoch 14/20\n",
      "16500/16500 [==============================] - 2s 116us/sample - loss: 7552.2398 - val_loss: 11837.0855\n",
      "Epoch 15/20\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 6213.1846 - val_loss: 10153.5960\n",
      "Epoch 16/20\n",
      "16500/16500 [==============================] - 2s 111us/sample - loss: 5037.5249 - val_loss: 8647.9683\n",
      "Epoch 17/20\n",
      "16500/16500 [==============================] - 2s 111us/sample - loss: 4018.1626 - val_loss: 7307.1831\n",
      "Epoch 18/20\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 3146.2787 - val_loss: 6123.2397\n",
      "Epoch 19/20\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 2413.0523 - val_loss: 5089.6445\n",
      "Epoch 20/20\n",
      "16500/16500 [==============================] - 2s 118us/sample - loss: 1808.8141 - val_loss: 4198.3317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14b0b2d90>"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/20\n",
      "16500/16500 [==============================] - 2s 111us/sample - loss: 1322.8062 - val_loss: 3439.4641\n",
      "Epoch 2/20\n",
      "16500/16500 [==============================] - 2s 117us/sample - loss: 943.3676 - val_loss: 2805.0609\n",
      "Epoch 3/20\n",
      "16500/16500 [==============================] - 2s 116us/sample - loss: 657.7758 - val_loss: 2283.8627\n",
      "Epoch 4/20\n",
      "16500/16500 [==============================] - 2s 106us/sample - loss: 452.0818 - val_loss: 1864.7974\n",
      "Epoch 5/20\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 312.0048 - val_loss: 1536.3445\n",
      "Epoch 6/20\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 223.0949 - val_loss: 1287.4983\n",
      "Epoch 7/20\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 171.1751 - val_loss: 1104.2713\n",
      "Epoch 8/20\n",
      "16500/16500 [==============================] - 2s 122us/sample - loss: 143.9120 - val_loss: 975.7463\n",
      "Epoch 9/20\n",
      "16500/16500 [==============================] - 2s 113us/sample - loss: 131.2897 - val_loss: 890.1772\n",
      "Epoch 10/20\n",
      "16500/16500 [==============================] - 2s 110us/sample - loss: 126.2974 - val_loss: 838.0555\n",
      "Epoch 11/20\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 124.6442 - val_loss: 808.0453\n",
      "Epoch 12/20\n",
      "16500/16500 [==============================] - 2s 113us/sample - loss: 124.1834 - val_loss: 793.3058\n",
      "Epoch 13/20\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 123.8853 - val_loss: 769.3643\n",
      "Epoch 14/20\n",
      "16500/16500 [==============================] - 2s 119us/sample - loss: 119.8746 - val_loss: 760.8050\n",
      "Epoch 15/20\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 119.7567 - val_loss: 759.0458\n",
      "Epoch 16/20\n",
      "16500/16500 [==============================] - 2s 107us/sample - loss: 119.7288 - val_loss: 760.9418\n",
      "Epoch 17/20\n",
      "16500/16500 [==============================] - 2s 111us/sample - loss: 119.6888 - val_loss: 761.2651\n",
      "Epoch 18/20\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 119.6456 - val_loss: 760.9383\n",
      "Epoch 19/20\n",
      "16500/16500 [==============================] - 2s 110us/sample - loss: 119.5956 - val_loss: 756.6199\n",
      "Epoch 20/20\n",
      "16500/16500 [==============================] - 2s 121us/sample - loss: 119.5371 - val_loss: 760.5915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13e3b2390>"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_13 (SimpleRNN)    (None, 32)                1312      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    SimpleRNN(32, input_shape=(window, len(features))),\n",
    "    Dense(1),\n",
    "])\n",
    "model.build()\n",
    "model.compile(loss='mse', optimizer='sgd')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "16500/16500 [==============================] - 3s 175us/sample - loss: 290.1315 - val_loss: 720.6219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14cde1110>"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/10\n",
      "16500/16500 [==============================] - 2s 119us/sample - loss: 120.7651 - val_loss: 744.7262\n",
      "Epoch 2/10\n",
      "16500/16500 [==============================] - 2s 104us/sample - loss: 117.0561 - val_loss: 790.6062\n",
      "Epoch 3/10\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 114.3773 - val_loss: 809.7257\n",
      "Epoch 4/10\n",
      "16500/16500 [==============================] - 2s 110us/sample - loss: 113.1029 - val_loss: 642.6632\n",
      "Epoch 5/10\n",
      "16500/16500 [==============================] - 2s 115us/sample - loss: 111.9965 - val_loss: 654.1763\n",
      "Epoch 6/10\n",
      "16500/16500 [==============================] - 2s 113us/sample - loss: 111.4130 - val_loss: 774.6058\n",
      "Epoch 7/10\n",
      "16500/16500 [==============================] - 2s 125us/sample - loss: 111.1374 - val_loss: 697.1080\n",
      "Epoch 8/10\n",
      "16500/16500 [==============================] - 2s 123us/sample - loss: 110.8589 - val_loss: 682.0563\n",
      "Epoch 9/10\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 110.5949 - val_loss: 627.7275\n",
      "Epoch 10/10\n",
      "16500/16500 [==============================] - 2s 110us/sample - loss: 110.6254 - val_loss: 739.7249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14abcd410>"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/20\n",
      "16500/16500 [==============================] - 2s 120us/sample - loss: 110.7725 - val_loss: 691.8990\n",
      "Epoch 2/20\n",
      "16500/16500 [==============================] - 2s 121us/sample - loss: 110.1673 - val_loss: 620.4467\n",
      "Epoch 3/20\n",
      "16500/16500 [==============================] - 2s 124us/sample - loss: 110.5189 - val_loss: 718.1927\n",
      "Epoch 4/20\n",
      "16500/16500 [==============================] - 2s 121us/sample - loss: 110.1622 - val_loss: 682.8046\n",
      "Epoch 5/20\n",
      "16500/16500 [==============================] - 2s 117us/sample - loss: 110.4196 - val_loss: 765.1008\n",
      "Epoch 6/20\n",
      "16500/16500 [==============================] - 2s 114us/sample - loss: 110.3792 - val_loss: 675.9035\n",
      "Epoch 7/20\n",
      "16500/16500 [==============================] - 2s 111us/sample - loss: 110.5333 - val_loss: 632.6029\n",
      "Epoch 8/20\n",
      "16500/16500 [==============================] - 2s 122us/sample - loss: 110.2806 - val_loss: 764.4253\n",
      "Epoch 9/20\n",
      "16500/16500 [==============================] - 2s 115us/sample - loss: 110.3655 - val_loss: 722.8224\n",
      "Epoch 10/20\n",
      "16500/16500 [==============================] - 2s 105us/sample - loss: 110.3473 - val_loss: 757.1707\n",
      "Epoch 11/20\n",
      "16500/16500 [==============================] - 2s 104us/sample - loss: 110.0416 - val_loss: 806.8209\n",
      "Epoch 12/20\n",
      "16500/16500 [==============================] - 2s 104us/sample - loss: 110.5190 - val_loss: 659.2229\n",
      "Epoch 13/20\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 110.3905 - val_loss: 707.0236\n",
      "Epoch 14/20\n",
      "16500/16500 [==============================] - 2s 111us/sample - loss: 110.2008 - val_loss: 697.8478\n",
      "Epoch 15/20\n",
      "16500/16500 [==============================] - 2s 115us/sample - loss: 110.3087 - val_loss: 806.5762\n",
      "Epoch 16/20\n",
      "16500/16500 [==============================] - 2s 114us/sample - loss: 110.3246 - val_loss: 849.2922\n",
      "Epoch 17/20\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 110.0890 - val_loss: 729.7543\n",
      "Epoch 18/20\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 110.3866 - val_loss: 679.1658\n",
      "Epoch 19/20\n",
      "16500/16500 [==============================] - 2s 112us/sample - loss: 110.5417 - val_loss: 632.7462\n",
      "Epoch 20/20\n",
      "16500/16500 [==============================] - 2s 112us/sample - loss: 110.2991 - val_loss: 704.9558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14ae8b190>"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-ticker attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = \\\n",
    "    array(\n",
    "        Parallel(n_jobs=8)(delayed(load_date_arr)(date) for date in dates)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24960"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 390, 505, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape =  all.shape; shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24960, 505, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = all.reshape(shape[0] * shape[1], *shape[2:]); all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(str(data_dir / 'all.npy'), all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24960, 4040)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = all.shape\n",
    "all = all.reshape(shape[:-2] + ((shape[-2] * shape[-1],)))\n",
    "shape = all.shape\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9792"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np.isnan(all[:, aapl_avg]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15168, 4040)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = all[~np.isnan(all[:, aapl_avg])]\n",
    "shape = all.shape; shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15167,), array([ 91.835, 204.915,  85.943, ...,  61.1  ,  54.221, 138.386]))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_avg = aapl * len(features) + 4\n",
    "out = all[:, aapl_avg]\n",
    "out = np.roll(out, -1)[:-1]\n",
    "all = all[:-1]\n",
    "shape = all.shape\n",
    "out.shape, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randint, shuffle\n",
    "from numpy import arange, nan_to_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 20\n",
    "\n",
    "def make_train_val_idxs(train=None, val=None):\n",
    "    num_samples = shape[0] - time_steps\n",
    "\n",
    "    if train is None and val is None:\n",
    "        raise Exception('Specify at least one of {train, val}')\n",
    "            \n",
    "    if train is not None and train < 1:\n",
    "        train = int(train * num_samples)\n",
    "\n",
    "    if val is not None and val < 1:\n",
    "        val = int(train * num_samples)\n",
    "    \n",
    "    if val is None:\n",
    "        val = num_samples - train\n",
    "    \n",
    "    if train is None:\n",
    "        train = num_samples - val\n",
    "    \n",
    "    if train + val > num_samples:\n",
    "        raise Exception('%d + %d > %d' % (train, val, num_samples))\n",
    "\n",
    "    sample_idxs = arange(time_steps, shape[0])\n",
    "    shuffle(sample_idxs)\n",
    "    training_idxs = sample_idxs[:train]\n",
    "    validation_idxs = sample_idxs[-val:]\n",
    "    return (training_idxs, validation_idxs)\n",
    "\n",
    "def make_train_val_sets(train=None, val=None):\n",
    "    train_idxs, val_idxs = make_train_val_idxs(train, val)\n",
    "    train_x = nan_to_num(array([ all[(idx - time_steps):idx] for idx in train_idxs ]))\n",
    "    train_y = nan_to_num(array([ all[idx][aapl_avg] for idx in train_idxs ]))\n",
    "    val_x = nan_to_num(array([ all[(idx - time_steps):idx] for idx in val_idxs ]))\n",
    "    val_y = nan_to_num(array([ all[idx][aapl_avg] for idx in val_idxs ]))\n",
    "    return (\n",
    "        train_x,\n",
    "        train_y,\n",
    "        val_x,\n",
    "        val_y,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12000, 20, 4040), (12000,), (1000, 20, 4040), (1000,)]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, train_y, val_x, val_y = make_train_val_sets(12000, 1000)\n",
    "[ a.shape for a in [train_x, train_y, val_x, val_y]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15167"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{python} -m pip install -Uq tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    SimpleRNN(32, input_shape=(time_steps, num_tickers * len(features))),\n",
    "    Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_7 (SimpleRNN)     (None, 32)                130336    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 130,369\n",
      "Trainable params: 130,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples\n",
      "Epoch 1/10\n",
      "12000/12000 [==============================] - 18s 1ms/sample - loss: 16344.0626\n",
      "Epoch 2/10\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15546.2652\n",
      "Epoch 3/10\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15530.9598\n",
      "Epoch 4/10\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15515.1891\n",
      "Epoch 5/10\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15502.5735\n",
      "Epoch 6/10\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15523.4275\n",
      "Epoch 7/10\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15517.6569\n",
      "Epoch 8/10\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15560.4271\n",
      "Epoch 9/10\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15538.1058\n",
      "Epoch 10/10\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15486.1096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1270f7f50>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, \n",
    "          #validation_data=(val_x, val_y),\n",
    "          batch_size=40,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples\n",
      "Epoch 1/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15545.4982\n",
      "Epoch 2/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15530.5658\n",
      "Epoch 3/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15478.8371\n",
      "Epoch 4/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15528.6299\n",
      "Epoch 5/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15508.9193\n",
      "Epoch 6/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15532.5590\n",
      "Epoch 7/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15535.9591\n",
      "Epoch 8/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15509.6757\n",
      "Epoch 9/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15512.1479\n",
      "Epoch 10/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15517.8358\n",
      "Epoch 11/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15523.9614\n",
      "Epoch 12/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15518.6465\n",
      "Epoch 13/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15541.3638\n",
      "Epoch 14/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15542.1389\n",
      "Epoch 15/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15507.6170\n",
      "Epoch 16/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15561.0873\n",
      "Epoch 17/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15500.9340\n",
      "Epoch 18/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15539.4070\n",
      "Epoch 19/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15534.0281\n",
      "Epoch 20/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15519.4072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x127084b10>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, \n",
    "          #validation_data=(val_x, val_y),\n",
    "          batch_size=40,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "12000/12000 [==============================] - 19s 2ms/sample - loss: 15419.7773 - val_loss: 15587.0837\n",
      "Epoch 2/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15412.6172 - val_loss: 15572.2574\n",
      "Epoch 3/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15406.8898 - val_loss: 15560.0918\n",
      "Epoch 4/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15402.4290 - val_loss: 15549.7905\n",
      "Epoch 5/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15398.7806 - val_loss: 15541.3923\n",
      "Epoch 6/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15395.8807 - val_loss: 15533.2663\n",
      "Epoch 7/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15393.4201 - val_loss: 15527.3017\n",
      "Epoch 8/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15391.4413 - val_loss: 15521.6040\n",
      "Epoch 9/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15389.8734 - val_loss: 15516.7603\n",
      "Epoch 10/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15388.4959 - val_loss: 15512.9119\n",
      "Epoch 11/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15387.0527 - val_loss: 15509.6008\n",
      "Epoch 12/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15385.9508 - val_loss: 15506.4874\n",
      "Epoch 13/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15384.9699 - val_loss: 15503.6509\n",
      "Epoch 14/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15384.1889 - val_loss: 15501.5730\n",
      "Epoch 15/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15383.2724 - val_loss: 15499.7572\n",
      "Epoch 16/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15382.4708 - val_loss: 15497.3213\n",
      "Epoch 17/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15381.7436 - val_loss: 15496.3086\n",
      "Epoch 18/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15381.1733 - val_loss: 15494.3058\n",
      "Epoch 19/20\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15380.4043 - val_loss: 15493.8809\n",
      "Epoch 20/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15379.8275 - val_loss: 15492.2244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1289c1c50>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, \n",
    "          validation_data=(val_x, val_y),\n",
    "          batch_size=40,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15379.3563 - val_loss: 15491.4467\n",
      "Epoch 2/20\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15378.7538 - val_loss: 15490.7604\n",
      "Epoch 3/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15378.3939 - val_loss: 15489.9805\n",
      "Epoch 4/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15377.8064 - val_loss: 15489.4879\n",
      "Epoch 5/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15377.2507 - val_loss: 15488.4293\n",
      "Epoch 6/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15376.9178 - val_loss: 15488.1877\n",
      "Epoch 7/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15376.4122 - val_loss: 15488.0419\n",
      "Epoch 8/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15375.9355 - val_loss: 15487.4029\n",
      "Epoch 9/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15375.5048 - val_loss: 15486.7018\n",
      "Epoch 10/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15375.1233 - val_loss: 15486.0648\n",
      "Epoch 11/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15374.7382 - val_loss: 15485.7077\n",
      "Epoch 12/20\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15374.4478 - val_loss: 15485.5669\n",
      "Epoch 13/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15374.1843 - val_loss: 15485.6775\n",
      "Epoch 14/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15373.7617 - val_loss: 15485.1194\n",
      "Epoch 15/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15373.3492 - val_loss: 15485.4241\n",
      "Epoch 16/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15373.1051 - val_loss: 15485.3653\n",
      "Epoch 17/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15372.8047 - val_loss: 15484.7645\n",
      "Epoch 18/20\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15372.7339 - val_loss: 15484.8161\n",
      "Epoch 19/20\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15372.2522 - val_loss: 15484.3374\n",
      "Epoch 20/20\n",
      "12000/12000 [==============================] - 22s 2ms/sample - loss: 15371.9052 - val_loss: 15484.4379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12939fbd0>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, \n",
    "          validation_data=(val_x, val_y),\n",
    "          batch_size=40,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 1000 samples\n",
      "Epoch 1/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15371.6789 - val_loss: 15484.1590\n",
      "Epoch 2/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15371.4278 - val_loss: 15484.0324\n",
      "Epoch 3/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15371.1502 - val_loss: 15484.1951\n",
      "Epoch 4/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15370.8957 - val_loss: 15483.6107\n",
      "Epoch 5/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15370.7880 - val_loss: 15483.7685\n",
      "Epoch 6/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15370.4712 - val_loss: 15483.7804\n",
      "Epoch 7/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15370.2009 - val_loss: 15484.2235\n",
      "Epoch 8/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15370.0815 - val_loss: 15483.6573\n",
      "Epoch 9/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15369.8132 - val_loss: 15482.9750\n",
      "Epoch 10/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15369.6613 - val_loss: 15483.3149\n",
      "Epoch 11/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15369.4625 - val_loss: 15484.1132\n",
      "Epoch 12/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15369.3379 - val_loss: 15483.3533\n",
      "Epoch 13/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15369.1234 - val_loss: 15484.1715\n",
      "Epoch 14/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15368.9816 - val_loss: 15483.5499\n",
      "Epoch 15/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15368.8965 - val_loss: 15483.5525\n",
      "Epoch 16/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15368.6454 - val_loss: 15483.6662\n",
      "Epoch 17/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15368.5599 - val_loss: 15483.7138\n",
      "Epoch 18/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15368.3201 - val_loss: 15483.7598\n",
      "Epoch 19/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15368.1804 - val_loss: 15483.7244\n",
      "Epoch 20/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15368.0417 - val_loss: 15484.0882\n",
      "Epoch 21/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15367.8634 - val_loss: 15483.8349\n",
      "Epoch 22/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15367.8055 - val_loss: 15484.6852\n",
      "Epoch 23/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15367.6273 - val_loss: 15484.4225\n",
      "Epoch 24/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15367.4939 - val_loss: 15483.9248\n",
      "Epoch 25/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15367.5515 - val_loss: 15484.5072\n",
      "Epoch 26/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15367.2620 - val_loss: 15484.0268\n",
      "Epoch 27/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15367.1751 - val_loss: 15484.4700\n",
      "Epoch 28/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15367.0119 - val_loss: 15484.5364\n",
      "Epoch 29/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15366.9254 - val_loss: 15484.7621\n",
      "Epoch 30/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15366.7972 - val_loss: 15484.0090\n",
      "Epoch 31/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15366.7314 - val_loss: 15484.5938\n",
      "Epoch 32/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15366.6675 - val_loss: 15484.6505\n",
      "Epoch 33/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15366.5920 - val_loss: 15485.5281\n",
      "Epoch 34/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15366.4706 - val_loss: 15485.0909\n",
      "Epoch 35/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15366.3468 - val_loss: 15484.9207\n",
      "Epoch 36/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15366.3199 - val_loss: 15484.9928\n",
      "Epoch 37/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15366.2021 - val_loss: 15485.0962\n",
      "Epoch 38/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15366.1154 - val_loss: 15485.0625\n",
      "Epoch 39/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15366.0865 - val_loss: 15484.7033\n",
      "Epoch 40/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.9530 - val_loss: 15484.6859\n",
      "Epoch 41/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15365.9066 - val_loss: 15484.9037\n",
      "Epoch 42/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.8852 - val_loss: 15485.7588\n",
      "Epoch 43/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.7198 - val_loss: 15485.7123\n",
      "Epoch 44/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.5846 - val_loss: 15485.8921\n",
      "Epoch 45/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.6091 - val_loss: 15485.8622\n",
      "Epoch 46/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15365.5466 - val_loss: 15485.8209\n",
      "Epoch 47/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.5100 - val_loss: 15486.5755\n",
      "Epoch 48/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.4012 - val_loss: 15486.3164\n",
      "Epoch 49/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.2905 - val_loss: 15486.0742\n",
      "Epoch 50/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.3412 - val_loss: 15486.5615\n",
      "Epoch 51/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.2883 - val_loss: 15486.1326\n",
      "Epoch 52/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.2048 - val_loss: 15486.1915\n",
      "Epoch 53/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.2716 - val_loss: 15486.2800\n",
      "Epoch 54/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15365.0775 - val_loss: 15487.2062\n",
      "Epoch 55/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.0816 - val_loss: 15486.6459\n",
      "Epoch 56/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.0033 - val_loss: 15487.4182\n",
      "Epoch 57/200\n",
      "12000/12000 [==============================] - 18s 1ms/sample - loss: 15364.9730 - val_loss: 15486.9547\n",
      "Epoch 58/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15364.8830 - val_loss: 15486.9924\n",
      "Epoch 59/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.9302 - val_loss: 15488.0205\n",
      "Epoch 60/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.8860 - val_loss: 15487.4170\n",
      "Epoch 61/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15364.7715 - val_loss: 15487.3907\n",
      "Epoch 62/200\n",
      "12000/12000 [==============================] - 20s 2ms/sample - loss: 15364.8262 - val_loss: 15487.7803\n",
      "Epoch 63/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15364.7199 - val_loss: 15488.1130\n",
      "Epoch 64/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.7073 - val_loss: 15487.8657\n",
      "Epoch 65/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15364.5922 - val_loss: 15487.9613\n",
      "Epoch 66/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15364.6650 - val_loss: 15487.8966\n",
      "Epoch 67/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.6510 - val_loss: 15487.7521\n",
      "Epoch 68/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.6147 - val_loss: 15488.2514\n",
      "Epoch 69/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15364.5341 - val_loss: 15488.6650\n",
      "Epoch 70/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.4567 - val_loss: 15487.8361\n",
      "Epoch 71/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.4859 - val_loss: 15488.8021\n",
      "Epoch 72/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15364.5323 - val_loss: 15488.8044\n",
      "Epoch 73/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15364.4228 - val_loss: 15488.7661\n",
      "Epoch 74/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.4240 - val_loss: 15489.0221\n",
      "Epoch 75/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.3305 - val_loss: 15488.6086\n",
      "Epoch 76/200\n",
      "12000/12000 [==============================] - 18s 2ms/sample - loss: 15364.4042 - val_loss: 15489.1560\n",
      "Epoch 77/200\n",
      "12000/12000 [==============================] - 18s 1ms/sample - loss: 15364.1848 - val_loss: 15489.3888\n",
      "Epoch 78/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15364.3073 - val_loss: 15489.8720\n",
      "Epoch 79/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15364.2523 - val_loss: 15489.4412\n",
      "Epoch 80/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15364.1253 - val_loss: 15489.1646\n",
      "Epoch 81/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.1467 - val_loss: 15489.2597\n",
      "Epoch 82/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.2014 - val_loss: 15489.4058\n",
      "Epoch 83/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.2043 - val_loss: 15489.4420\n",
      "Epoch 84/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.0430 - val_loss: 15490.0845\n",
      "Epoch 85/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15364.0453 - val_loss: 15490.0477\n",
      "Epoch 86/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.0640 - val_loss: 15489.8942\n",
      "Epoch 87/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.0791 - val_loss: 15489.7594\n",
      "Epoch 88/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.0414 - val_loss: 15489.8688\n",
      "Epoch 89/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.9893 - val_loss: 15491.1146\n",
      "Epoch 90/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.0469 - val_loss: 15490.1292\n",
      "Epoch 91/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.9962 - val_loss: 15490.6645\n",
      "Epoch 92/200\n",
      "12000/12000 [==============================] - 19s 2ms/sample - loss: 15363.9750 - val_loss: 15490.2653\n",
      "Epoch 93/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15364.0191 - val_loss: 15490.1542\n",
      "Epoch 94/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15364.0085 - val_loss: 15490.3099\n",
      "Epoch 95/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.0008 - val_loss: 15490.1798\n",
      "Epoch 96/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.9550 - val_loss: 15490.5604\n",
      "Epoch 97/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.7946 - val_loss: 15491.2408\n",
      "Epoch 98/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.8231 - val_loss: 15491.2425\n",
      "Epoch 99/200\n",
      "12000/12000 [==============================] - 18s 2ms/sample - loss: 15363.8095 - val_loss: 15491.2521\n",
      "Epoch 100/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.9265 - val_loss: 15491.5680\n",
      "Epoch 101/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.7955 - val_loss: 15491.9384\n",
      "Epoch 102/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.7687 - val_loss: 15491.2110\n",
      "Epoch 103/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.8176 - val_loss: 15492.2268\n",
      "Epoch 104/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.6955 - val_loss: 15491.3702\n",
      "Epoch 105/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.7407 - val_loss: 15491.8358\n",
      "Epoch 106/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.6801 - val_loss: 15492.1043\n",
      "Epoch 107/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.7715 - val_loss: 15491.4440\n",
      "Epoch 108/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.7181 - val_loss: 15491.8456\n",
      "Epoch 109/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.7679 - val_loss: 15492.1118\n",
      "Epoch 110/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.6826 - val_loss: 15492.3659\n",
      "Epoch 111/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.7242 - val_loss: 15492.4152\n",
      "Epoch 112/200\n",
      "12000/12000 [==============================] - 18s 2ms/sample - loss: 15363.6951 - val_loss: 15493.2859\n",
      "Epoch 113/200\n",
      "12000/12000 [==============================] - 20s 2ms/sample - loss: 15363.6332 - val_loss: 15492.0758\n",
      "Epoch 114/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.7628 - val_loss: 15492.5307\n",
      "Epoch 115/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.6426 - val_loss: 15492.5631\n",
      "Epoch 116/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.6874 - val_loss: 15492.9209\n",
      "Epoch 117/200\n",
      "12000/12000 [==============================] - 18s 1ms/sample - loss: 15363.6634 - val_loss: 15492.7098\n",
      "Epoch 118/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.6470 - val_loss: 15492.3780\n",
      "Epoch 119/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.5755 - val_loss: 15493.2647\n",
      "Epoch 120/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.5610 - val_loss: 15492.6952\n",
      "Epoch 121/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.5847 - val_loss: 15493.7637\n",
      "Epoch 122/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.5152 - val_loss: 15493.1302\n",
      "Epoch 123/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.6426 - val_loss: 15493.8497\n",
      "Epoch 124/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.6164 - val_loss: 15493.7640\n",
      "Epoch 125/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.7003 - val_loss: 15492.6092\n",
      "Epoch 126/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.6629 - val_loss: 15493.5451\n",
      "Epoch 127/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.7010 - val_loss: 15493.1428\n",
      "Epoch 128/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.4990 - val_loss: 15493.2272\n",
      "Epoch 129/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.5227 - val_loss: 15493.6791\n",
      "Epoch 130/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.5284 - val_loss: 15493.5030\n",
      "Epoch 131/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.5364 - val_loss: 15493.8812\n",
      "Epoch 132/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.6192 - val_loss: 15493.9941\n",
      "Epoch 133/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.6177 - val_loss: 15493.3013\n",
      "Epoch 134/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.6193 - val_loss: 15493.5246\n",
      "Epoch 135/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.5487 - val_loss: 15494.4170\n",
      "Epoch 136/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.4950 - val_loss: 15494.5055\n",
      "Epoch 137/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3594 - val_loss: 15494.6568\n",
      "Epoch 138/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.5039 - val_loss: 15494.9066\n",
      "Epoch 139/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.5146 - val_loss: 15493.8905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.4934 - val_loss: 15494.7523\n",
      "Epoch 141/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3948 - val_loss: 15494.3557\n",
      "Epoch 142/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.4620 - val_loss: 15495.2337\n",
      "Epoch 143/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.4224 - val_loss: 15494.8069\n",
      "Epoch 144/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.4144 - val_loss: 15494.9970\n",
      "Epoch 145/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.4223 - val_loss: 15495.0199\n",
      "Epoch 146/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.4744 - val_loss: 15495.5698\n",
      "Epoch 147/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3751 - val_loss: 15494.8303\n",
      "Epoch 148/200\n",
      "12000/12000 [==============================] - 19s 2ms/sample - loss: 15363.4290 - val_loss: 15495.0324\n",
      "Epoch 149/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.3788 - val_loss: 15495.3106\n",
      "Epoch 150/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3796 - val_loss: 15495.0147\n",
      "Epoch 151/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3762 - val_loss: 15495.1361\n",
      "Epoch 152/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.4002 - val_loss: 15494.7084\n",
      "Epoch 153/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3733 - val_loss: 15495.3746\n",
      "Epoch 154/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3760 - val_loss: 15495.9733\n",
      "Epoch 155/200\n",
      "12000/12000 [==============================] - 18s 1ms/sample - loss: 15363.3704 - val_loss: 15495.4700\n",
      "Epoch 156/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.4479 - val_loss: 15495.5818\n",
      "Epoch 157/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.4128 - val_loss: 15495.4421\n",
      "Epoch 158/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.4167 - val_loss: 15494.9213\n",
      "Epoch 159/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.4127 - val_loss: 15495.7243\n",
      "Epoch 160/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3238 - val_loss: 15495.5377\n",
      "Epoch 161/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3957 - val_loss: 15496.4208\n",
      "Epoch 162/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.4137 - val_loss: 15495.5683\n",
      "Epoch 163/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3438 - val_loss: 15495.7751\n",
      "Epoch 164/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3569 - val_loss: 15495.5899\n",
      "Epoch 165/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2598 - val_loss: 15495.6927\n",
      "Epoch 166/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.5380 - val_loss: 15495.9599\n",
      "Epoch 167/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3724 - val_loss: 15495.6699\n",
      "Epoch 168/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3303 - val_loss: 15496.2546\n",
      "Epoch 169/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.4383 - val_loss: 15495.8824\n",
      "Epoch 170/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.4371 - val_loss: 15496.4429\n",
      "Epoch 171/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3343 - val_loss: 15496.1940\n",
      "Epoch 172/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3407 - val_loss: 15496.3231\n",
      "Epoch 173/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.4285 - val_loss: 15496.3053\n",
      "Epoch 174/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2681 - val_loss: 15496.4063\n",
      "Epoch 175/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3369 - val_loss: 15496.2381\n",
      "Epoch 176/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3454 - val_loss: 15496.4258\n",
      "Epoch 177/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3479 - val_loss: 15497.2161\n",
      "Epoch 178/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2949 - val_loss: 15496.4778\n",
      "Epoch 179/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2682 - val_loss: 15497.1458\n",
      "Epoch 180/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3693 - val_loss: 15496.5148\n",
      "Epoch 181/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3856 - val_loss: 15496.7098\n",
      "Epoch 182/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2492 - val_loss: 15496.5529\n",
      "Epoch 183/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3478 - val_loss: 15497.1580\n",
      "Epoch 184/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2718 - val_loss: 15496.9531\n",
      "Epoch 185/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3173 - val_loss: 15497.1014\n",
      "Epoch 186/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2959 - val_loss: 15497.0138\n",
      "Epoch 187/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3931 - val_loss: 15497.3296\n",
      "Epoch 188/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3893 - val_loss: 15497.1907\n",
      "Epoch 189/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2284 - val_loss: 15497.0637\n",
      "Epoch 190/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2770 - val_loss: 15496.7870\n",
      "Epoch 191/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3897 - val_loss: 15497.0820\n",
      "Epoch 192/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.4221 - val_loss: 15496.4670\n",
      "Epoch 193/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.1928 - val_loss: 15497.0653\n",
      "Epoch 194/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3465 - val_loss: 15496.9933\n",
      "Epoch 195/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2698 - val_loss: 15497.0039\n",
      "Epoch 196/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3350 - val_loss: 15498.0570\n",
      "Epoch 197/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3492 - val_loss: 15496.9771\n",
      "Epoch 198/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.1619 - val_loss: 15497.2436\n",
      "Epoch 199/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2072 - val_loss: 15497.1660\n",
      "Epoch 200/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2826 - val_loss: 15497.1246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x128965790>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, \n",
    "          validation_data=(val_x, val_y),\n",
    "          batch_size=40,\n",
    "          epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12392.3727\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 14s 1ms/sample - loss: 12332.7983\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 16s 2ms/sample - loss: 12362.4786\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12381.8192\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12341.3580\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12337.6320\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12358.0993\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12322.7205\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12390.4263\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12381.1204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x126945dd0>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, \n",
    "          batch_size=10,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 16s 2ms/sample - loss: 12356.6821\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12356.3212\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12393.1001\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12219.4047\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12299.5797\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12324.0439\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12323.7565\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12325.0019\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12394.5230\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12326.8734\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12363.2107\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 17s 2ms/sample - loss: 12362.7202\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12406.3008\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12312.1227\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12358.4351\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12372.3430\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12337.8851\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 16s 2ms/sample - loss: 12331.7085\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12399.3326\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 16s 2ms/sample - loss: 12380.6395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x126c5fd90>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, \n",
    "          batch_size=10,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.46147427, 0.4936299 , 0.7725021 , 0.18668415, 0.19160269,\n",
       "        0.5329875 , 0.89422435, 0.8431803 , 0.45767853, 0.9006393 ,\n",
       "        0.30371124, 0.8654656 , 0.64627594, 0.2774724 , 0.34715426,\n",
       "        0.7767715 , 0.08706174, 0.9893154 , 0.6400852 , 0.9627552 ,\n",
       "        0.50067353, 0.56687176, 0.48472205, 0.6378169 , 0.6819773 ,\n",
       "        0.6446982 , 0.13012254, 0.27104077, 0.50481087, 0.25702876,\n",
       "        0.59998226, 0.45324805, 0.50154966, 0.43757737, 0.66555214,\n",
       "        0.9135334 , 0.7003318 , 0.23003371, 0.05756523, 0.49323606,\n",
       "        0.75259066, 0.6157169 , 0.6374104 , 0.5707051 , 0.6783405 ,\n",
       "        0.89434326, 0.8651092 , 0.9301288 , 0.586712  , 0.7044457 ,\n",
       "        0.7020338 , 0.09967529, 0.7703017 , 0.85118467, 0.14892976,\n",
       "        0.24892834, 0.2034809 , 0.26588657, 0.05641429, 0.03270473,\n",
       "        0.73204887, 0.9724218 , 0.31882647, 0.17593206, 0.7806721 ,\n",
       "        0.96902066, 0.84500116, 0.7622705 , 0.00976924, 0.772007  ,\n",
       "        0.31686476, 0.95740134, 0.16487914, 0.99371856, 0.77002376,\n",
       "        0.0585487 , 0.30136323, 0.05418719, 0.02097294, 0.8098558 ,\n",
       "        0.9993328 , 0.9676906 , 0.8079357 , 0.07865059, 0.7572921 ,\n",
       "        0.00712246, 0.6570062 , 0.316152  , 0.00867406, 0.6616431 ,\n",
       "        0.25412577, 0.3306162 , 0.14759275, 0.13746355, 0.02187528,\n",
       "        0.1780793 , 0.6548838 , 0.15741996, 0.94479674, 0.16080537],\n",
       "       dtype=float32),\n",
       " array([0.7818266 , 0.44980854, 0.65075845, 0.17491417, 0.5047283 ,\n",
       "        0.16106072, 0.5499607 , 0.8744731 , 0.6006628 , 0.8955531 ,\n",
       "        0.12414642, 0.68526095, 0.6667509 , 0.11806473, 0.359241  ,\n",
       "        0.6119286 , 0.8484664 , 0.68293065, 0.9550282 , 0.9045459 ,\n",
       "        0.88269144, 0.27150008, 0.4650287 , 0.8676415 , 0.5026252 ,\n",
       "        0.42452398, 0.8481062 , 0.15626116, 0.36071396, 0.42584082,\n",
       "        0.12930751, 0.26520145, 0.6903245 , 0.84599334, 0.13224092,\n",
       "        0.37767032, 0.97641206, 0.96301776, 0.21939163, 0.05385643,\n",
       "        0.4527225 , 0.9724792 , 0.3342038 , 0.6168115 , 0.3395587 ,\n",
       "        0.43398395, 0.9803608 , 0.7955412 , 0.23625055, 0.23964162,\n",
       "        0.02104023, 0.40777066, 0.94194674, 0.9913477 , 0.04047493,\n",
       "        0.5572203 , 0.06472664, 0.64436775, 0.24161713, 0.7522351 ,\n",
       "        0.892538  , 0.08331183, 0.26689017, 0.7610726 , 0.8750384 ,\n",
       "        0.99299073, 0.91673225, 0.7365139 , 0.9257179 , 0.5206772 ,\n",
       "        0.5923702 , 0.5963442 , 0.39472255, 0.25320303, 0.9780684 ,\n",
       "        0.2298456 , 0.43313423, 0.00417769, 0.3118336 , 0.7907522 ,\n",
       "        0.09478721, 0.30305177, 0.40730244, 0.8591287 , 0.7661657 ,\n",
       "        0.5432202 , 0.48406875, 0.77418864, 0.1522045 , 0.29970375,\n",
       "        0.35280573, 0.20427185, 0.8599315 , 0.6667513 , 0.81909835,\n",
       "        0.48030037, 0.43726304, 0.92959535, 0.6319735 , 0.87687695],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = random((100,)).astype(np.float32)\n",
    "train_y = random((100,)).astype(np.float32)\n",
    "train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    SimpleRNN(10, input_shape=(10, 1)),\n",
    "    Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_4 (SimpleRNN)     (None, 10)                120       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.46147427],\n",
       "        [0.4936299 ],\n",
       "        [0.7725021 ],\n",
       "        [0.18668415],\n",
       "        [0.19160269],\n",
       "        [0.5329875 ],\n",
       "        [0.89422435],\n",
       "        [0.8431803 ],\n",
       "        [0.45767853],\n",
       "        [0.9006393 ]],\n",
       "\n",
       "       [[0.30371124],\n",
       "        [0.8654656 ],\n",
       "        [0.64627594],\n",
       "        [0.2774724 ],\n",
       "        [0.34715426],\n",
       "        [0.7767715 ],\n",
       "        [0.08706174],\n",
       "        [0.9893154 ],\n",
       "        [0.6400852 ],\n",
       "        [0.9627552 ]],\n",
       "\n",
       "       [[0.50067353],\n",
       "        [0.56687176],\n",
       "        [0.48472205],\n",
       "        [0.6378169 ],\n",
       "        [0.6819773 ],\n",
       "        [0.6446982 ],\n",
       "        [0.13012254],\n",
       "        [0.27104077],\n",
       "        [0.50481087],\n",
       "        [0.25702876]],\n",
       "\n",
       "       [[0.59998226],\n",
       "        [0.45324805],\n",
       "        [0.50154966],\n",
       "        [0.43757737],\n",
       "        [0.66555214],\n",
       "        [0.9135334 ],\n",
       "        [0.7003318 ],\n",
       "        [0.23003371],\n",
       "        [0.05756523],\n",
       "        [0.49323606]],\n",
       "\n",
       "       [[0.75259066],\n",
       "        [0.6157169 ],\n",
       "        [0.6374104 ],\n",
       "        [0.5707051 ],\n",
       "        [0.6783405 ],\n",
       "        [0.89434326],\n",
       "        [0.8651092 ],\n",
       "        [0.9301288 ],\n",
       "        [0.586712  ],\n",
       "        [0.7044457 ]],\n",
       "\n",
       "       [[0.7020338 ],\n",
       "        [0.09967529],\n",
       "        [0.7703017 ],\n",
       "        [0.85118467],\n",
       "        [0.14892976],\n",
       "        [0.24892834],\n",
       "        [0.2034809 ],\n",
       "        [0.26588657],\n",
       "        [0.05641429],\n",
       "        [0.03270473]],\n",
       "\n",
       "       [[0.73204887],\n",
       "        [0.9724218 ],\n",
       "        [0.31882647],\n",
       "        [0.17593206],\n",
       "        [0.7806721 ],\n",
       "        [0.96902066],\n",
       "        [0.84500116],\n",
       "        [0.7622705 ],\n",
       "        [0.00976924],\n",
       "        [0.772007  ]],\n",
       "\n",
       "       [[0.31686476],\n",
       "        [0.95740134],\n",
       "        [0.16487914],\n",
       "        [0.99371856],\n",
       "        [0.77002376],\n",
       "        [0.0585487 ],\n",
       "        [0.30136323],\n",
       "        [0.05418719],\n",
       "        [0.02097294],\n",
       "        [0.8098558 ]],\n",
       "\n",
       "       [[0.9993328 ],\n",
       "        [0.9676906 ],\n",
       "        [0.8079357 ],\n",
       "        [0.07865059],\n",
       "        [0.7572921 ],\n",
       "        [0.00712246],\n",
       "        [0.6570062 ],\n",
       "        [0.316152  ],\n",
       "        [0.00867406],\n",
       "        [0.6616431 ]],\n",
       "\n",
       "       [[0.25412577],\n",
       "        [0.3306162 ],\n",
       "        [0.14759275],\n",
       "        [0.13746355],\n",
       "        [0.02187528],\n",
       "        [0.1780793 ],\n",
       "        [0.6548838 ],\n",
       "        [0.15741996],\n",
       "        [0.94479674],\n",
       "        [0.16080537]]], dtype=float32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.reshape(10, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10 samples\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 1693.9922\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 593us/sample - loss: 1245.9900\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 475us/sample - loss: 963.2513\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 502us/sample - loss: 778.3412\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 483us/sample - loss: 666.6307\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 707us/sample - loss: 877.8005\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 611us/sample - loss: 580.0933\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 693us/sample - loss: 1129.6672\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 753us/sample - loss: 948.7717\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 786us/sample - loss: 719.8773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1253a7f50>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x.reshape(10, 10, 1) * 100, train_y[:10] * 100, \n",
    "          batch_size=10,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks-3.7.4",
   "language": "python",
   "name": "notebooks-3.7.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
