{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Periodic download of IEX stock-ticker data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read IEX API credentials from `~/.config/iex.ini`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "config_path = Path.home() / '.config' / 'iex.ini'\n",
    "\n",
    "from configparser import ConfigParser\n",
    "config = ConfigParser()\n",
    "config.read(str(config_path))\n",
    "iex_config = config['iex']\n",
    "\n",
    "api = 'https://cloud.iexapis.com'\n",
    "public_key = iex_config['public_key']\n",
    "secret_key = iex_config['secret_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers = sorted(\"MMM ABT ABBV ABMD ACN ATVI ADBE AMD AAP AES AMG AFL A APD AKAM ALK ALB ARE ALXN ALGN ALLE AGN ADS LNT ALL GOOGL GOOG MO AMZN AMCR AEE AAL AEP AXP AIG AMT AWK AMP ABC AME AMGN APH ADI ANSS ANTM AON AOS APA AIV AAPL AMAT APTV ADM ARNC ANET AJG AIZ ATO T ADSK ADP AZO AVB AVY BKR BLL BAC BK BAX BBT BDX BRK.B BBY BIIB BLK HRB BA BKNG BWA BXP BSX BMY AVGO BR BF.B CHRW COG CDNS CPB COF CPRI CAH KMX CCL CAT CBOE CBRE CBS CDW CE CELG CNC CNP CTL CERN CF SCHW CHTR CVX CMG CB CHD CI XEC CINF CTAS CSCO C CFG CTXS CLX CME CMS KO CTSH CL CMCSA CMA CAG CXO COP ED STZ COO CPRT GLW CTVA COST COTY CCI CSX CMI CVS DHI DHR DRI DVA DE DAL XRAY DVN FANG DLR DFS DISCA DISCK DISH DG DLTR D DOV DOW DTE DUK DRE DD DXC ETFC EMN ETN EBAY ECL EIX EW EA EMR ETR EOG EFX EQIX EQR ESS EL EVRG ES RE EXC EXPE EXPD EXR XOM FFIV FB FAST FRT FDX FIS FITB FE FRC FISV FLT FLIR FLS FMC F FTNT FTV FBHS FOXA FOX BEN FCX GPS GRMN IT GD GE GIS GM GPC GILD GL GPN GS GWW HAL HBI HOG HIG HAS HCA HCP HP HSIC HSY HES HPE HLT HFC HOLX HD HON HRL HST HPQ HUM HBAN HII IEX IDXX INFO ITW ILMN IR INTC ICE IBM INCY IP IPG IFF INTU ISRG IVZ IPGP IQV IRM JKHY JEC JBHT SJM JNJ JCI JPM JNPR KSU K KEY KEYS KMB KIM KMI KLAC KSS KHC KR LB LHX LH LRCX LW LVS LEG LDOS LEN LLY LNC LIN LKQ LMT L LOW LYB MTB MAC M MRO MPC MKTX MAR MMC MLM MAS MA MKC MXIM MCD MCK MDT MRK MET MTD MGM MCHP MU MSFT MAA MHK TAP MDLZ MNST MCO MS MOS MSI MSCI MYL NDAQ NOV NTAP NFLX NWL NEM NWSA NWS NEE NLSN NKE NI NBL JWN NSC NTRS NOC NCLH NRG NUE NVDA NVR ORLY OXY OMC OKE ORCL PCAR PKG PH PAYX PYPL PNR PBCT PEP PKI PRGO PFE PM PSX PNW PXD PNC PPG PPL PFG PG PGR PLD PRU PEG PSA PHM PVH QRVO PWR QCOM DGX RL RJF RTN O REG REGN RF RSG RMD RHI ROK ROL ROP ROST RCL CRM SBAC SLB STX SEE SRE SHW SPG SWKS SLG SNA SO LUV SPGI SWK SBUX STT SYK STI SIVB SYMC SYF SNPS SYY TMUS TROW TTWO TPR TGT TEL FTI TFX TXN TXT TMO TIF TWTR TJX TSCO TDG TRV TRIP TSN UDR ULTA USB UAA UA UNP UAL UNH UPS URI UTX UHS UNM VFC VLO VAR VTR VRSN VRSK VZ VRTX VIAB V VNO VMC WAB WMT WBA DIS WM WAT WEC WCG WFC WELL WDC WU WRK WY WHR WMB WLTW WYNN XEL XRX XLNX XYL YUM ZBH ZION ZTS\".split(\" \"))\n",
    "num_tickers = len(tickers)\n",
    "num_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl = tickers.index('AAPL'); aapl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2019, 10, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "from datetime import timedelta as Δ\n",
    "\n",
    "time = datetime.now\n",
    "now = time()\n",
    "today = now.date()\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.cwd() / 'data'\n",
    "data_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import executable as python\n",
    "!{python} -m pip install -Uq requests\n",
    "from requests import get as GET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def fetch(date_str, ticker):\n",
    "    out_path = data_dir / ('%s-%s' % (date_str, ticker))\n",
    "    if out_path.exists():\n",
    "        return True\n",
    "\n",
    "    print('Fetching data for %s from %s' % (ticker, date_str))\n",
    "\n",
    "    url = f'https://cloud.iexapis.com/stable/stock/{ticker}/chart/date/{date_str}?token={secret_key}'\n",
    "    resp = GET(url)\n",
    "    resp.raise_for_status()\n",
    "    with out_path.open('wb') as f:\n",
    "        f.write(resp.content)\n",
    "\n",
    "    data = json.loads(resp.content)\n",
    "    if data:\n",
    "        return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.22 s, sys: 387 ms, total: 1.61 s\n",
      "Wall time: 1.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "end_date = today\n",
    "start_date = datetime(2019, 8, 1).date()\n",
    "N = 32\n",
    "\n",
    "def get_dates(start_date, end_date, step=1):\n",
    "    date = start_date\n",
    "    while date != end_date:\n",
    "        if date.weekday() <= 4:\n",
    "            yield date\n",
    "        date += Δ(days=step)\n",
    "\n",
    "dates = list(get_dates(start_date, end_date))\n",
    "\n",
    "for date in dates:\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers = N) as p:\n",
    "        results = p.map(lambda ticker: fetch(date_str, ticker), tickers)\n",
    "    \n",
    "    found_data = True in results\n",
    "    if not found_data:\n",
    "        print('No data found for %s; breaking' % date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{python} -m pip install -Uq pandas\n",
    "from pandas import DataFrame as DF, read_csv, read_json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes = 390  # [9:30am,4:00pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [ 'open', 'close', 'high', 'low', 'average', 'volume', 'notional', 'numberOfTrades' ]\n",
    "cols = [ 'datetime', 'ticker' ] + features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_arr(date, ticker):\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "    out_path = data_dir / ('%s-%s' % (date_str, ticker))\n",
    "    if not out_path.exists():\n",
    "        arr = zeros((minutes, len(features)))\n",
    "        arr[:] = nan\n",
    "        return arr\n",
    "    df = read_json(out_path)\n",
    "    if df.empty:\n",
    "        arr = zeros((minutes, len(features)))\n",
    "        arr[:] = nan\n",
    "        return arr\n",
    "    arr = df[features].values\n",
    "    assert arr.shape == (minutes, len(features))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{python} -m pip install -Uq numpy\n",
    "import numpy as np\n",
    "from numpy import array, nan, zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_date_arr(date):\n",
    "    arr = array([ \n",
    "        load_data_arr(start_date, ticker) \n",
    "        for ticker in tickers \n",
    "    ]) \\\n",
    "    .reshape((\n",
    "        minutes, \n",
    "        len(tickers), \n",
    "        len(features),\n",
    "    ))\n",
    "    assert arr.shape == (minutes, num_tickers, len(features))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{python} -m pip install -Uq joblib\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = \\\n",
    "    array(\n",
    "        Parallel(n_jobs=8)(delayed(load_date_arr)(date) for date in dates)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24960"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 390, 505, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape =  all.shape; shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24960, 505, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = all.reshape(shape[0] * shape[1], *shape[2:]); all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(str(data_dir / 'all.npy'), all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24960, 4040)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = all.shape\n",
    "all = all.reshape(shape[:-2] + ((shape[-2] * shape[-1],)))\n",
    "shape = all.shape\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9792"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np.isnan(all[:, aapl_avg]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15168, 4040)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = all[~np.isnan(all[:, aapl_avg])]\n",
    "shape = all.shape; shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15167,), array([ 91.835, 204.915,  85.943, ...,  61.1  ,  54.221, 138.386]))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_avg = aapl * len(features) + 4\n",
    "out = all[:, aapl_avg]\n",
    "out = np.roll(out, -1)[:-1]\n",
    "all = all[:-1]\n",
    "shape = all.shape\n",
    "out.shape, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randint, shuffle\n",
    "from numpy import arange, nan_to_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 20\n",
    "\n",
    "def make_train_val_idxs(train=None, val=None):\n",
    "    num_samples = shape[0] - time_steps\n",
    "\n",
    "    if train is None and val is None:\n",
    "        raise Exception('Specify at least one of {train, val}')\n",
    "            \n",
    "    if train is not None and train < 1:\n",
    "        train = int(train * num_samples)\n",
    "\n",
    "    if val is not None and val < 1:\n",
    "        val = int(train * num_samples)\n",
    "    \n",
    "    if val is None:\n",
    "        val = num_samples - train\n",
    "    \n",
    "    if train is None:\n",
    "        train = num_samples - val\n",
    "    \n",
    "    if train + val > num_samples:\n",
    "        raise Exception('%d + %d > %d' % (train, val, num_samples))\n",
    "\n",
    "    sample_idxs = arange(time_steps, shape[0])\n",
    "    shuffle(sample_idxs)\n",
    "    training_idxs = sample_idxs[:train]\n",
    "    validation_idxs = sample_idxs[-val:]\n",
    "    return (training_idxs, validation_idxs)\n",
    "\n",
    "def make_train_val_sets(train=None, val=None):\n",
    "    train_idxs, val_idxs = make_train_val_idxs(train, val)\n",
    "    train_x = nan_to_num(array([ all[(idx - time_steps):idx] for idx in train_idxs ]))\n",
    "    train_y = nan_to_num(array([ all[idx][aapl_avg] for idx in train_idxs ]))\n",
    "    val_x = nan_to_num(array([ all[(idx - time_steps):idx] for idx in val_idxs ]))\n",
    "    val_y = nan_to_num(array([ all[idx][aapl_avg] for idx in val_idxs ]))\n",
    "    return (\n",
    "        train_x,\n",
    "        train_y,\n",
    "        val_x,\n",
    "        val_y,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12000, 20, 4040), (12000,), (1000, 20, 4040), (1000,)]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, train_y, val_x, val_y = make_train_val_sets(12000, 1000)\n",
    "[ a.shape for a in [train_x, train_y, val_x, val_y]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15167"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{python} -m pip install -Uq tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    SimpleRNN(32, input_shape=(time_steps, num_tickers * len(features))),\n",
    "    Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_7 (SimpleRNN)     (None, 32)                130336    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 130,369\n",
      "Trainable params: 130,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples\n",
      "Epoch 1/10\n",
      "12000/12000 [==============================] - 18s 1ms/sample - loss: 16344.0626\n",
      "Epoch 2/10\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15546.2652\n",
      "Epoch 3/10\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15530.9598\n",
      "Epoch 4/10\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15515.1891\n",
      "Epoch 5/10\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15502.5735\n",
      "Epoch 6/10\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15523.4275\n",
      "Epoch 7/10\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15517.6569\n",
      "Epoch 8/10\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15560.4271\n",
      "Epoch 9/10\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15538.1058\n",
      "Epoch 10/10\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15486.1096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1270f7f50>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, \n",
    "          #validation_data=(val_x, val_y),\n",
    "          batch_size=40,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples\n",
      "Epoch 1/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15545.4982\n",
      "Epoch 2/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15530.5658\n",
      "Epoch 3/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15478.8371\n",
      "Epoch 4/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15528.6299\n",
      "Epoch 5/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15508.9193\n",
      "Epoch 6/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15532.5590\n",
      "Epoch 7/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15535.9591\n",
      "Epoch 8/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15509.6757\n",
      "Epoch 9/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15512.1479\n",
      "Epoch 10/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15517.8358\n",
      "Epoch 11/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15523.9614\n",
      "Epoch 12/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15518.6465\n",
      "Epoch 13/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15541.3638\n",
      "Epoch 14/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15542.1389\n",
      "Epoch 15/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15507.6170\n",
      "Epoch 16/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15561.0873\n",
      "Epoch 17/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15500.9340\n",
      "Epoch 18/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15539.4070\n",
      "Epoch 19/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15534.0281\n",
      "Epoch 20/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15519.4072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x127084b10>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, \n",
    "          #validation_data=(val_x, val_y),\n",
    "          batch_size=40,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "12000/12000 [==============================] - 19s 2ms/sample - loss: 15419.7773 - val_loss: 15587.0837\n",
      "Epoch 2/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15412.6172 - val_loss: 15572.2574\n",
      "Epoch 3/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15406.8898 - val_loss: 15560.0918\n",
      "Epoch 4/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15402.4290 - val_loss: 15549.7905\n",
      "Epoch 5/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15398.7806 - val_loss: 15541.3923\n",
      "Epoch 6/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15395.8807 - val_loss: 15533.2663\n",
      "Epoch 7/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15393.4201 - val_loss: 15527.3017\n",
      "Epoch 8/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15391.4413 - val_loss: 15521.6040\n",
      "Epoch 9/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15389.8734 - val_loss: 15516.7603\n",
      "Epoch 10/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15388.4959 - val_loss: 15512.9119\n",
      "Epoch 11/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15387.0527 - val_loss: 15509.6008\n",
      "Epoch 12/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15385.9508 - val_loss: 15506.4874\n",
      "Epoch 13/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15384.9699 - val_loss: 15503.6509\n",
      "Epoch 14/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15384.1889 - val_loss: 15501.5730\n",
      "Epoch 15/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15383.2724 - val_loss: 15499.7572\n",
      "Epoch 16/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15382.4708 - val_loss: 15497.3213\n",
      "Epoch 17/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15381.7436 - val_loss: 15496.3086\n",
      "Epoch 18/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15381.1733 - val_loss: 15494.3058\n",
      "Epoch 19/20\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15380.4043 - val_loss: 15493.8809\n",
      "Epoch 20/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15379.8275 - val_loss: 15492.2244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1289c1c50>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, \n",
    "          validation_data=(val_x, val_y),\n",
    "          batch_size=40,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15379.3563 - val_loss: 15491.4467\n",
      "Epoch 2/20\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15378.7538 - val_loss: 15490.7604\n",
      "Epoch 3/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15378.3939 - val_loss: 15489.9805\n",
      "Epoch 4/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15377.8064 - val_loss: 15489.4879\n",
      "Epoch 5/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15377.2507 - val_loss: 15488.4293\n",
      "Epoch 6/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15376.9178 - val_loss: 15488.1877\n",
      "Epoch 7/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15376.4122 - val_loss: 15488.0419\n",
      "Epoch 8/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15375.9355 - val_loss: 15487.4029\n",
      "Epoch 9/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15375.5048 - val_loss: 15486.7018\n",
      "Epoch 10/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15375.1233 - val_loss: 15486.0648\n",
      "Epoch 11/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15374.7382 - val_loss: 15485.7077\n",
      "Epoch 12/20\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15374.4478 - val_loss: 15485.5669\n",
      "Epoch 13/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15374.1843 - val_loss: 15485.6775\n",
      "Epoch 14/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15373.7617 - val_loss: 15485.1194\n",
      "Epoch 15/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15373.3492 - val_loss: 15485.4241\n",
      "Epoch 16/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15373.1051 - val_loss: 15485.3653\n",
      "Epoch 17/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15372.8047 - val_loss: 15484.7645\n",
      "Epoch 18/20\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15372.7339 - val_loss: 15484.8161\n",
      "Epoch 19/20\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15372.2522 - val_loss: 15484.3374\n",
      "Epoch 20/20\n",
      "12000/12000 [==============================] - 22s 2ms/sample - loss: 15371.9052 - val_loss: 15484.4379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12939fbd0>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, \n",
    "          validation_data=(val_x, val_y),\n",
    "          batch_size=40,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 1000 samples\n",
      "Epoch 1/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15371.6789 - val_loss: 15484.1590\n",
      "Epoch 2/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15371.4278 - val_loss: 15484.0324\n",
      "Epoch 3/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15371.1502 - val_loss: 15484.1951\n",
      "Epoch 4/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15370.8957 - val_loss: 15483.6107\n",
      "Epoch 5/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15370.7880 - val_loss: 15483.7685\n",
      "Epoch 6/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15370.4712 - val_loss: 15483.7804\n",
      "Epoch 7/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15370.2009 - val_loss: 15484.2235\n",
      "Epoch 8/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15370.0815 - val_loss: 15483.6573\n",
      "Epoch 9/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15369.8132 - val_loss: 15482.9750\n",
      "Epoch 10/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15369.6613 - val_loss: 15483.3149\n",
      "Epoch 11/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15369.4625 - val_loss: 15484.1132\n",
      "Epoch 12/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15369.3379 - val_loss: 15483.3533\n",
      "Epoch 13/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15369.1234 - val_loss: 15484.1715\n",
      "Epoch 14/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15368.9816 - val_loss: 15483.5499\n",
      "Epoch 15/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15368.8965 - val_loss: 15483.5525\n",
      "Epoch 16/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15368.6454 - val_loss: 15483.6662\n",
      "Epoch 17/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15368.5599 - val_loss: 15483.7138\n",
      "Epoch 18/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15368.3201 - val_loss: 15483.7598\n",
      "Epoch 19/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15368.1804 - val_loss: 15483.7244\n",
      "Epoch 20/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15368.0417 - val_loss: 15484.0882\n",
      "Epoch 21/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15367.8634 - val_loss: 15483.8349\n",
      "Epoch 22/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15367.8055 - val_loss: 15484.6852\n",
      "Epoch 23/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15367.6273 - val_loss: 15484.4225\n",
      "Epoch 24/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15367.4939 - val_loss: 15483.9248\n",
      "Epoch 25/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15367.5515 - val_loss: 15484.5072\n",
      "Epoch 26/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15367.2620 - val_loss: 15484.0268\n",
      "Epoch 27/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15367.1751 - val_loss: 15484.4700\n",
      "Epoch 28/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15367.0119 - val_loss: 15484.5364\n",
      "Epoch 29/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15366.9254 - val_loss: 15484.7621\n",
      "Epoch 30/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15366.7972 - val_loss: 15484.0090\n",
      "Epoch 31/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15366.7314 - val_loss: 15484.5938\n",
      "Epoch 32/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15366.6675 - val_loss: 15484.6505\n",
      "Epoch 33/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15366.5920 - val_loss: 15485.5281\n",
      "Epoch 34/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15366.4706 - val_loss: 15485.0909\n",
      "Epoch 35/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15366.3468 - val_loss: 15484.9207\n",
      "Epoch 36/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15366.3199 - val_loss: 15484.9928\n",
      "Epoch 37/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15366.2021 - val_loss: 15485.0962\n",
      "Epoch 38/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15366.1154 - val_loss: 15485.0625\n",
      "Epoch 39/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15366.0865 - val_loss: 15484.7033\n",
      "Epoch 40/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.9530 - val_loss: 15484.6859\n",
      "Epoch 41/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15365.9066 - val_loss: 15484.9037\n",
      "Epoch 42/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.8852 - val_loss: 15485.7588\n",
      "Epoch 43/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.7198 - val_loss: 15485.7123\n",
      "Epoch 44/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.5846 - val_loss: 15485.8921\n",
      "Epoch 45/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.6091 - val_loss: 15485.8622\n",
      "Epoch 46/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15365.5466 - val_loss: 15485.8209\n",
      "Epoch 47/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.5100 - val_loss: 15486.5755\n",
      "Epoch 48/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.4012 - val_loss: 15486.3164\n",
      "Epoch 49/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.2905 - val_loss: 15486.0742\n",
      "Epoch 50/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.3412 - val_loss: 15486.5615\n",
      "Epoch 51/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.2883 - val_loss: 15486.1326\n",
      "Epoch 52/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.2048 - val_loss: 15486.1915\n",
      "Epoch 53/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.2716 - val_loss: 15486.2800\n",
      "Epoch 54/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15365.0775 - val_loss: 15487.2062\n",
      "Epoch 55/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.0816 - val_loss: 15486.6459\n",
      "Epoch 56/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.0033 - val_loss: 15487.4182\n",
      "Epoch 57/200\n",
      "12000/12000 [==============================] - 18s 1ms/sample - loss: 15364.9730 - val_loss: 15486.9547\n",
      "Epoch 58/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15364.8830 - val_loss: 15486.9924\n",
      "Epoch 59/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.9302 - val_loss: 15488.0205\n",
      "Epoch 60/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.8860 - val_loss: 15487.4170\n",
      "Epoch 61/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15364.7715 - val_loss: 15487.3907\n",
      "Epoch 62/200\n",
      "12000/12000 [==============================] - 20s 2ms/sample - loss: 15364.8262 - val_loss: 15487.7803\n",
      "Epoch 63/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15364.7199 - val_loss: 15488.1130\n",
      "Epoch 64/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.7073 - val_loss: 15487.8657\n",
      "Epoch 65/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15364.5922 - val_loss: 15487.9613\n",
      "Epoch 66/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15364.6650 - val_loss: 15487.8966\n",
      "Epoch 67/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.6510 - val_loss: 15487.7521\n",
      "Epoch 68/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.6147 - val_loss: 15488.2514\n",
      "Epoch 69/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15364.5341 - val_loss: 15488.6650\n",
      "Epoch 70/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.4567 - val_loss: 15487.8361\n",
      "Epoch 71/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.4859 - val_loss: 15488.8021\n",
      "Epoch 72/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15364.5323 - val_loss: 15488.8044\n",
      "Epoch 73/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15364.4228 - val_loss: 15488.7661\n",
      "Epoch 74/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.4240 - val_loss: 15489.0221\n",
      "Epoch 75/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.3305 - val_loss: 15488.6086\n",
      "Epoch 76/200\n",
      "12000/12000 [==============================] - 18s 2ms/sample - loss: 15364.4042 - val_loss: 15489.1560\n",
      "Epoch 77/200\n",
      "12000/12000 [==============================] - 18s 1ms/sample - loss: 15364.1848 - val_loss: 15489.3888\n",
      "Epoch 78/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15364.3073 - val_loss: 15489.8720\n",
      "Epoch 79/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15364.2523 - val_loss: 15489.4412\n",
      "Epoch 80/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15364.1253 - val_loss: 15489.1646\n",
      "Epoch 81/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.1467 - val_loss: 15489.2597\n",
      "Epoch 82/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.2014 - val_loss: 15489.4058\n",
      "Epoch 83/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.2043 - val_loss: 15489.4420\n",
      "Epoch 84/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.0430 - val_loss: 15490.0845\n",
      "Epoch 85/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15364.0453 - val_loss: 15490.0477\n",
      "Epoch 86/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.0640 - val_loss: 15489.8942\n",
      "Epoch 87/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.0791 - val_loss: 15489.7594\n",
      "Epoch 88/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.0414 - val_loss: 15489.8688\n",
      "Epoch 89/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.9893 - val_loss: 15491.1146\n",
      "Epoch 90/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.0469 - val_loss: 15490.1292\n",
      "Epoch 91/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.9962 - val_loss: 15490.6645\n",
      "Epoch 92/200\n",
      "12000/12000 [==============================] - 19s 2ms/sample - loss: 15363.9750 - val_loss: 15490.2653\n",
      "Epoch 93/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15364.0191 - val_loss: 15490.1542\n",
      "Epoch 94/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15364.0085 - val_loss: 15490.3099\n",
      "Epoch 95/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.0008 - val_loss: 15490.1798\n",
      "Epoch 96/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.9550 - val_loss: 15490.5604\n",
      "Epoch 97/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.7946 - val_loss: 15491.2408\n",
      "Epoch 98/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.8231 - val_loss: 15491.2425\n",
      "Epoch 99/200\n",
      "12000/12000 [==============================] - 18s 2ms/sample - loss: 15363.8095 - val_loss: 15491.2521\n",
      "Epoch 100/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.9265 - val_loss: 15491.5680\n",
      "Epoch 101/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.7955 - val_loss: 15491.9384\n",
      "Epoch 102/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.7687 - val_loss: 15491.2110\n",
      "Epoch 103/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.8176 - val_loss: 15492.2268\n",
      "Epoch 104/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.6955 - val_loss: 15491.3702\n",
      "Epoch 105/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.7407 - val_loss: 15491.8358\n",
      "Epoch 106/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.6801 - val_loss: 15492.1043\n",
      "Epoch 107/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.7715 - val_loss: 15491.4440\n",
      "Epoch 108/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.7181 - val_loss: 15491.8456\n",
      "Epoch 109/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.7679 - val_loss: 15492.1118\n",
      "Epoch 110/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.6826 - val_loss: 15492.3659\n",
      "Epoch 111/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.7242 - val_loss: 15492.4152\n",
      "Epoch 112/200\n",
      "12000/12000 [==============================] - 18s 2ms/sample - loss: 15363.6951 - val_loss: 15493.2859\n",
      "Epoch 113/200\n",
      "12000/12000 [==============================] - 20s 2ms/sample - loss: 15363.6332 - val_loss: 15492.0758\n",
      "Epoch 114/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.7628 - val_loss: 15492.5307\n",
      "Epoch 115/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.6426 - val_loss: 15492.5631\n",
      "Epoch 116/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.6874 - val_loss: 15492.9209\n",
      "Epoch 117/200\n",
      "12000/12000 [==============================] - 18s 1ms/sample - loss: 15363.6634 - val_loss: 15492.7098\n",
      "Epoch 118/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.6470 - val_loss: 15492.3780\n",
      "Epoch 119/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.5755 - val_loss: 15493.2647\n",
      "Epoch 120/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.5610 - val_loss: 15492.6952\n",
      "Epoch 121/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.5847 - val_loss: 15493.7637\n",
      "Epoch 122/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.5152 - val_loss: 15493.1302\n",
      "Epoch 123/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.6426 - val_loss: 15493.8497\n",
      "Epoch 124/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.6164 - val_loss: 15493.7640\n",
      "Epoch 125/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.7003 - val_loss: 15492.6092\n",
      "Epoch 126/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.6629 - val_loss: 15493.5451\n",
      "Epoch 127/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.7010 - val_loss: 15493.1428\n",
      "Epoch 128/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.4990 - val_loss: 15493.2272\n",
      "Epoch 129/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.5227 - val_loss: 15493.6791\n",
      "Epoch 130/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.5284 - val_loss: 15493.5030\n",
      "Epoch 131/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.5364 - val_loss: 15493.8812\n",
      "Epoch 132/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.6192 - val_loss: 15493.9941\n",
      "Epoch 133/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.6177 - val_loss: 15493.3013\n",
      "Epoch 134/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.6193 - val_loss: 15493.5246\n",
      "Epoch 135/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.5487 - val_loss: 15494.4170\n",
      "Epoch 136/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.4950 - val_loss: 15494.5055\n",
      "Epoch 137/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3594 - val_loss: 15494.6568\n",
      "Epoch 138/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.5039 - val_loss: 15494.9066\n",
      "Epoch 139/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.5146 - val_loss: 15493.8905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.4934 - val_loss: 15494.7523\n",
      "Epoch 141/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3948 - val_loss: 15494.3557\n",
      "Epoch 142/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.4620 - val_loss: 15495.2337\n",
      "Epoch 143/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.4224 - val_loss: 15494.8069\n",
      "Epoch 144/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.4144 - val_loss: 15494.9970\n",
      "Epoch 145/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.4223 - val_loss: 15495.0199\n",
      "Epoch 146/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.4744 - val_loss: 15495.5698\n",
      "Epoch 147/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3751 - val_loss: 15494.8303\n",
      "Epoch 148/200\n",
      "12000/12000 [==============================] - 19s 2ms/sample - loss: 15363.4290 - val_loss: 15495.0324\n",
      "Epoch 149/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.3788 - val_loss: 15495.3106\n",
      "Epoch 150/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3796 - val_loss: 15495.0147\n",
      "Epoch 151/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3762 - val_loss: 15495.1361\n",
      "Epoch 152/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.4002 - val_loss: 15494.7084\n",
      "Epoch 153/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3733 - val_loss: 15495.3746\n",
      "Epoch 154/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3760 - val_loss: 15495.9733\n",
      "Epoch 155/200\n",
      "12000/12000 [==============================] - 18s 1ms/sample - loss: 15363.3704 - val_loss: 15495.4700\n",
      "Epoch 156/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.4479 - val_loss: 15495.5818\n",
      "Epoch 157/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.4128 - val_loss: 15495.4421\n",
      "Epoch 158/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.4167 - val_loss: 15494.9213\n",
      "Epoch 159/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.4127 - val_loss: 15495.7243\n",
      "Epoch 160/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3238 - val_loss: 15495.5377\n",
      "Epoch 161/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3957 - val_loss: 15496.4208\n",
      "Epoch 162/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.4137 - val_loss: 15495.5683\n",
      "Epoch 163/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3438 - val_loss: 15495.7751\n",
      "Epoch 164/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3569 - val_loss: 15495.5899\n",
      "Epoch 165/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2598 - val_loss: 15495.6927\n",
      "Epoch 166/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.5380 - val_loss: 15495.9599\n",
      "Epoch 167/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3724 - val_loss: 15495.6699\n",
      "Epoch 168/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3303 - val_loss: 15496.2546\n",
      "Epoch 169/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.4383 - val_loss: 15495.8824\n",
      "Epoch 170/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.4371 - val_loss: 15496.4429\n",
      "Epoch 171/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3343 - val_loss: 15496.1940\n",
      "Epoch 172/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3407 - val_loss: 15496.3231\n",
      "Epoch 173/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.4285 - val_loss: 15496.3053\n",
      "Epoch 174/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2681 - val_loss: 15496.4063\n",
      "Epoch 175/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3369 - val_loss: 15496.2381\n",
      "Epoch 176/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3454 - val_loss: 15496.4258\n",
      "Epoch 177/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3479 - val_loss: 15497.2161\n",
      "Epoch 178/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2949 - val_loss: 15496.4778\n",
      "Epoch 179/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2682 - val_loss: 15497.1458\n",
      "Epoch 180/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3693 - val_loss: 15496.5148\n",
      "Epoch 181/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3856 - val_loss: 15496.7098\n",
      "Epoch 182/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2492 - val_loss: 15496.5529\n",
      "Epoch 183/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3478 - val_loss: 15497.1580\n",
      "Epoch 184/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2718 - val_loss: 15496.9531\n",
      "Epoch 185/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3173 - val_loss: 15497.1014\n",
      "Epoch 186/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2959 - val_loss: 15497.0138\n",
      "Epoch 187/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3931 - val_loss: 15497.3296\n",
      "Epoch 188/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3893 - val_loss: 15497.1907\n",
      "Epoch 189/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2284 - val_loss: 15497.0637\n",
      "Epoch 190/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2770 - val_loss: 15496.7870\n",
      "Epoch 191/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3897 - val_loss: 15497.0820\n",
      "Epoch 192/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.4221 - val_loss: 15496.4670\n",
      "Epoch 193/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.1928 - val_loss: 15497.0653\n",
      "Epoch 194/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3465 - val_loss: 15496.9933\n",
      "Epoch 195/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2698 - val_loss: 15497.0039\n",
      "Epoch 196/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3350 - val_loss: 15498.0570\n",
      "Epoch 197/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3492 - val_loss: 15496.9771\n",
      "Epoch 198/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.1619 - val_loss: 15497.2436\n",
      "Epoch 199/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2072 - val_loss: 15497.1660\n",
      "Epoch 200/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2826 - val_loss: 15497.1246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x128965790>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, \n",
    "          validation_data=(val_x, val_y),\n",
    "          batch_size=40,\n",
    "          epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12392.3727\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 14s 1ms/sample - loss: 12332.7983\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 16s 2ms/sample - loss: 12362.4786\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12381.8192\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12341.3580\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12337.6320\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12358.0993\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12322.7205\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12390.4263\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12381.1204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x126945dd0>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, \n",
    "          batch_size=10,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 16s 2ms/sample - loss: 12356.6821\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12356.3212\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12393.1001\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12219.4047\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12299.5797\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12324.0439\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12323.7565\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12325.0019\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12394.5230\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12326.8734\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12363.2107\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 17s 2ms/sample - loss: 12362.7202\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12406.3008\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12312.1227\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12358.4351\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12372.3430\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12337.8851\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 16s 2ms/sample - loss: 12331.7085\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12399.3326\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 16s 2ms/sample - loss: 12380.6395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x126c5fd90>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, \n",
    "          batch_size=10,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.46147427, 0.4936299 , 0.7725021 , 0.18668415, 0.19160269,\n",
       "        0.5329875 , 0.89422435, 0.8431803 , 0.45767853, 0.9006393 ,\n",
       "        0.30371124, 0.8654656 , 0.64627594, 0.2774724 , 0.34715426,\n",
       "        0.7767715 , 0.08706174, 0.9893154 , 0.6400852 , 0.9627552 ,\n",
       "        0.50067353, 0.56687176, 0.48472205, 0.6378169 , 0.6819773 ,\n",
       "        0.6446982 , 0.13012254, 0.27104077, 0.50481087, 0.25702876,\n",
       "        0.59998226, 0.45324805, 0.50154966, 0.43757737, 0.66555214,\n",
       "        0.9135334 , 0.7003318 , 0.23003371, 0.05756523, 0.49323606,\n",
       "        0.75259066, 0.6157169 , 0.6374104 , 0.5707051 , 0.6783405 ,\n",
       "        0.89434326, 0.8651092 , 0.9301288 , 0.586712  , 0.7044457 ,\n",
       "        0.7020338 , 0.09967529, 0.7703017 , 0.85118467, 0.14892976,\n",
       "        0.24892834, 0.2034809 , 0.26588657, 0.05641429, 0.03270473,\n",
       "        0.73204887, 0.9724218 , 0.31882647, 0.17593206, 0.7806721 ,\n",
       "        0.96902066, 0.84500116, 0.7622705 , 0.00976924, 0.772007  ,\n",
       "        0.31686476, 0.95740134, 0.16487914, 0.99371856, 0.77002376,\n",
       "        0.0585487 , 0.30136323, 0.05418719, 0.02097294, 0.8098558 ,\n",
       "        0.9993328 , 0.9676906 , 0.8079357 , 0.07865059, 0.7572921 ,\n",
       "        0.00712246, 0.6570062 , 0.316152  , 0.00867406, 0.6616431 ,\n",
       "        0.25412577, 0.3306162 , 0.14759275, 0.13746355, 0.02187528,\n",
       "        0.1780793 , 0.6548838 , 0.15741996, 0.94479674, 0.16080537],\n",
       "       dtype=float32),\n",
       " array([0.7818266 , 0.44980854, 0.65075845, 0.17491417, 0.5047283 ,\n",
       "        0.16106072, 0.5499607 , 0.8744731 , 0.6006628 , 0.8955531 ,\n",
       "        0.12414642, 0.68526095, 0.6667509 , 0.11806473, 0.359241  ,\n",
       "        0.6119286 , 0.8484664 , 0.68293065, 0.9550282 , 0.9045459 ,\n",
       "        0.88269144, 0.27150008, 0.4650287 , 0.8676415 , 0.5026252 ,\n",
       "        0.42452398, 0.8481062 , 0.15626116, 0.36071396, 0.42584082,\n",
       "        0.12930751, 0.26520145, 0.6903245 , 0.84599334, 0.13224092,\n",
       "        0.37767032, 0.97641206, 0.96301776, 0.21939163, 0.05385643,\n",
       "        0.4527225 , 0.9724792 , 0.3342038 , 0.6168115 , 0.3395587 ,\n",
       "        0.43398395, 0.9803608 , 0.7955412 , 0.23625055, 0.23964162,\n",
       "        0.02104023, 0.40777066, 0.94194674, 0.9913477 , 0.04047493,\n",
       "        0.5572203 , 0.06472664, 0.64436775, 0.24161713, 0.7522351 ,\n",
       "        0.892538  , 0.08331183, 0.26689017, 0.7610726 , 0.8750384 ,\n",
       "        0.99299073, 0.91673225, 0.7365139 , 0.9257179 , 0.5206772 ,\n",
       "        0.5923702 , 0.5963442 , 0.39472255, 0.25320303, 0.9780684 ,\n",
       "        0.2298456 , 0.43313423, 0.00417769, 0.3118336 , 0.7907522 ,\n",
       "        0.09478721, 0.30305177, 0.40730244, 0.8591287 , 0.7661657 ,\n",
       "        0.5432202 , 0.48406875, 0.77418864, 0.1522045 , 0.29970375,\n",
       "        0.35280573, 0.20427185, 0.8599315 , 0.6667513 , 0.81909835,\n",
       "        0.48030037, 0.43726304, 0.92959535, 0.6319735 , 0.87687695],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = random((100,)).astype(np.float32)\n",
    "train_y = random((100,)).astype(np.float32)\n",
    "train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    SimpleRNN(10, input_shape=(10, 1)),\n",
    "    Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_4 (SimpleRNN)     (None, 10)                120       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.46147427],\n",
       "        [0.4936299 ],\n",
       "        [0.7725021 ],\n",
       "        [0.18668415],\n",
       "        [0.19160269],\n",
       "        [0.5329875 ],\n",
       "        [0.89422435],\n",
       "        [0.8431803 ],\n",
       "        [0.45767853],\n",
       "        [0.9006393 ]],\n",
       "\n",
       "       [[0.30371124],\n",
       "        [0.8654656 ],\n",
       "        [0.64627594],\n",
       "        [0.2774724 ],\n",
       "        [0.34715426],\n",
       "        [0.7767715 ],\n",
       "        [0.08706174],\n",
       "        [0.9893154 ],\n",
       "        [0.6400852 ],\n",
       "        [0.9627552 ]],\n",
       "\n",
       "       [[0.50067353],\n",
       "        [0.56687176],\n",
       "        [0.48472205],\n",
       "        [0.6378169 ],\n",
       "        [0.6819773 ],\n",
       "        [0.6446982 ],\n",
       "        [0.13012254],\n",
       "        [0.27104077],\n",
       "        [0.50481087],\n",
       "        [0.25702876]],\n",
       "\n",
       "       [[0.59998226],\n",
       "        [0.45324805],\n",
       "        [0.50154966],\n",
       "        [0.43757737],\n",
       "        [0.66555214],\n",
       "        [0.9135334 ],\n",
       "        [0.7003318 ],\n",
       "        [0.23003371],\n",
       "        [0.05756523],\n",
       "        [0.49323606]],\n",
       "\n",
       "       [[0.75259066],\n",
       "        [0.6157169 ],\n",
       "        [0.6374104 ],\n",
       "        [0.5707051 ],\n",
       "        [0.6783405 ],\n",
       "        [0.89434326],\n",
       "        [0.8651092 ],\n",
       "        [0.9301288 ],\n",
       "        [0.586712  ],\n",
       "        [0.7044457 ]],\n",
       "\n",
       "       [[0.7020338 ],\n",
       "        [0.09967529],\n",
       "        [0.7703017 ],\n",
       "        [0.85118467],\n",
       "        [0.14892976],\n",
       "        [0.24892834],\n",
       "        [0.2034809 ],\n",
       "        [0.26588657],\n",
       "        [0.05641429],\n",
       "        [0.03270473]],\n",
       "\n",
       "       [[0.73204887],\n",
       "        [0.9724218 ],\n",
       "        [0.31882647],\n",
       "        [0.17593206],\n",
       "        [0.7806721 ],\n",
       "        [0.96902066],\n",
       "        [0.84500116],\n",
       "        [0.7622705 ],\n",
       "        [0.00976924],\n",
       "        [0.772007  ]],\n",
       "\n",
       "       [[0.31686476],\n",
       "        [0.95740134],\n",
       "        [0.16487914],\n",
       "        [0.99371856],\n",
       "        [0.77002376],\n",
       "        [0.0585487 ],\n",
       "        [0.30136323],\n",
       "        [0.05418719],\n",
       "        [0.02097294],\n",
       "        [0.8098558 ]],\n",
       "\n",
       "       [[0.9993328 ],\n",
       "        [0.9676906 ],\n",
       "        [0.8079357 ],\n",
       "        [0.07865059],\n",
       "        [0.7572921 ],\n",
       "        [0.00712246],\n",
       "        [0.6570062 ],\n",
       "        [0.316152  ],\n",
       "        [0.00867406],\n",
       "        [0.6616431 ]],\n",
       "\n",
       "       [[0.25412577],\n",
       "        [0.3306162 ],\n",
       "        [0.14759275],\n",
       "        [0.13746355],\n",
       "        [0.02187528],\n",
       "        [0.1780793 ],\n",
       "        [0.6548838 ],\n",
       "        [0.15741996],\n",
       "        [0.94479674],\n",
       "        [0.16080537]]], dtype=float32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.reshape(10, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10 samples\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 1693.9922\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 593us/sample - loss: 1245.9900\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 475us/sample - loss: 963.2513\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 502us/sample - loss: 778.3412\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 483us/sample - loss: 666.6307\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 707us/sample - loss: 877.8005\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 611us/sample - loss: 580.0933\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 693us/sample - loss: 1129.6672\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 753us/sample - loss: 948.7717\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 786us/sample - loss: 719.8773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1253a7f50>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x.reshape(10, 10, 1) * 100, train_y[:10] * 100, \n",
    "          batch_size=10,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks-3.7.4",
   "language": "python",
   "name": "notebooks-3.7.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
