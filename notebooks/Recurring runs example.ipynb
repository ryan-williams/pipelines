{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Periodic download of IEX stock-ticker data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read IEX API credentials from `~/.config/iex.ini`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "config_path = Path.home() / '.config' / 'iex.ini'\n",
    "\n",
    "from configparser import ConfigParser\n",
    "config = ConfigParser()\n",
    "config.read(str(config_path))\n",
    "iex_config = config['iex']\n",
    "\n",
    "api = 'https://cloud.iexapis.com'\n",
    "public_key = iex_config['public_key']\n",
    "secret_key = iex_config['secret_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers = sorted(\"MMM ABT ABBV ABMD ACN ATVI ADBE AMD AAP AES AMG AFL A APD AKAM ALK ALB ARE ALXN ALGN ALLE AGN ADS LNT ALL GOOGL GOOG MO AMZN AMCR AEE AAL AEP AXP AIG AMT AWK AMP ABC AME AMGN APH ADI ANSS ANTM AON AOS APA AIV AAPL AMAT APTV ADM ARNC ANET AJG AIZ ATO T ADSK ADP AZO AVB AVY BKR BLL BAC BK BAX BBT BDX BRK.B BBY BIIB BLK HRB BA BKNG BWA BXP BSX BMY AVGO BR BF.B CHRW COG CDNS CPB COF CPRI CAH KMX CCL CAT CBOE CBRE CBS CDW CE CELG CNC CNP CTL CERN CF SCHW CHTR CVX CMG CB CHD CI XEC CINF CTAS CSCO C CFG CTXS CLX CME CMS KO CTSH CL CMCSA CMA CAG CXO COP ED STZ COO CPRT GLW CTVA COST COTY CCI CSX CMI CVS DHI DHR DRI DVA DE DAL XRAY DVN FANG DLR DFS DISCA DISCK DISH DG DLTR D DOV DOW DTE DUK DRE DD DXC ETFC EMN ETN EBAY ECL EIX EW EA EMR ETR EOG EFX EQIX EQR ESS EL EVRG ES RE EXC EXPE EXPD EXR XOM FFIV FB FAST FRT FDX FIS FITB FE FRC FISV FLT FLIR FLS FMC F FTNT FTV FBHS FOXA FOX BEN FCX GPS GRMN IT GD GE GIS GM GPC GILD GL GPN GS GWW HAL HBI HOG HIG HAS HCA HCP HP HSIC HSY HES HPE HLT HFC HOLX HD HON HRL HST HPQ HUM HBAN HII IEX IDXX INFO ITW ILMN IR INTC ICE IBM INCY IP IPG IFF INTU ISRG IVZ IPGP IQV IRM JKHY JEC JBHT SJM JNJ JCI JPM JNPR KSU K KEY KEYS KMB KIM KMI KLAC KSS KHC KR LB LHX LH LRCX LW LVS LEG LDOS LEN LLY LNC LIN LKQ LMT L LOW LYB MTB MAC M MRO MPC MKTX MAR MMC MLM MAS MA MKC MXIM MCD MCK MDT MRK MET MTD MGM MCHP MU MSFT MAA MHK TAP MDLZ MNST MCO MS MOS MSI MSCI MYL NDAQ NOV NTAP NFLX NWL NEM NWSA NWS NEE NLSN NKE NI NBL JWN NSC NTRS NOC NCLH NRG NUE NVDA NVR ORLY OXY OMC OKE ORCL PCAR PKG PH PAYX PYPL PNR PBCT PEP PKI PRGO PFE PM PSX PNW PXD PNC PPG PPL PFG PG PGR PLD PRU PEG PSA PHM PVH QRVO PWR QCOM DGX RL RJF RTN O REG REGN RF RSG RMD RHI ROK ROL ROP ROST RCL CRM SBAC SLB STX SEE SRE SHW SPG SWKS SLG SNA SO LUV SPGI SWK SBUX STT SYK STI SIVB SYMC SYF SNPS SYY TMUS TROW TTWO TPR TGT TEL FTI TFX TXN TXT TMO TIF TWTR TJX TSCO TDG TRV TRIP TSN UDR ULTA USB UAA UA UNP UAL UNH UPS URI UTX UHS UNM VFC VLO VAR VTR VRSN VRSK VZ VRTX VIAB V VNO VMC WAB WMT WBA DIS WM WAT WEC WCG WFC WELL WDC WU WRK WY WHR WMB WLTW WYNN XEL XRX XLNX XYL YUM ZBH ZION ZTS\".split(\" \"))\n",
    "num_tickers = len(tickers)\n",
    "num_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl = tickers.index('AAPL'); aapl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2019, 10, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "from datetime import timedelta as Δ\n",
    "\n",
    "time = datetime.now\n",
    "now = time()\n",
    "today = now.date()\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.cwd() / 'data'\n",
    "data_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import executable as python\n",
    "!{python} -m pip install -Uq requests\n",
    "from requests import get as GET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def fetch(date_str, ticker):\n",
    "    out_path = data_dir / ('%s-%s' % (date_str, ticker))\n",
    "    if out_path.exists():\n",
    "        return True\n",
    "\n",
    "    print('Fetching data for %s from %s' % (ticker, date_str))\n",
    "\n",
    "    url = f'https://cloud.iexapis.com/stable/stock/{ticker}/chart/date/{date_str}?token={secret_key}'\n",
    "    resp = GET(url)\n",
    "    resp.raise_for_status()\n",
    "    with out_path.open('wb') as f:\n",
    "        f.write(resp.content)\n",
    "\n",
    "    data = json.loads(resp.content)\n",
    "    if data:\n",
    "        return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.22 s, sys: 387 ms, total: 1.61 s\n",
      "Wall time: 1.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "end_date = today\n",
    "start_date = datetime(2019, 8, 1).date()\n",
    "N = 32\n",
    "\n",
    "def get_dates(start_date, end_date, step=1):\n",
    "    date = start_date\n",
    "    while date != end_date:\n",
    "        if date.weekday() <= 4:\n",
    "            yield date\n",
    "        date += Δ(days=step)\n",
    "\n",
    "dates = list(get_dates(start_date, end_date))\n",
    "\n",
    "for date in dates:\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers = N) as p:\n",
    "        results = p.map(lambda ticker: fetch(date_str, ticker), tickers)\n",
    "    \n",
    "    found_data = True in results\n",
    "    if not found_data:\n",
    "        print('No data found for %s; breaking' % date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{python} -m pip install -Uq pandas\n",
    "from pandas import DataFrame as DF, read_csv, read_json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes = 390  # [9:30am,4:00pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [ 'open', 'close', 'high', 'low', 'average', 'volume', 'notional', 'numberOfTrades' ]\n",
    "cols = [ 'datetime', 'ticker' ] + features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_arr(date, ticker):\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "    out_path = data_dir / ('%s-%s' % (date_str, ticker))\n",
    "    if not out_path.exists():\n",
    "        arr = zeros((minutes, len(features)))\n",
    "        arr[:] = nan\n",
    "        return arr\n",
    "    df = read_json(out_path)\n",
    "    if df.empty:\n",
    "        arr = zeros((minutes, len(features)))\n",
    "        arr[:] = nan\n",
    "        return arr\n",
    "    arr = df[features].values\n",
    "    assert arr.shape == (minutes, len(features))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{python} -m pip install -Uq numpy\n",
    "import numpy as np\n",
    "from numpy import array, nan, zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_date_arr(date):\n",
    "    arr = array([ \n",
    "        load_data_arr(start_date, ticker) \n",
    "        for ticker in tickers \n",
    "    ]) \\\n",
    "    .reshape((\n",
    "        minutes, \n",
    "        len(tickers), \n",
    "        len(features),\n",
    "    ))\n",
    "    assert arr.shape == (minutes, num_tickers, len(features))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{python} -m pip install -Uq joblib\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import count_nonzero as cnz, isnan as na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'AAPL'\n",
    "num_tickers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 390, 8)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl = array([ load_data_arr(date, ticker) for date in dates ]); aapl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24960,)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = aapl.shape\n",
    "aapl = aapl.reshape((shape[0] * shape[1], shape[2]))\n",
    "aapl = aapl[:, 4]\n",
    "shape = aapl.shape; shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24959,), (24959,))"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.roll(avgs, -1)\n",
    "y = y[:-1]\n",
    "x = aapl[:-1]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24939, 20), (24939,))"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window = 20\n",
    "n = x.shape[0]\n",
    "x = np.array([ x[i:(i+window)] for i in range(n-window) ])\n",
    "y = y[window:]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18463, 20), (18463,))"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = np.logical_and([ (cnz(na(row)) == 0) for row in x ], ~na(y))\n",
    "y = y[idxs]\n",
    "x = x[idxs]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18463, 20), (18463,))"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181.3834607423043"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = aapl[~na(aapl)]\n",
    "u = np.mean(vals)\n",
    "mean((vals-u)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213.7095086060606, 10.457293365325054, 109.35498452847138)"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(ty), std(ty), mean((ty-mean(ty))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = x.shape[0]\n",
    "val = 1963\n",
    "trn = n - val\n",
    "tx, ty = x[:trn], y[:trn]\n",
    "vx, vy = x[trn:], y[trn:]\n",
    "tx = tx.reshape(tx.shape + (1,))\n",
    "vx = vx.reshape(vx.shape + (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_17 (SimpleRNN)    (None, 8)                 80        \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(window, 1)),\n",
    "    SimpleRNN(8, input_shape=(window, 1)),\n",
    "    Dense(1),\n",
    "])\n",
    "model.build()\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/40\n",
      "16500/16500 [==============================] - 9s 560us/sample - loss: 44777.7019 - val_loss: 55744.5477\n",
      "Epoch 2/40\n",
      "16500/16500 [==============================] - 2s 93us/sample - loss: 43538.8645 - val_loss: 54364.1220\n",
      "Epoch 3/40\n",
      "16500/16500 [==============================] - 2s 92us/sample - loss: 42324.5288 - val_loss: 53008.3513\n",
      "Epoch 4/40\n",
      "16500/16500 [==============================] - 2s 91us/sample - loss: 41133.7890 - val_loss: 51676.5793\n",
      "Epoch 5/40\n",
      "16500/16500 [==============================] - 2s 94us/sample - loss: 39965.6380 - val_loss: 50367.6317\n",
      "Epoch 6/40\n",
      "16500/16500 [==============================] - 2s 92us/sample - loss: 38819.1267 - val_loss: 49080.4976\n",
      "Epoch 7/40\n",
      "16500/16500 [==============================] - 2s 105us/sample - loss: 37693.4104 - val_loss: 47814.1664\n",
      "Epoch 8/40\n",
      "16500/16500 [==============================] - 2s 93us/sample - loss: 36587.8074 - val_loss: 46568.1162\n",
      "Epoch 9/40\n",
      "16500/16500 [==============================] - 2s 94us/sample - loss: 35501.7509 - val_loss: 45341.7070\n",
      "Epoch 10/40\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 34434.6582 - val_loss: 44134.4939\n",
      "Epoch 11/40\n",
      "16500/16500 [==============================] - 2s 104us/sample - loss: 33386.0666 - val_loss: 42945.8087\n",
      "Epoch 12/40\n",
      "16500/16500 [==============================] - 2s 94us/sample - loss: 32355.6962 - val_loss: 41775.4714\n",
      "Epoch 13/40\n",
      "16500/16500 [==============================] - 2s 104us/sample - loss: 31343.2365 - val_loss: 40623.1114\n",
      "Epoch 14/40\n",
      "16500/16500 [==============================] - 2s 106us/sample - loss: 30348.3753 - val_loss: 39488.4922\n",
      "Epoch 15/40\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 29370.9018 - val_loss: 38371.3493\n",
      "Epoch 16/40\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 28410.6840 - val_loss: 37271.5314\n",
      "Epoch 17/40\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 27467.6498 - val_loss: 36189.0228\n",
      "Epoch 18/40\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 26541.6872 - val_loss: 35123.8418\n",
      "Epoch 19/40\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 25632.6869 - val_loss: 34075.4282\n",
      "Epoch 20/40\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 24740.5484 - val_loss: 33044.3347\n",
      "Epoch 21/40\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 23865.1421 - val_loss: 32029.8978\n",
      "Epoch 22/40\n",
      "16500/16500 [==============================] - 2s 106us/sample - loss: 23006.4783 - val_loss: 31032.4024\n",
      "Epoch 23/40\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 22164.4996 - val_loss: 30051.7610\n",
      "Epoch 24/40\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 21339.1733 - val_loss: 29087.9148\n",
      "Epoch 25/40\n",
      "16500/16500 [==============================] - 2s 103us/sample - loss: 20530.4188 - val_loss: 28140.7378\n",
      "Epoch 26/40\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 19738.3079 - val_loss: 27210.3642\n",
      "Epoch 27/40\n",
      "16500/16500 [==============================] - 2s 107us/sample - loss: 18962.7907 - val_loss: 26296.7988\n",
      "Epoch 28/40\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 18203.7872 - val_loss: 25399.7772\n",
      "Epoch 29/40\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 17461.3033 - val_loss: 24519.5713\n",
      "Epoch 30/40\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 16735.2722 - val_loss: 23656.0203\n",
      "Epoch 31/40\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 16025.6794 - val_loss: 22808.9693\n",
      "Epoch 32/40\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 15332.5033 - val_loss: 21978.5595\n",
      "Epoch 33/40\n",
      "16500/16500 [==============================] - 2s 107us/sample - loss: 14655.7264 - val_loss: 21164.8550\n",
      "Epoch 34/40\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 13995.3403 - val_loss: 20367.7251\n",
      "Epoch 35/40\n",
      "16500/16500 [==============================] - 2s 93us/sample - loss: 13351.2482 - val_loss: 19586.8518\n",
      "Epoch 36/40\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 12723.4752 - val_loss: 18822.9409\n",
      "Epoch 37/40\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 12112.0613 - val_loss: 18075.2573\n",
      "Epoch 38/40\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 11516.8592 - val_loss: 17344.1339\n",
      "Epoch 39/40\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 10937.7834 - val_loss: 16629.4722\n",
      "Epoch 40/40\n",
      "16500/16500 [==============================] - 2s 119us/sample - loss: 10374.9092 - val_loss: 15931.1644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x5bec28410>"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[235.622],\n",
       "        [235.671],\n",
       "        [235.688],\n",
       "        [235.73 ],\n",
       "        [235.936],\n",
       "        [236.08 ],\n",
       "        [236.042],\n",
       "        [236.059],\n",
       "        [235.961],\n",
       "        [236.   ],\n",
       "        [235.96 ],\n",
       "        [235.901],\n",
       "        [235.8  ],\n",
       "        [235.785],\n",
       "        [235.82 ],\n",
       "        [235.759],\n",
       "        [235.761],\n",
       "        [235.7  ],\n",
       "        [235.585],\n",
       "        [235.639]],\n",
       "\n",
       "       [[235.671],\n",
       "        [235.688],\n",
       "        [235.73 ],\n",
       "        [235.936],\n",
       "        [236.08 ],\n",
       "        [236.042],\n",
       "        [236.059],\n",
       "        [235.961],\n",
       "        [236.   ],\n",
       "        [235.96 ],\n",
       "        [235.901],\n",
       "        [235.8  ],\n",
       "        [235.785],\n",
       "        [235.82 ],\n",
       "        [235.759],\n",
       "        [235.761],\n",
       "        [235.7  ],\n",
       "        [235.585],\n",
       "        [235.639],\n",
       "        [235.735]],\n",
       "\n",
       "       [[235.688],\n",
       "        [235.73 ],\n",
       "        [235.936],\n",
       "        [236.08 ],\n",
       "        [236.042],\n",
       "        [236.059],\n",
       "        [235.961],\n",
       "        [236.   ],\n",
       "        [235.96 ],\n",
       "        [235.901],\n",
       "        [235.8  ],\n",
       "        [235.785],\n",
       "        [235.82 ],\n",
       "        [235.759],\n",
       "        [235.761],\n",
       "        [235.7  ],\n",
       "        [235.585],\n",
       "        [235.639],\n",
       "        [235.735],\n",
       "        [235.745]],\n",
       "\n",
       "       [[235.73 ],\n",
       "        [235.936],\n",
       "        [236.08 ],\n",
       "        [236.042],\n",
       "        [236.059],\n",
       "        [235.961],\n",
       "        [236.   ],\n",
       "        [235.96 ],\n",
       "        [235.901],\n",
       "        [235.8  ],\n",
       "        [235.785],\n",
       "        [235.82 ],\n",
       "        [235.759],\n",
       "        [235.761],\n",
       "        [235.7  ],\n",
       "        [235.585],\n",
       "        [235.639],\n",
       "        [235.735],\n",
       "        [235.745],\n",
       "        [235.711]],\n",
       "\n",
       "       [[235.936],\n",
       "        [236.08 ],\n",
       "        [236.042],\n",
       "        [236.059],\n",
       "        [235.961],\n",
       "        [236.   ],\n",
       "        [235.96 ],\n",
       "        [235.901],\n",
       "        [235.8  ],\n",
       "        [235.785],\n",
       "        [235.82 ],\n",
       "        [235.759],\n",
       "        [235.761],\n",
       "        [235.7  ],\n",
       "        [235.585],\n",
       "        [235.639],\n",
       "        [235.735],\n",
       "        [235.745],\n",
       "        [235.711],\n",
       "        [235.696]],\n",
       "\n",
       "       [[236.08 ],\n",
       "        [236.042],\n",
       "        [236.059],\n",
       "        [235.961],\n",
       "        [236.   ],\n",
       "        [235.96 ],\n",
       "        [235.901],\n",
       "        [235.8  ],\n",
       "        [235.785],\n",
       "        [235.82 ],\n",
       "        [235.759],\n",
       "        [235.761],\n",
       "        [235.7  ],\n",
       "        [235.585],\n",
       "        [235.639],\n",
       "        [235.735],\n",
       "        [235.745],\n",
       "        [235.711],\n",
       "        [235.696],\n",
       "        [235.765]],\n",
       "\n",
       "       [[236.042],\n",
       "        [236.059],\n",
       "        [235.961],\n",
       "        [236.   ],\n",
       "        [235.96 ],\n",
       "        [235.901],\n",
       "        [235.8  ],\n",
       "        [235.785],\n",
       "        [235.82 ],\n",
       "        [235.759],\n",
       "        [235.761],\n",
       "        [235.7  ],\n",
       "        [235.585],\n",
       "        [235.639],\n",
       "        [235.735],\n",
       "        [235.745],\n",
       "        [235.711],\n",
       "        [235.696],\n",
       "        [235.765],\n",
       "        [235.766]],\n",
       "\n",
       "       [[236.059],\n",
       "        [235.961],\n",
       "        [236.   ],\n",
       "        [235.96 ],\n",
       "        [235.901],\n",
       "        [235.8  ],\n",
       "        [235.785],\n",
       "        [235.82 ],\n",
       "        [235.759],\n",
       "        [235.761],\n",
       "        [235.7  ],\n",
       "        [235.585],\n",
       "        [235.639],\n",
       "        [235.735],\n",
       "        [235.745],\n",
       "        [235.711],\n",
       "        [235.696],\n",
       "        [235.765],\n",
       "        [235.766],\n",
       "        [235.783]],\n",
       "\n",
       "       [[235.961],\n",
       "        [236.   ],\n",
       "        [235.96 ],\n",
       "        [235.901],\n",
       "        [235.8  ],\n",
       "        [235.785],\n",
       "        [235.82 ],\n",
       "        [235.759],\n",
       "        [235.761],\n",
       "        [235.7  ],\n",
       "        [235.585],\n",
       "        [235.639],\n",
       "        [235.735],\n",
       "        [235.745],\n",
       "        [235.711],\n",
       "        [235.696],\n",
       "        [235.765],\n",
       "        [235.766],\n",
       "        [235.783],\n",
       "        [235.78 ]],\n",
       "\n",
       "       [[236.   ],\n",
       "        [235.96 ],\n",
       "        [235.901],\n",
       "        [235.8  ],\n",
       "        [235.785],\n",
       "        [235.82 ],\n",
       "        [235.759],\n",
       "        [235.761],\n",
       "        [235.7  ],\n",
       "        [235.585],\n",
       "        [235.639],\n",
       "        [235.735],\n",
       "        [235.745],\n",
       "        [235.711],\n",
       "        [235.696],\n",
       "        [235.765],\n",
       "        [235.766],\n",
       "        [235.783],\n",
       "        [235.78 ],\n",
       "        [235.887]]])"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[113.766594],\n",
       "       [113.766594],\n",
       "       [113.766594],\n",
       "       [113.766594],\n",
       "       [113.766594],\n",
       "       [113.766594],\n",
       "       [113.766594],\n",
       "       [113.766594],\n",
       "       [113.766594],\n",
       "       [113.766594]], dtype=float32)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(vx[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/40\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 9828.1939 - val_loss: 15249.4345\n",
      "Epoch 2/40\n",
      "16500/16500 [==============================] - 2s 94us/sample - loss: 9297.5158 - val_loss: 14583.9656\n",
      "Epoch 3/40\n",
      "16500/16500 [==============================] - 2s 92us/sample - loss: 8782.8788 - val_loss: 13934.8672\n",
      "Epoch 4/40\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 8284.2093 - val_loss: 13302.0760\n",
      "Epoch 5/40\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 7801.5583 - val_loss: 12685.5464\n",
      "Epoch 6/40\n",
      "16500/16500 [==============================] - 2s 106us/sample - loss: 7334.7564 - val_loss: 12085.2790\n",
      "Epoch 7/40\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 6883.8133 - val_loss: 11501.3407\n",
      "Epoch 8/40\n",
      "16500/16500 [==============================] - 2s 103us/sample - loss: 6448.6567 - val_loss: 10933.4256\n",
      "Epoch 9/40\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 6029.2214 - val_loss: 10381.7255\n",
      "Epoch 10/40\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 5625.4559 - val_loss: 9846.1465\n",
      "Epoch 11/40\n",
      "16500/16500 [==============================] - 2s 94us/sample - loss: 5237.2775 - val_loss: 9326.5478\n",
      "Epoch 12/40\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 4864.6891 - val_loss: 8823.2217\n",
      "Epoch 13/40\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 4507.5752 - val_loss: 8335.8268\n",
      "Epoch 14/40\n",
      "16500/16500 [==============================] - 2s 105us/sample - loss: 4165.8155 - val_loss: 7864.2137\n",
      "Epoch 15/40\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 3839.3502 - val_loss: 7408.6807\n",
      "Epoch 16/40\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 3528.0952 - val_loss: 6968.9862\n",
      "Epoch 17/40\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 3231.9489 - val_loss: 6545.0022\n",
      "Epoch 18/40\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 2950.7631 - val_loss: 6136.7827\n",
      "Epoch 19/40\n",
      "16500/16500 [==============================] - 2s 94us/sample - loss: 2684.4690 - val_loss: 5744.2674\n",
      "Epoch 20/40\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 2432.9273 - val_loss: 5367.2973\n",
      "Epoch 21/40\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 2195.9884 - val_loss: 5005.8184\n",
      "Epoch 22/40\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 1973.5619 - val_loss: 4660.0377\n",
      "Epoch 23/40\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 1765.3797 - val_loss: 4329.5005\n",
      "Epoch 24/40\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 1571.2858 - val_loss: 4014.1370\n",
      "Epoch 25/40\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 1391.1398 - val_loss: 3714.3062\n",
      "Epoch 26/40\n",
      "16500/16500 [==============================] - 2s 94us/sample - loss: 1224.7946 - val_loss: 3429.5590\n",
      "Epoch 27/40\n",
      "16500/16500 [==============================] - 2s 110us/sample - loss: 1071.9464 - val_loss: 3159.9260\n",
      "Epoch 28/40\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 932.2913 - val_loss: 2905.2899\n",
      "Epoch 29/40\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 805.5750 - val_loss: 2665.4224\n",
      "Epoch 30/40\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 691.4916 - val_loss: 2440.3148\n",
      "Epoch 31/40\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 589.6963 - val_loss: 2230.0057\n",
      "Epoch 32/40\n",
      "16500/16500 [==============================] - 2s 107us/sample - loss: 499.7731 - val_loss: 2034.4388\n",
      "Epoch 33/40\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 421.1849 - val_loss: 1853.0183\n",
      "Epoch 34/40\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 353.4783 - val_loss: 1685.9428\n",
      "Epoch 35/40\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 296.0647 - val_loss: 1532.7953\n",
      "Epoch 36/40\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 248.3114 - val_loss: 1393.7149\n",
      "Epoch 37/40\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 209.5680 - val_loss: 1269.0867\n",
      "Epoch 38/40\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 178.9690 - val_loss: 1157.5075\n",
      "Epoch 39/40\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 155.6207 - val_loss: 1060.6104\n",
      "Epoch 40/40\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 138.4894 - val_loss: 976.4063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14e33edd0>"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/40\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 126.5531 - val_loss: 905.4306\n",
      "Epoch 2/40\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 118.7578 - val_loss: 847.4617\n",
      "Epoch 3/40\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 114.0279 - val_loss: 801.1946\n",
      "Epoch 4/40\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 111.4415 - val_loss: 766.9980\n",
      "Epoch 5/40\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 110.1865 - val_loss: 742.2547\n",
      "Epoch 6/40\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.6367 - val_loss: 726.3992\n",
      "Epoch 7/40\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.4357 - val_loss: 716.1499\n",
      "Epoch 8/40\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 109.3782 - val_loss: 710.8648\n",
      "Epoch 9/40\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 109.3651 - val_loss: 708.7055\n",
      "Epoch 10/40\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3601 - val_loss: 706.4816\n",
      "Epoch 11/40\n",
      "16500/16500 [==============================] - 2s 105us/sample - loss: 109.3583 - val_loss: 703.1520\n",
      "Epoch 12/40\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3632 - val_loss: 704.0058\n",
      "Epoch 13/40\n",
      "16500/16500 [==============================] - 2s 93us/sample - loss: 109.3584 - val_loss: 707.6119\n",
      "Epoch 14/40\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3635 - val_loss: 706.3552\n",
      "Epoch 15/40\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 109.3636 - val_loss: 707.5110\n",
      "Epoch 16/40\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3653 - val_loss: 705.8692\n",
      "Epoch 17/40\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3654 - val_loss: 706.1961\n",
      "Epoch 18/40\n",
      "16500/16500 [==============================] - 2s 106us/sample - loss: 109.3648 - val_loss: 704.6325\n",
      "Epoch 19/40\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3640 - val_loss: 705.4984\n",
      "Epoch 20/40\n",
      "16500/16500 [==============================] - 2s 94us/sample - loss: 109.3657 - val_loss: 709.7903\n",
      "Epoch 21/40\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 109.3648 - val_loss: 706.7375\n",
      "Epoch 22/40\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3671 - val_loss: 705.6990\n",
      "Epoch 23/40\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 109.3682 - val_loss: 708.0625\n",
      "Epoch 24/40\n",
      "16500/16500 [==============================] - 2s 105us/sample - loss: 109.3643 - val_loss: 708.0289\n",
      "Epoch 25/40\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 109.3619 - val_loss: 703.9779\n",
      "Epoch 26/40\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3695 - val_loss: 705.9523\n",
      "Epoch 27/40\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3655 - val_loss: 707.8928\n",
      "Epoch 28/40\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3636 - val_loss: 707.7039\n",
      "Epoch 29/40\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3684 - val_loss: 707.2430\n",
      "Epoch 30/40\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3623 - val_loss: 705.6478\n",
      "Epoch 31/40\n",
      "16500/16500 [==============================] - 2s 106us/sample - loss: 109.3658 - val_loss: 707.3150\n",
      "Epoch 32/40\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 109.3624 - val_loss: 706.3304\n",
      "Epoch 33/40\n",
      "16500/16500 [==============================] - 2s 104us/sample - loss: 109.3643 - val_loss: 706.7798\n",
      "Epoch 34/40\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3688 - val_loss: 703.2884\n",
      "Epoch 35/40\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3602 - val_loss: 707.8456\n",
      "Epoch 36/40\n",
      "16500/16500 [==============================] - 2s 94us/sample - loss: 109.3695 - val_loss: 707.9432\n",
      "Epoch 37/40\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 109.3660 - val_loss: 706.6103\n",
      "Epoch 38/40\n",
      "16500/16500 [==============================] - 2s 103us/sample - loss: 109.3633 - val_loss: 704.2796\n",
      "Epoch 39/40\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 109.3680 - val_loss: 704.2189\n",
      "Epoch 40/40\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3656 - val_loss: 704.2157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14e484dd0>"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[213.7478],\n",
       "       [213.7478],\n",
       "       [213.7478],\n",
       "       [213.7478],\n",
       "       [213.7478],\n",
       "       [213.7478],\n",
       "       [213.7478],\n",
       "       [213.7478],\n",
       "       [213.7478],\n",
       "       [213.7478]], dtype=float32)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(vx[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/100\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 109.3671 - val_loss: 707.2414\n",
      "Epoch 2/100\n",
      "16500/16500 [==============================] - 2s 92us/sample - loss: 109.3646 - val_loss: 710.0116\n",
      "Epoch 3/100\n",
      "16500/16500 [==============================] - 2s 94us/sample - loss: 109.3631 - val_loss: 703.9060\n",
      "Epoch 4/100\n",
      "16500/16500 [==============================] - 2s 93us/sample - loss: 109.3627 - val_loss: 706.1498\n",
      "Epoch 5/100\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3648 - val_loss: 706.6095\n",
      "Epoch 6/100\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 109.3588 - val_loss: 703.1959\n",
      "Epoch 7/100\n",
      "16500/16500 [==============================] - 2s 107us/sample - loss: 109.3603 - val_loss: 708.7431\n",
      "Epoch 8/100\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 109.3650 - val_loss: 707.7551\n",
      "Epoch 9/100\n",
      "16500/16500 [==============================] - 1s 91us/sample - loss: 109.3628 - val_loss: 709.8160\n",
      "Epoch 10/100\n",
      "16500/16500 [==============================] - 2s 92us/sample - loss: 109.3643 - val_loss: 710.4566\n",
      "Epoch 11/100\n",
      "16500/16500 [==============================] - 2s 91us/sample - loss: 109.3674 - val_loss: 708.6350\n",
      "Epoch 12/100\n",
      "16500/16500 [==============================] - 2s 94us/sample - loss: 109.3743 - val_loss: 706.4672\n",
      "Epoch 13/100\n",
      "16500/16500 [==============================] - 2s 92us/sample - loss: 109.3672 - val_loss: 707.1566\n",
      "Epoch 14/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3594 - val_loss: 704.3962\n",
      "Epoch 15/100\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 109.3651 - val_loss: 706.0754\n",
      "Epoch 16/100\n",
      "16500/16500 [==============================] - 2s 94us/sample - loss: 109.3633 - val_loss: 707.2158\n",
      "Epoch 17/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3637 - val_loss: 705.8916\n",
      "Epoch 18/100\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 109.3661 - val_loss: 707.8376\n",
      "Epoch 19/100\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 109.3634 - val_loss: 703.2454\n",
      "Epoch 20/100\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 109.3698 - val_loss: 706.0282\n",
      "Epoch 21/100\n",
      "16500/16500 [==============================] - 2s 107us/sample - loss: 109.3670 - val_loss: 708.5317\n",
      "Epoch 22/100\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 109.3620 - val_loss: 707.5718\n",
      "Epoch 23/100\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 109.3727 - val_loss: 705.0933\n",
      "Epoch 24/100\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3627 - val_loss: 704.3331\n",
      "Epoch 25/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3539 - val_loss: 699.8179\n",
      "Epoch 26/100\n",
      "16500/16500 [==============================] - 2s 92us/sample - loss: 109.3695 - val_loss: 706.0203\n",
      "Epoch 27/100\n",
      "16500/16500 [==============================] - 2s 92us/sample - loss: 109.3636 - val_loss: 704.6101\n",
      "Epoch 28/100\n",
      "16500/16500 [==============================] - 2s 105us/sample - loss: 109.3620 - val_loss: 704.1862\n",
      "Epoch 29/100\n",
      "16500/16500 [==============================] - 2s 92us/sample - loss: 109.3637 - val_loss: 705.6718\n",
      "Epoch 30/100\n",
      "16500/16500 [==============================] - 2s 91us/sample - loss: 109.3683 - val_loss: 706.9638\n",
      "Epoch 31/100\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 109.3632 - val_loss: 707.2662\n",
      "Epoch 32/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3629 - val_loss: 707.2686\n",
      "Epoch 33/100\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3610 - val_loss: 705.4848\n",
      "Epoch 34/100\n",
      "16500/16500 [==============================] - 2s 105us/sample - loss: 109.3708 - val_loss: 706.5711\n",
      "Epoch 35/100\n",
      "16500/16500 [==============================] - 2s 107us/sample - loss: 109.3597 - val_loss: 703.6658\n",
      "Epoch 36/100\n",
      "16500/16500 [==============================] - 2s 106us/sample - loss: 109.3611 - val_loss: 702.1282\n",
      "Epoch 37/100\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 109.3683 - val_loss: 704.2652\n",
      "Epoch 38/100\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 109.3626 - val_loss: 705.2124\n",
      "Epoch 39/100\n",
      "16500/16500 [==============================] - 2s 104us/sample - loss: 109.3674 - val_loss: 703.7488\n",
      "Epoch 40/100\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3639 - val_loss: 707.3870\n",
      "Epoch 41/100\n",
      "16500/16500 [==============================] - 2s 106us/sample - loss: 109.3672 - val_loss: 704.6261\n",
      "Epoch 42/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3670 - val_loss: 706.4440\n",
      "Epoch 43/100\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 109.3574 - val_loss: 702.4606\n",
      "Epoch 44/100\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3677 - val_loss: 704.6892\n",
      "Epoch 45/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3739 - val_loss: 707.4246\n",
      "Epoch 46/100\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3607 - val_loss: 703.0675\n",
      "Epoch 47/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3672 - val_loss: 704.2525\n",
      "Epoch 48/100\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 109.3625 - val_loss: 709.1236\n",
      "Epoch 49/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3694 - val_loss: 706.3960\n",
      "Epoch 50/100\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 109.3659 - val_loss: 703.5868\n",
      "Epoch 51/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3672 - val_loss: 706.4312\n",
      "Epoch 52/100\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3669 - val_loss: 706.2297\n",
      "Epoch 53/100\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3653 - val_loss: 707.4430\n",
      "Epoch 54/100\n",
      "16500/16500 [==============================] - 2s 110us/sample - loss: 109.3661 - val_loss: 706.9086\n",
      "Epoch 55/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3669 - val_loss: 706.1642\n",
      "Epoch 56/100\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3708 - val_loss: 703.4879\n",
      "Epoch 57/100\n",
      "16500/16500 [==============================] - 2s 115us/sample - loss: 109.3681 - val_loss: 704.4880\n",
      "Epoch 58/100\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3644 - val_loss: 708.5197\n",
      "Epoch 59/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3675 - val_loss: 706.5607\n",
      "Epoch 60/100\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 109.3696 - val_loss: 704.3291\n",
      "Epoch 61/100\n",
      "16500/16500 [==============================] - 2s 103us/sample - loss: 109.3675 - val_loss: 705.6894\n",
      "Epoch 62/100\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 109.3642 - val_loss: 704.2948\n",
      "Epoch 63/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3655 - val_loss: 704.1646\n",
      "Epoch 64/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3616 - val_loss: 706.6399\n",
      "Epoch 65/100\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3610 - val_loss: 706.1642\n",
      "Epoch 66/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3621 - val_loss: 704.8897\n",
      "Epoch 67/100\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 109.3704 - val_loss: 707.6503\n",
      "Epoch 68/100\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3640 - val_loss: 709.3327\n",
      "Epoch 69/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3711 - val_loss: 708.2723\n",
      "Epoch 70/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3621 - val_loss: 707.1422\n",
      "Epoch 71/100\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3630 - val_loss: 705.0853\n",
      "Epoch 72/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3674 - val_loss: 706.6983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3639 - val_loss: 705.6766\n",
      "Epoch 74/100\n",
      "16500/16500 [==============================] - 2s 107us/sample - loss: 109.3636 - val_loss: 706.0243\n",
      "Epoch 75/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3688 - val_loss: 704.2413\n",
      "Epoch 76/100\n",
      "16500/16500 [==============================] - 2s 104us/sample - loss: 109.3662 - val_loss: 707.5278\n",
      "Epoch 77/100\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3722 - val_loss: 708.1690\n",
      "Epoch 78/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3652 - val_loss: 710.3451\n",
      "Epoch 79/100\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3654 - val_loss: 704.8689\n",
      "Epoch 80/100\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 109.3664 - val_loss: 706.5040\n",
      "Epoch 81/100\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 109.3671 - val_loss: 705.2411\n",
      "Epoch 82/100\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 109.3662 - val_loss: 705.4984\n",
      "Epoch 83/100\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 109.3669 - val_loss: 705.6934\n",
      "Epoch 84/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3651 - val_loss: 706.2353\n",
      "Epoch 85/100\n",
      "16500/16500 [==============================] - 2s 107us/sample - loss: 109.3703 - val_loss: 708.0065\n",
      "Epoch 86/100\n",
      "16500/16500 [==============================] - 2s 107us/sample - loss: 109.3685 - val_loss: 708.6142\n",
      "Epoch 87/100\n",
      "16500/16500 [==============================] - 2s 118us/sample - loss: 109.3643 - val_loss: 706.8974\n",
      "Epoch 88/100\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3647 - val_loss: 705.5184\n",
      "Epoch 89/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3684 - val_loss: 703.8039\n",
      "Epoch 90/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3642 - val_loss: 705.2715\n",
      "Epoch 91/100\n",
      "16500/16500 [==============================] - 2s 131us/sample - loss: 109.3643 - val_loss: 707.4662\n",
      "Epoch 92/100\n",
      "16500/16500 [==============================] - 2s 149us/sample - loss: 109.3689 - val_loss: 708.2442\n",
      "Epoch 93/100\n",
      "16500/16500 [==============================] - 2s 110us/sample - loss: 109.3635 - val_loss: 706.9846\n",
      "Epoch 94/100\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3632 - val_loss: 707.8840\n",
      "Epoch 95/100\n",
      "16500/16500 [==============================] - 2s 104us/sample - loss: 109.3651 - val_loss: 707.3982\n",
      "Epoch 96/100\n",
      "16500/16500 [==============================] - 2s 126us/sample - loss: 109.3638 - val_loss: 706.7295\n",
      "Epoch 97/100\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 109.3670 - val_loss: 708.6823\n",
      "Epoch 98/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3653 - val_loss: 706.2545\n",
      "Epoch 99/100\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 109.3694 - val_loss: 706.4232\n",
      "Epoch 100/100\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 109.3683 - val_loss: 709.8569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14e438490>"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = model.predict(vx)\n",
    "p.max() - p.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[213.6402],\n",
       "       [213.6402],\n",
       "       [213.6402],\n",
       "       [213.6402],\n",
       "       [213.6402],\n",
       "       [213.6402],\n",
       "       [213.6402],\n",
       "       [213.6402],\n",
       "       [213.6402],\n",
       "       [213.6402]], dtype=float32)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3669 - val_loss: 709.2678\n",
      "Epoch 2/100\n",
      "16500/16500 [==============================] - 2s 94us/sample - loss: 109.3687 - val_loss: 707.0782\n",
      "Epoch 3/100\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 109.3663 - val_loss: 708.5653\n",
      "Epoch 4/100\n",
      "16500/16500 [==============================] - 2s 115us/sample - loss: 109.3642 - val_loss: 708.9313\n",
      "Epoch 5/100\n",
      "16500/16500 [==============================] - 2s 111us/sample - loss: 109.3600 - val_loss: 708.9434\n",
      "Epoch 6/100\n",
      "16500/16500 [==============================] - 2s 103us/sample - loss: 109.3682 - val_loss: 710.4293\n",
      "Epoch 7/100\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 109.3567 - val_loss: 702.3865\n",
      "Epoch 8/100\n",
      "16500/16500 [==============================] - 2s 92us/sample - loss: 109.3679 - val_loss: 705.2499\n",
      "Epoch 9/100\n",
      "16500/16500 [==============================] - 2s 103us/sample - loss: 109.3652 - val_loss: 706.0466\n",
      "Epoch 10/100\n",
      "16500/16500 [==============================] - 2s 92us/sample - loss: 109.3672 - val_loss: 708.0401\n",
      "Epoch 11/100\n",
      "16500/16500 [==============================] - 2s 92us/sample - loss: 109.3634 - val_loss: 706.3472\n",
      "Epoch 12/100\n",
      "16500/16500 [==============================] - 2s 94us/sample - loss: 109.3614 - val_loss: 705.1500\n",
      "Epoch 13/100\n",
      "16500/16500 [==============================] - 2s 92us/sample - loss: 109.3630 - val_loss: 704.8042\n",
      "Epoch 14/100\n",
      "16500/16500 [==============================] - 2s 92us/sample - loss: 109.3691 - val_loss: 707.0702\n",
      "Epoch 15/100\n",
      "16500/16500 [==============================] - 2s 93us/sample - loss: 109.3702 - val_loss: 704.6317\n",
      "Epoch 16/100\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 109.3637 - val_loss: 708.4676\n",
      "Epoch 17/100\n",
      "16500/16500 [==============================] - 2s 92us/sample - loss: 109.3671 - val_loss: 705.6814\n",
      "Epoch 18/100\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3618 - val_loss: 706.5160\n",
      "Epoch 19/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3610 - val_loss: 704.4361\n",
      "Epoch 20/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3639 - val_loss: 703.4759\n",
      "Epoch 21/100\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 109.3617 - val_loss: 707.8120\n",
      "Epoch 22/100\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 109.3630 - val_loss: 709.9170\n",
      "Epoch 23/100\n",
      "16500/16500 [==============================] - 2s 106us/sample - loss: 109.3673 - val_loss: 705.5415\n",
      "Epoch 24/100\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3669 - val_loss: 708.8681\n",
      "Epoch 25/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3633 - val_loss: 705.8404\n",
      "Epoch 26/100\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 109.3678 - val_loss: 705.8540\n",
      "Epoch 27/100\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 109.3655 - val_loss: 706.1674\n",
      "Epoch 28/100\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3536 - val_loss: 701.7751\n",
      "Epoch 29/100\n",
      "16500/16500 [==============================] - 2s 112us/sample - loss: 109.3667 - val_loss: 708.3523\n",
      "Epoch 30/100\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 109.3633 - val_loss: 709.3191\n",
      "Epoch 31/100\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3670 - val_loss: 708.6767\n",
      "Epoch 32/100\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 109.3617 - val_loss: 706.4392\n",
      "Epoch 33/100\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 109.3652 - val_loss: 707.9128\n",
      "Epoch 34/100\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 109.3712 - val_loss: 703.6155\n",
      "Epoch 35/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3636 - val_loss: 707.6287\n",
      "Epoch 36/100\n",
      "16500/16500 [==============================] - 2s 110us/sample - loss: 109.3642 - val_loss: 705.6598\n",
      "Epoch 37/100\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 109.3660 - val_loss: 706.5160\n",
      "Epoch 38/100\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3665 - val_loss: 704.2533\n",
      "Epoch 39/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3666 - val_loss: 705.6238\n",
      "Epoch 40/100\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 109.3643 - val_loss: 705.7069\n",
      "Epoch 41/100\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3682 - val_loss: 707.6103\n",
      "Epoch 42/100\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 109.3648 - val_loss: 707.1206\n",
      "Epoch 43/100\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 109.3616 - val_loss: 708.5093\n",
      "Epoch 44/100\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 109.3647 - val_loss: 704.8689\n",
      "Epoch 45/100\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 109.3619 - val_loss: 707.9776\n",
      "Epoch 46/100\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3655 - val_loss: 704.2876\n",
      "Epoch 47/100\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 109.3659 - val_loss: 705.5847\n",
      "Epoch 48/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3661 - val_loss: 704.8729\n",
      "Epoch 49/100\n",
      "16500/16500 [==============================] - 2s 111us/sample - loss: 109.3686 - val_loss: 705.2211\n",
      "Epoch 50/100\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 109.3643 - val_loss: 704.5742\n",
      "Epoch 51/100\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3731 - val_loss: 706.4768\n",
      "Epoch 52/100\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3652 - val_loss: 706.6047\n",
      "Epoch 53/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3590 - val_loss: 709.7046\n",
      "Epoch 54/100\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3679 - val_loss: 706.8062\n",
      "Epoch 55/100\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 109.3676 - val_loss: 708.5181\n",
      "Epoch 56/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3615 - val_loss: 703.9635\n",
      "Epoch 57/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3661 - val_loss: 705.1732\n",
      "Epoch 58/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3641 - val_loss: 704.0218\n",
      "Epoch 59/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3572 - val_loss: 699.5481\n",
      "Epoch 60/100\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3693 - val_loss: 705.7054\n",
      "Epoch 61/100\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 109.3684 - val_loss: 707.1854\n",
      "Epoch 62/100\n",
      "16500/16500 [==============================] - 2s 105us/sample - loss: 109.3647 - val_loss: 706.6063\n",
      "Epoch 63/100\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3623 - val_loss: 704.7435\n",
      "Epoch 64/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3600 - val_loss: 701.0956\n",
      "Epoch 65/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3673 - val_loss: 708.5237\n",
      "Epoch 66/100\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3669 - val_loss: 708.8809\n",
      "Epoch 67/100\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 109.3587 - val_loss: 703.7288\n",
      "Epoch 68/100\n",
      "16500/16500 [==============================] - 2s 103us/sample - loss: 109.3652 - val_loss: 702.5922\n",
      "Epoch 69/100\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 109.3647 - val_loss: 705.7965\n",
      "Epoch 70/100\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 109.3655 - val_loss: 706.1921\n",
      "Epoch 71/100\n",
      "16500/16500 [==============================] - 2s 105us/sample - loss: 109.3624 - val_loss: 704.6868\n",
      "Epoch 72/100\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 109.3704 - val_loss: 707.8912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3618 - val_loss: 708.9562\n",
      "Epoch 74/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3672 - val_loss: 706.0019\n",
      "Epoch 75/100\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 109.3614 - val_loss: 705.7733\n",
      "Epoch 76/100\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 109.3652 - val_loss: 701.3019\n",
      "Epoch 77/100\n",
      "16500/16500 [==============================] - 2s 94us/sample - loss: 109.3733 - val_loss: 705.3530\n",
      "Epoch 78/100\n",
      "16500/16500 [==============================] - 2s 94us/sample - loss: 109.3631 - val_loss: 711.0140\n",
      "Epoch 79/100\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 109.3685 - val_loss: 707.5135\n",
      "Epoch 80/100\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 109.3637 - val_loss: 704.8928\n",
      "Epoch 81/100\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 109.3640 - val_loss: 708.4748\n",
      "Epoch 82/100\n",
      "16500/16500 [==============================] - 2s 116us/sample - loss: 109.3643 - val_loss: 708.5669\n",
      "Epoch 83/100\n",
      "16500/16500 [==============================] - 2s 116us/sample - loss: 109.3643 - val_loss: 700.1115\n",
      "Epoch 84/100\n",
      "16500/16500 [==============================] - 2s 117us/sample - loss: 109.3661 - val_loss: 707.6631\n",
      "Epoch 85/100\n",
      "16500/16500 [==============================] - 2s 110us/sample - loss: 109.3648 - val_loss: 703.7767\n",
      "Epoch 86/100\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 109.3643 - val_loss: 704.0712\n",
      "Epoch 87/100\n",
      "16500/16500 [==============================] - 2s 110us/sample - loss: 109.3650 - val_loss: 703.8813\n",
      "Epoch 88/100\n",
      "16500/16500 [==============================] - 2s 119us/sample - loss: 109.3643 - val_loss: 708.2194\n",
      "Epoch 89/100\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 109.3666 - val_loss: 706.4368\n",
      "Epoch 90/100\n",
      "16500/16500 [==============================] - 2s 111us/sample - loss: 109.3666 - val_loss: 706.7663\n",
      "Epoch 91/100\n",
      "16500/16500 [==============================] - 2s 107us/sample - loss: 109.3726 - val_loss: 706.6959\n",
      "Epoch 92/100\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3655 - val_loss: 706.7463\n",
      "Epoch 93/100\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 109.3659 - val_loss: 707.5527\n",
      "Epoch 94/100\n",
      "16500/16500 [==============================] - 2s 103us/sample - loss: 109.3690 - val_loss: 704.0752\n",
      "Epoch 95/100\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3662 - val_loss: 706.2641\n",
      "Epoch 96/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3647 - val_loss: 705.2323\n",
      "Epoch 97/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3657 - val_loss: 706.4304\n",
      "Epoch 98/100\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3665 - val_loss: 703.4967\n",
      "Epoch 99/100\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3641 - val_loss: 702.7812\n",
      "Epoch 100/100\n",
      "16500/16500 [==============================] - 2s 104us/sample - loss: 109.3708 - val_loss: 705.0350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x5bd647450>"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, array([[213.73215],\n",
       "        [213.73215],\n",
       "        [213.73215],\n",
       "        [213.73215],\n",
       "        [213.73215],\n",
       "        [213.73215],\n",
       "        [213.73215],\n",
       "        [213.73215],\n",
       "        [213.73215],\n",
       "        [213.73215]], dtype=float32))"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = model.predict(vx)\n",
    "p.max() - p.min(), p[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/100\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 109.3682 - val_loss: 706.7606\n",
      "Epoch 2/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3673 - val_loss: 706.7103\n",
      "Epoch 3/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3727 - val_loss: 705.2355\n",
      "Epoch 4/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3662 - val_loss: 707.4446\n",
      "Epoch 5/100\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3674 - val_loss: 707.8880\n",
      "Epoch 6/100\n",
      "16500/16500 [==============================] - 2s 107us/sample - loss: 109.3634 - val_loss: 709.1869\n",
      "Epoch 7/100\n",
      "16500/16500 [==============================] - 2s 94us/sample - loss: 109.3665 - val_loss: 708.9145\n",
      "Epoch 8/100\n",
      "16500/16500 [==============================] - 2s 94us/sample - loss: 109.3632 - val_loss: 708.2234\n",
      "Epoch 9/100\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 109.3649 - val_loss: 702.9343\n",
      "Epoch 10/100\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 109.3593 - val_loss: 708.2298\n",
      "Epoch 11/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3659 - val_loss: 705.2571\n",
      "Epoch 12/100\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 109.3647 - val_loss: 705.9731\n",
      "Epoch 13/100\n",
      "16500/16500 [==============================] - 2s 105us/sample - loss: 109.3689 - val_loss: 703.5230\n",
      "Epoch 14/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3690 - val_loss: 709.4706\n",
      "Epoch 15/100\n",
      "16500/16500 [==============================] - 2s 93us/sample - loss: 109.3663 - val_loss: 703.9515\n",
      "Epoch 16/100\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3666 - val_loss: 706.6455\n",
      "Epoch 17/100\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3618 - val_loss: 705.4984\n",
      "Epoch 18/100\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 109.3659 - val_loss: 706.0195\n",
      "Epoch 19/100\n",
      "16500/16500 [==============================] - 2s 103us/sample - loss: 109.3684 - val_loss: 706.4392\n",
      "Epoch 20/100\n",
      "16500/16500 [==============================] - 2s 93us/sample - loss: 109.3656 - val_loss: 708.4964\n",
      "Epoch 21/100\n",
      "16500/16500 [==============================] - 2s 94us/sample - loss: 109.3650 - val_loss: 706.8958\n",
      "Epoch 22/100\n",
      "16500/16500 [==============================] - 2s 92us/sample - loss: 109.3647 - val_loss: 705.8828\n",
      "Epoch 23/100\n",
      "16500/16500 [==============================] - 1s 89us/sample - loss: 109.3639 - val_loss: 706.3720\n",
      "Epoch 24/100\n",
      "16500/16500 [==============================] - 2s 91us/sample - loss: 109.3677 - val_loss: 703.4320\n",
      "Epoch 25/100\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 109.3637 - val_loss: 705.1285\n",
      "Epoch 26/100\n",
      "16500/16500 [==============================] - 2s 105us/sample - loss: 109.3596 - val_loss: 708.2338\n",
      "Epoch 27/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3611 - val_loss: 704.1040\n",
      "Epoch 28/100\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3682 - val_loss: 707.1286\n",
      "Epoch 29/100\n",
      "16500/16500 [==============================] - 2s 93us/sample - loss: 109.3601 - val_loss: 704.0497\n",
      "Epoch 30/100\n",
      "16500/16500 [==============================] - 2s 91us/sample - loss: 109.3622 - val_loss: 704.2796\n",
      "Epoch 31/100\n",
      "16500/16500 [==============================] - 1s 91us/sample - loss: 109.3611 - val_loss: 709.9643\n",
      "Epoch 32/100\n",
      "16500/16500 [==============================] - 2s 92us/sample - loss: 109.3753 - val_loss: 703.9156\n",
      "Epoch 33/100\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 109.3671 - val_loss: 705.1876\n",
      "Epoch 34/100\n",
      "16500/16500 [==============================] - 2s 94us/sample - loss: 109.3704 - val_loss: 703.8438\n",
      "Epoch 35/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3645 - val_loss: 706.6023\n",
      "Epoch 36/100\n",
      "16500/16500 [==============================] - 2s 94us/sample - loss: 109.3641 - val_loss: 711.4385\n",
      "Epoch 37/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3665 - val_loss: 712.0614\n",
      "Epoch 38/100\n",
      "16500/16500 [==============================] - 1s 90us/sample - loss: 109.3670 - val_loss: 706.0099\n",
      "Epoch 39/100\n",
      "16500/16500 [==============================] - 1s 91us/sample - loss: 109.3606 - val_loss: 709.2606\n",
      "Epoch 40/100\n",
      "16500/16500 [==============================] - 2s 104us/sample - loss: 109.3652 - val_loss: 705.0742\n",
      "Epoch 41/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3639 - val_loss: 707.1302\n",
      "Epoch 42/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3623 - val_loss: 705.7469\n",
      "Epoch 43/100\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 109.3627 - val_loss: 709.4409\n",
      "Epoch 44/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3671 - val_loss: 706.1705\n",
      "Epoch 45/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3633 - val_loss: 708.0161\n",
      "Epoch 46/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3674 - val_loss: 705.3657\n",
      "Epoch 47/100\n",
      "16500/16500 [==============================] - 2s 104us/sample - loss: 109.3618 - val_loss: 708.2667\n",
      "Epoch 48/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3631 - val_loss: 704.4848\n",
      "Epoch 49/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3629 - val_loss: 707.9568\n",
      "Epoch 50/100\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 109.3627 - val_loss: 705.7341\n",
      "Epoch 51/100\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3703 - val_loss: 702.8003\n",
      "Epoch 52/100\n",
      "16500/16500 [==============================] - 2s 110us/sample - loss: 109.3677 - val_loss: 706.7846\n",
      "Epoch 53/100\n",
      "16500/16500 [==============================] - 2s 107us/sample - loss: 109.3671 - val_loss: 706.7487\n",
      "Epoch 54/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3555 - val_loss: 702.1067\n",
      "Epoch 55/100\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3682 - val_loss: 702.9295\n",
      "Epoch 56/100\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3650 - val_loss: 707.5551\n",
      "Epoch 57/100\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 109.3660 - val_loss: 707.1734\n",
      "Epoch 58/100\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3654 - val_loss: 708.3884\n",
      "Epoch 59/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3638 - val_loss: 705.3290\n",
      "Epoch 60/100\n",
      "16500/16500 [==============================] - 2s 111us/sample - loss: 109.3645 - val_loss: 706.8038\n",
      "Epoch 61/100\n",
      "16500/16500 [==============================] - 2s 93us/sample - loss: 109.3674 - val_loss: 707.6967\n",
      "Epoch 62/100\n",
      "16500/16500 [==============================] - 2s 93us/sample - loss: 109.3645 - val_loss: 703.5182\n",
      "Epoch 63/100\n",
      "16500/16500 [==============================] - 2s 94us/sample - loss: 109.3677 - val_loss: 705.7645\n",
      "Epoch 64/100\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3534 - val_loss: 711.6495\n",
      "Epoch 65/100\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 109.3630 - val_loss: 706.4912\n",
      "Epoch 66/100\n",
      "16500/16500 [==============================] - 2s 106us/sample - loss: 109.3644 - val_loss: 706.5095\n",
      "Epoch 67/100\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 109.3650 - val_loss: 708.8424\n",
      "Epoch 68/100\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3660 - val_loss: 704.2030\n",
      "Epoch 69/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3702 - val_loss: 707.8480\n",
      "Epoch 70/100\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 109.3700 - val_loss: 707.2902\n",
      "Epoch 71/100\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 109.3584 - val_loss: 701.6668\n",
      "Epoch 72/100\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3702 - val_loss: 705.6278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 109.3683 - val_loss: 706.1058\n",
      "Epoch 74/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3727 - val_loss: 704.5431\n",
      "Epoch 75/100\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 109.3668 - val_loss: 706.2089\n",
      "Epoch 76/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3623 - val_loss: 705.6750\n",
      "Epoch 77/100\n",
      "16500/16500 [==============================] - 2s 93us/sample - loss: 109.3653 - val_loss: 708.9994\n",
      "Epoch 78/100\n",
      "16500/16500 [==============================] - 2s 92us/sample - loss: 109.3672 - val_loss: 707.5423\n",
      "Epoch 79/100\n",
      "16500/16500 [==============================] - 2s 94us/sample - loss: 109.3675 - val_loss: 706.8422\n",
      "Epoch 80/100\n",
      "16500/16500 [==============================] - 2s 106us/sample - loss: 109.3688 - val_loss: 706.6167\n",
      "Epoch 81/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3703 - val_loss: 706.4152\n",
      "Epoch 82/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3636 - val_loss: 707.0870\n",
      "Epoch 83/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3607 - val_loss: 703.9355\n",
      "Epoch 84/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3632 - val_loss: 704.7826\n",
      "Epoch 85/100\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 109.3647 - val_loss: 704.1439\n",
      "Epoch 86/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3650 - val_loss: 703.8956\n",
      "Epoch 87/100\n",
      "16500/16500 [==============================] - 2s 106us/sample - loss: 109.3670 - val_loss: 706.2065\n",
      "Epoch 88/100\n",
      "16500/16500 [==============================] - 2s 103us/sample - loss: 109.3650 - val_loss: 707.4886\n",
      "Epoch 89/100\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 109.3594 - val_loss: 703.0228\n",
      "Epoch 90/100\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3658 - val_loss: 704.7347\n",
      "Epoch 91/100\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 109.3694 - val_loss: 706.1785\n",
      "Epoch 92/100\n",
      "16500/16500 [==============================] - 2s 95us/sample - loss: 109.3646 - val_loss: 704.1287\n",
      "Epoch 93/100\n",
      "16500/16500 [==============================] - 2s 106us/sample - loss: 109.3688 - val_loss: 703.9244\n",
      "Epoch 94/100\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 109.3656 - val_loss: 708.0233\n",
      "Epoch 95/100\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 109.3664 - val_loss: 707.7367\n",
      "Epoch 96/100\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 109.3655 - val_loss: 707.8200\n",
      "Epoch 97/100\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3613 - val_loss: 701.3656\n",
      "Epoch 98/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3729 - val_loss: 703.4967\n",
      "Epoch 99/100\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 109.3649 - val_loss: 706.9334\n",
      "Epoch 100/100\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3633 - val_loss: 703.9204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, array([[213.75345],\n",
       "        [213.75345],\n",
       "        [213.75345],\n",
       "        [213.75345],\n",
       "        [213.75345],\n",
       "        [213.75345],\n",
       "        [213.75345],\n",
       "        [213.75345],\n",
       "        [213.75345],\n",
       "        [213.75345]], dtype=float32))"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=100)\n",
    "\n",
    "p = model.predict(vx)\n",
    "p.max() - p.min(), p[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/20\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 23695.8891 - val_loss: 31833.5312\n",
      "Epoch 2/20\n",
      "16500/16500 [==============================] - 2s 105us/sample - loss: 22840.4573 - val_loss: 30839.3250\n",
      "Epoch 3/20\n",
      "16500/16500 [==============================] - 2s 106us/sample - loss: 22001.7827 - val_loss: 29861.9263\n",
      "Epoch 4/20\n",
      "16500/16500 [==============================] - 2s 103us/sample - loss: 21179.6795 - val_loss: 28901.3037\n",
      "Epoch 5/20\n",
      "16500/16500 [==============================] - 2s 105us/sample - loss: 20374.2148 - val_loss: 27957.5544\n",
      "Epoch 6/20\n",
      "16500/16500 [==============================] - 2s 105us/sample - loss: 19585.3680 - val_loss: 27030.4896\n",
      "Epoch 7/20\n",
      "16500/16500 [==============================] - 2s 107us/sample - loss: 18813.0083 - val_loss: 26119.8637\n",
      "Epoch 8/20\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 18057.2038 - val_loss: 25226.3443\n",
      "Epoch 9/20\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 17317.9834 - val_loss: 24349.3199\n",
      "Epoch 10/20\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 16595.2094 - val_loss: 23489.0638\n",
      "Epoch 11/20\n",
      "16500/16500 [==============================] - 2s 103us/sample - loss: 15888.8219 - val_loss: 22645.1932\n",
      "Epoch 12/20\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 15198.8833 - val_loss: 21818.1223\n",
      "Epoch 13/20\n",
      "16500/16500 [==============================] - 2s 111us/sample - loss: 14525.3502 - val_loss: 21007.6516\n",
      "Epoch 14/20\n",
      "16500/16500 [==============================] - 2s 105us/sample - loss: 13868.1541 - val_loss: 20213.7618\n",
      "Epoch 15/20\n",
      "16500/16500 [==============================] - 2s 106us/sample - loss: 13227.2807 - val_loss: 19436.2704\n",
      "Epoch 16/20\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 12602.7028 - val_loss: 18675.4385\n",
      "Epoch 17/20\n",
      "16500/16500 [==============================] - 2s 107us/sample - loss: 11994.4048 - val_loss: 17930.9888\n",
      "Epoch 18/20\n",
      "16500/16500 [==============================] - 2s 104us/sample - loss: 11402.3054 - val_loss: 17203.1005\n",
      "Epoch 19/20\n",
      "16500/16500 [==============================] - 2s 115us/sample - loss: 10826.3847 - val_loss: 16491.6331\n",
      "Epoch 20/20\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 10266.6562 - val_loss: 15796.5183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x5bd384410>"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/20\n",
      "16500/16500 [==============================] - 2s 113us/sample - loss: 9723.0399 - val_loss: 15117.8777\n",
      "Epoch 2/20\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 9195.5388 - val_loss: 14455.6754\n",
      "Epoch 3/20\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 8684.0220 - val_loss: 13809.6919\n",
      "Epoch 4/20\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 8188.4706 - val_loss: 13180.2714\n",
      "Epoch 5/20\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 7708.9248 - val_loss: 12566.7594\n",
      "Epoch 6/20\n",
      "16500/16500 [==============================] - 2s 110us/sample - loss: 7245.3244 - val_loss: 11969.7513\n",
      "Epoch 7/20\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 6797.5033 - val_loss: 11388.8811\n",
      "Epoch 8/20\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 6365.3931 - val_loss: 10824.2146\n",
      "Epoch 9/20\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 5949.0004 - val_loss: 10275.6270\n",
      "Epoch 10/20\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 5548.2961 - val_loss: 9743.2577\n",
      "Epoch 11/20\n",
      "16500/16500 [==============================] - 2s 103us/sample - loss: 5163.2255 - val_loss: 9226.9274\n",
      "Epoch 12/20\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 4793.6460 - val_loss: 8726.6500\n",
      "Epoch 13/20\n",
      "16500/16500 [==============================] - 2s 115us/sample - loss: 4439.5103 - val_loss: 8242.3447\n",
      "Epoch 14/20\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 4100.8212 - val_loss: 7773.9261\n",
      "Epoch 15/20\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 3777.3627 - val_loss: 7321.5542\n",
      "Epoch 16/20\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 3469.0617 - val_loss: 6884.8765\n",
      "Epoch 17/20\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 3175.8109 - val_loss: 6463.9795\n",
      "Epoch 18/20\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 2897.5296 - val_loss: 6058.7657\n",
      "Epoch 19/20\n",
      "16500/16500 [==============================] - 2s 115us/sample - loss: 2634.1177 - val_loss: 5669.2482\n",
      "Epoch 20/20\n",
      "16500/16500 [==============================] - 2s 104us/sample - loss: 2385.4263 - val_loss: 5295.3771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14c0bbf90>"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/20\n",
      "16500/16500 [==============================] - 2s 111us/sample - loss: 2151.3395 - val_loss: 4937.0624\n",
      "Epoch 2/20\n",
      "16500/16500 [==============================] - 2s 111us/sample - loss: 1931.6576 - val_loss: 4594.1900\n",
      "Epoch 3/20\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 1726.2325 - val_loss: 4266.5968\n",
      "Epoch 4/20\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 1534.9350 - val_loss: 3954.3587\n",
      "Epoch 5/20\n",
      "16500/16500 [==============================] - 2s 105us/sample - loss: 1357.5372 - val_loss: 3657.3540\n",
      "Epoch 6/20\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 1193.8296 - val_loss: 3375.6710\n",
      "Epoch 7/20\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 1043.5504 - val_loss: 3108.9675\n",
      "Epoch 8/20\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 906.4682 - val_loss: 2857.1506\n",
      "Epoch 9/20\n",
      "16500/16500 [==============================] - 2s 110us/sample - loss: 782.2359 - val_loss: 2620.2246\n",
      "Epoch 10/20\n",
      "16500/16500 [==============================] - 2s 103us/sample - loss: 670.5745 - val_loss: 2397.9855\n",
      "Epoch 11/20\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 571.0851 - val_loss: 2190.2962\n",
      "Epoch 12/20\n",
      "16500/16500 [==============================] - 2s 107us/sample - loss: 483.3921 - val_loss: 1997.5433\n",
      "Epoch 13/20\n",
      "16500/16500 [==============================] - 2s 103us/sample - loss: 406.9992 - val_loss: 1818.8678\n",
      "Epoch 14/20\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 341.4022 - val_loss: 1654.5764\n",
      "Epoch 15/20\n",
      "16500/16500 [==============================] - 2s 111us/sample - loss: 286.0296 - val_loss: 1504.4510\n",
      "Epoch 16/20\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 240.1671 - val_loss: 1368.4006\n",
      "Epoch 17/20\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 203.0875 - val_loss: 1246.2772\n",
      "Epoch 18/20\n",
      "16500/16500 [==============================] - 2s 103us/sample - loss: 173.9607 - val_loss: 1138.0780\n",
      "Epoch 19/20\n",
      "16500/16500 [==============================] - 2s 105us/sample - loss: 151.8730 - val_loss: 1043.1791\n",
      "Epoch 20/20\n",
      "16500/16500 [==============================] - 2s 104us/sample - loss: 135.8040 - val_loss: 961.8089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x5bd486990>"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/20\n",
      "16500/16500 [==============================] - 2s 103us/sample - loss: 124.7279 - val_loss: 893.0323\n",
      "Epoch 2/20\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 117.6009 - val_loss: 837.3855\n",
      "Epoch 3/20\n",
      "16500/16500 [==============================] - 2s 106us/sample - loss: 113.3840 - val_loss: 793.8091\n",
      "Epoch 4/20\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 111.1027 - val_loss: 761.3085\n",
      "Epoch 5/20\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 110.0161 - val_loss: 737.6249\n",
      "Epoch 6/20\n",
      "16500/16500 [==============================] - 2s 111us/sample - loss: 109.5734 - val_loss: 723.0645\n",
      "Epoch 7/20\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 109.4179 - val_loss: 715.2676\n",
      "Epoch 8/20\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 109.3765 - val_loss: 710.4165\n",
      "Epoch 9/20\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 109.3627 - val_loss: 707.7447\n",
      "Epoch 10/20\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3592 - val_loss: 706.3304\n",
      "Epoch 11/20\n",
      "16500/16500 [==============================] - 2s 102us/sample - loss: 109.3604 - val_loss: 706.8526\n",
      "Epoch 12/20\n",
      "16500/16500 [==============================] - 2s 110us/sample - loss: 109.3601 - val_loss: 705.1724\n",
      "Epoch 13/20\n",
      "16500/16500 [==============================] - 2s 101us/sample - loss: 109.3651 - val_loss: 705.9939\n",
      "Epoch 14/20\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 109.3600 - val_loss: 704.1303\n",
      "Epoch 15/20\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 109.3634 - val_loss: 703.6275\n",
      "Epoch 16/20\n",
      "16500/16500 [==============================] - 2s 106us/sample - loss: 109.3637 - val_loss: 704.7299\n",
      "Epoch 17/20\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 109.3694 - val_loss: 705.9451\n",
      "Epoch 18/20\n",
      "16500/16500 [==============================] - 2s 112us/sample - loss: 109.3707 - val_loss: 705.3450\n",
      "Epoch 19/20\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 109.3633 - val_loss: 707.7992\n",
      "Epoch 20/20\n",
      "16500/16500 [==============================] - 2s 103us/sample - loss: 109.3683 - val_loss: 708.4188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x5bd543290>"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 8), (8, 8), (8,), (8, 1), (1,)]"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = model.get_weights()\n",
    "[ r.shape for r in w ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.5911007 , -0.09386152,  0.7858523 ,  0.13839978, -0.04129133,\n",
       "         -0.1983273 ,  0.19056714,  0.12164313]], dtype=float32),\n",
       " array([[ 0.66170406,  0.07864968, -0.0857741 ,  0.00465569,  0.23122407,\n",
       "          0.23979928,  0.29800957, -0.6132319 ],\n",
       "        [ 0.10043948,  0.43177623,  0.54822636,  0.04553895, -0.08450262,\n",
       "          0.6372433 , -0.10235932,  0.24625379],\n",
       "        [-0.18622677,  0.424772  , -0.18163659,  0.07859045, -0.08238811,\n",
       "         -0.03797168, -0.71313715, -0.48532724],\n",
       "        [-0.20455588, -0.30253392, -0.22140023, -0.40680477, -0.7330993 ,\n",
       "          0.3933699 ,  0.03625377, -0.23546964],\n",
       "        [-0.01476307,  0.21162851,  0.42626294, -0.7794128 ,  0.11725012,\n",
       "         -0.36578918,  0.05476402, -0.14893378],\n",
       "        [ 0.52338564,  0.25230432, -0.4987298 , -0.30956528, -0.07566322,\n",
       "         -0.06359223, -0.22296605,  0.49302447],\n",
       "        [-0.19393167,  0.61659366, -0.1611582 ,  0.20718573, -0.4673722 ,\n",
       "         -0.25404182,  0.53650063, -0.04978885],\n",
       "        [-0.4046928 ,  0.2163184 , -0.3920171 , -0.28283706,  0.49904898,\n",
       "          0.42172575,  0.22424993,  0.06770453]], dtype=float32),\n",
       " array([ 0.        ,  0.        ,  0.        ,  0.        , -0.06930923,\n",
       "         0.        ,  0.        ,  0.        ], dtype=float32),\n",
       " array([[-23.82826 ],\n",
       "        [-24.181868],\n",
       "        [ 23.638296],\n",
       "        [ 22.775738],\n",
       "        [-24.149534],\n",
       "        [-23.5807  ],\n",
       "        [ 23.79372 ],\n",
       "        [ 24.139091]], dtype=float32),\n",
       " array([23.580362], dtype=float32)]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 7ms/sample - loss: 487.4119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "487.41192626953125"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(vx[:1], vy[:1], batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[235.622],\n",
       "        [235.671],\n",
       "        [235.688],\n",
       "        [235.73 ],\n",
       "        [235.936],\n",
       "        [236.08 ],\n",
       "        [236.042],\n",
       "        [236.059],\n",
       "        [235.961],\n",
       "        [236.   ],\n",
       "        [235.96 ],\n",
       "        [235.901],\n",
       "        [235.8  ],\n",
       "        [235.785],\n",
       "        [235.82 ],\n",
       "        [235.759],\n",
       "        [235.761],\n",
       "        [235.7  ],\n",
       "        [235.585],\n",
       "        [235.639]],\n",
       "\n",
       "       [[235.671],\n",
       "        [235.688],\n",
       "        [235.73 ],\n",
       "        [235.936],\n",
       "        [236.08 ],\n",
       "        [236.042],\n",
       "        [236.059],\n",
       "        [235.961],\n",
       "        [236.   ],\n",
       "        [235.96 ],\n",
       "        [235.901],\n",
       "        [235.8  ],\n",
       "        [235.785],\n",
       "        [235.82 ],\n",
       "        [235.759],\n",
       "        [235.761],\n",
       "        [235.7  ],\n",
       "        [235.585],\n",
       "        [235.639],\n",
       "        [235.735]],\n",
       "\n",
       "       [[235.688],\n",
       "        [235.73 ],\n",
       "        [235.936],\n",
       "        [236.08 ],\n",
       "        [236.042],\n",
       "        [236.059],\n",
       "        [235.961],\n",
       "        [236.   ],\n",
       "        [235.96 ],\n",
       "        [235.901],\n",
       "        [235.8  ],\n",
       "        [235.785],\n",
       "        [235.82 ],\n",
       "        [235.759],\n",
       "        [235.761],\n",
       "        [235.7  ],\n",
       "        [235.585],\n",
       "        [235.639],\n",
       "        [235.735],\n",
       "        [235.745]],\n",
       "\n",
       "       [[235.73 ],\n",
       "        [235.936],\n",
       "        [236.08 ],\n",
       "        [236.042],\n",
       "        [236.059],\n",
       "        [235.961],\n",
       "        [236.   ],\n",
       "        [235.96 ],\n",
       "        [235.901],\n",
       "        [235.8  ],\n",
       "        [235.785],\n",
       "        [235.82 ],\n",
       "        [235.759],\n",
       "        [235.761],\n",
       "        [235.7  ],\n",
       "        [235.585],\n",
       "        [235.639],\n",
       "        [235.735],\n",
       "        [235.745],\n",
       "        [235.711]],\n",
       "\n",
       "       [[235.936],\n",
       "        [236.08 ],\n",
       "        [236.042],\n",
       "        [236.059],\n",
       "        [235.961],\n",
       "        [236.   ],\n",
       "        [235.96 ],\n",
       "        [235.901],\n",
       "        [235.8  ],\n",
       "        [235.785],\n",
       "        [235.82 ],\n",
       "        [235.759],\n",
       "        [235.761],\n",
       "        [235.7  ],\n",
       "        [235.585],\n",
       "        [235.639],\n",
       "        [235.735],\n",
       "        [235.745],\n",
       "        [235.711],\n",
       "        [235.696]],\n",
       "\n",
       "       [[236.08 ],\n",
       "        [236.042],\n",
       "        [236.059],\n",
       "        [235.961],\n",
       "        [236.   ],\n",
       "        [235.96 ],\n",
       "        [235.901],\n",
       "        [235.8  ],\n",
       "        [235.785],\n",
       "        [235.82 ],\n",
       "        [235.759],\n",
       "        [235.761],\n",
       "        [235.7  ],\n",
       "        [235.585],\n",
       "        [235.639],\n",
       "        [235.735],\n",
       "        [235.745],\n",
       "        [235.711],\n",
       "        [235.696],\n",
       "        [235.765]],\n",
       "\n",
       "       [[236.042],\n",
       "        [236.059],\n",
       "        [235.961],\n",
       "        [236.   ],\n",
       "        [235.96 ],\n",
       "        [235.901],\n",
       "        [235.8  ],\n",
       "        [235.785],\n",
       "        [235.82 ],\n",
       "        [235.759],\n",
       "        [235.761],\n",
       "        [235.7  ],\n",
       "        [235.585],\n",
       "        [235.639],\n",
       "        [235.735],\n",
       "        [235.745],\n",
       "        [235.711],\n",
       "        [235.696],\n",
       "        [235.765],\n",
       "        [235.766]],\n",
       "\n",
       "       [[236.059],\n",
       "        [235.961],\n",
       "        [236.   ],\n",
       "        [235.96 ],\n",
       "        [235.901],\n",
       "        [235.8  ],\n",
       "        [235.785],\n",
       "        [235.82 ],\n",
       "        [235.759],\n",
       "        [235.761],\n",
       "        [235.7  ],\n",
       "        [235.585],\n",
       "        [235.639],\n",
       "        [235.735],\n",
       "        [235.745],\n",
       "        [235.711],\n",
       "        [235.696],\n",
       "        [235.765],\n",
       "        [235.766],\n",
       "        [235.783]],\n",
       "\n",
       "       [[235.961],\n",
       "        [236.   ],\n",
       "        [235.96 ],\n",
       "        [235.901],\n",
       "        [235.8  ],\n",
       "        [235.785],\n",
       "        [235.82 ],\n",
       "        [235.759],\n",
       "        [235.761],\n",
       "        [235.7  ],\n",
       "        [235.585],\n",
       "        [235.639],\n",
       "        [235.735],\n",
       "        [235.745],\n",
       "        [235.711],\n",
       "        [235.696],\n",
       "        [235.765],\n",
       "        [235.766],\n",
       "        [235.783],\n",
       "        [235.78 ]],\n",
       "\n",
       "       [[236.   ],\n",
       "        [235.96 ],\n",
       "        [235.901],\n",
       "        [235.8  ],\n",
       "        [235.785],\n",
       "        [235.82 ],\n",
       "        [235.759],\n",
       "        [235.761],\n",
       "        [235.7  ],\n",
       "        [235.585],\n",
       "        [235.639],\n",
       "        [235.735],\n",
       "        [235.745],\n",
       "        [235.711],\n",
       "        [235.696],\n",
       "        [235.765],\n",
       "        [235.766],\n",
       "        [235.783],\n",
       "        [235.78 ],\n",
       "        [235.887]]])"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[213.66759],\n",
       "       [213.66759],\n",
       "       [213.66759],\n",
       "       [213.66759],\n",
       "       [213.66759],\n",
       "       [213.66759],\n",
       "       [213.66759],\n",
       "       [213.66759],\n",
       "       [213.66759],\n",
       "       [213.66759]], dtype=float32)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(vx[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1963/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 32us/sample - loss: 801.5727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "708.4187838787093"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(vx, vy, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AAPL-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24960, 8)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = aapl.shape\n",
    "aapl = aapl.reshape((shape[0] * shape[1], shape[2]))\n",
    "shape = aapl.shape; shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([214.718, 215.417, 215.43 , ..., 243.282, 243.258, 243.297])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgs = aapl[:, 4]; avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24959, 8), (24959,))"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.roll(avgs, -1)\n",
    "y = y[:-1]\n",
    "x = aapl[:-1]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24939, 20, 8), (24939,))"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window = 20\n",
    "n = x.shape[0]\n",
    "x = np.array([ x[i:(i+window)] for i in range(n-window) ])\n",
    "y = y[window:]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18463, 20, 8), (18463,))"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = np.logical_and([ (cnz(na(row)) == 0) for row in x ], ~na(y))\n",
    "y = y[idxs]\n",
    "x = x[idxs]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = x.shape[0]\n",
    "val = 1963\n",
    "trn = n - val\n",
    "tx, ty = x[:trn], y[:trn]\n",
    "vx, vy = x[trn:], y[trn:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18463,), (18463,))"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,-1,4].shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([214.435, 214.594, 214.476, ..., 243.282, 243.258, 243.297])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.059, -0.289, -0.041, ...,  0.202,  0.161, -0.015])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06451057146725886"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = x[:,-1,4] - y\n",
    "np.mean(d**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(16500, 20, 8), (16500,), (1963, 20, 8), (1963,)]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ a.shape for a in [tx,ty,vx,vy] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 32)                5248      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 5,281\n",
      "Trainable params: 5,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    LSTM(32, input_shape=(window, len(features))),\n",
    "    Dense(1),\n",
    "])\n",
    "model.build()\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/20\n",
      "16500/16500 [==============================] - 5s 308us/sample - loss: 44988.6397 - val_loss: 55906.6671\n",
      "Epoch 2/20\n",
      "16500/16500 [==============================] - 3s 171us/sample - loss: 43137.6257 - val_loss: 53393.1119\n",
      "Epoch 3/20\n",
      "16500/16500 [==============================] - 3s 175us/sample - loss: 41233.0813 - val_loss: 51560.3246\n",
      "Epoch 4/20\n",
      "16500/16500 [==============================] - 3s 179us/sample - loss: 39622.2297 - val_loss: 49728.6806\n",
      "Epoch 5/20\n",
      "16500/16500 [==============================] - 3s 174us/sample - loss: 37480.2085 - val_loss: 46678.4399\n",
      "Epoch 6/20\n",
      "16500/16500 [==============================] - 3s 170us/sample - loss: 35155.7298 - val_loss: 44440.6561\n",
      "Epoch 7/20\n",
      "16500/16500 [==============================] - 3s 172us/sample - loss: 33338.3102 - val_loss: 42551.0105\n",
      "Epoch 8/20\n",
      "16500/16500 [==============================] - 3s 180us/sample - loss: 31739.7855 - val_loss: 40770.5517\n",
      "Epoch 9/20\n",
      "16500/16500 [==============================] - 3s 172us/sample - loss: 30224.1840 - val_loss: 39065.1387\n",
      "Epoch 10/20\n",
      "16500/16500 [==============================] - 3s 170us/sample - loss: 28771.3893 - val_loss: 37419.8548\n",
      "Epoch 11/20\n",
      "16500/16500 [==============================] - 3s 175us/sample - loss: 27371.4636 - val_loss: 35826.1798\n",
      "Epoch 12/20\n",
      "16500/16500 [==============================] - 3s 178us/sample - loss: 26018.5757 - val_loss: 34275.5493\n",
      "Epoch 13/20\n",
      "16500/16500 [==============================] - 3s 169us/sample - loss: 24708.2888 - val_loss: 32771.7443\n",
      "Epoch 14/20\n",
      "16500/16500 [==============================] - 3s 170us/sample - loss: 23439.9464 - val_loss: 31309.1213\n",
      "Epoch 15/20\n",
      "16500/16500 [==============================] - 3s 169us/sample - loss: 22210.9555 - val_loss: 29886.4189\n",
      "Epoch 16/20\n",
      "16500/16500 [==============================] - 3s 181us/sample - loss: 21020.0687 - val_loss: 28501.9039\n",
      "Epoch 17/20\n",
      "16500/16500 [==============================] - 3s 184us/sample - loss: 19866.3794 - val_loss: 27155.1668\n",
      "Epoch 18/20\n",
      "16500/16500 [==============================] - 3s 172us/sample - loss: 18749.2058 - val_loss: 25845.0854\n",
      "Epoch 19/20\n",
      "16500/16500 [==============================] - 3s 171us/sample - loss: 17668.0538 - val_loss: 24571.6055\n",
      "Epoch 20/20\n",
      "16500/16500 [==============================] - 3s 180us/sample - loss: 16622.4917 - val_loss: 23334.2280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13e944d10>"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/20\n",
      "16500/16500 [==============================] - 3s 196us/sample - loss: 15612.2131 - val_loss: 22132.6820\n",
      "Epoch 2/20\n",
      "16500/16500 [==============================] - 3s 177us/sample - loss: 14636.8450 - val_loss: 20966.6546\n",
      "Epoch 3/20\n",
      "16500/16500 [==============================] - 3s 169us/sample - loss: 13696.1606 - val_loss: 19835.6729\n",
      "Epoch 4/20\n",
      "16500/16500 [==============================] - 3s 168us/sample - loss: 12789.9664 - val_loss: 18739.8554\n",
      "Epoch 5/20\n",
      "16500/16500 [==============================] - 3s 167us/sample - loss: 11918.1591 - val_loss: 17679.0931\n",
      "Epoch 6/20\n",
      "16500/16500 [==============================] - 3s 189us/sample - loss: 11080.4502 - val_loss: 16653.1755\n",
      "Epoch 7/20\n",
      "16500/16500 [==============================] - 3s 164us/sample - loss: 10276.5481 - val_loss: 15661.6208\n",
      "Epoch 8/20\n",
      "16500/16500 [==============================] - 3s 161us/sample - loss: 9506.3863 - val_loss: 14704.9840\n",
      "Epoch 9/20\n",
      "16500/16500 [==============================] - 3s 179us/sample - loss: 8769.7136 - val_loss: 13782.2635\n",
      "Epoch 10/20\n",
      "16500/16500 [==============================] - 3s 193us/sample - loss: 8066.3573 - val_loss: 12893.6561\n",
      "Epoch 11/20\n",
      "16500/16500 [==============================] - 3s 160us/sample - loss: 7396.1374 - val_loss: 12039.4758\n",
      "Epoch 12/20\n",
      "16500/16500 [==============================] - 3s 169us/sample - loss: 6758.8128 - val_loss: 11218.9557\n",
      "Epoch 13/20\n",
      "16500/16500 [==============================] - 3s 178us/sample - loss: 6154.0822 - val_loss: 10432.2643\n",
      "Epoch 14/20\n",
      "16500/16500 [==============================] - 3s 161us/sample - loss: 5581.6903 - val_loss: 9678.9815\n",
      "Epoch 15/20\n",
      "16500/16500 [==============================] - 3s 168us/sample - loss: 5041.4148 - val_loss: 8958.9880\n",
      "Epoch 16/20\n",
      "16500/16500 [==============================] - 3s 162us/sample - loss: 4532.8922 - val_loss: 8272.3027\n",
      "Epoch 17/20\n",
      "16500/16500 [==============================] - 3s 172us/sample - loss: 4055.7866 - val_loss: 7618.3019\n",
      "Epoch 18/20\n",
      "16500/16500 [==============================] - 3s 165us/sample - loss: 3609.8117 - val_loss: 6997.2377\n",
      "Epoch 19/20\n",
      "16500/16500 [==============================] - 3s 168us/sample - loss: 3194.5773 - val_loss: 6408.5697\n",
      "Epoch 20/20\n",
      "16500/16500 [==============================] - 3s 164us/sample - loss: 2809.5651 - val_loss: 5852.0548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14c24cd50>"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/20\n",
      "16500/16500 [==============================] - 3s 175us/sample - loss: 2454.3287 - val_loss: 5327.2482\n",
      "Epoch 2/20\n",
      "16500/16500 [==============================] - 3s 177us/sample - loss: 2128.3118 - val_loss: 4833.9684\n",
      "Epoch 3/20\n",
      "16500/16500 [==============================] - 3s 178us/sample - loss: 1830.9780 - val_loss: 4372.2482\n",
      "Epoch 4/20\n",
      "16500/16500 [==============================] - 3s 159us/sample - loss: 1561.7360 - val_loss: 3941.0871\n",
      "Epoch 5/20\n",
      "16500/16500 [==============================] - 3s 161us/sample - loss: 1319.8299 - val_loss: 3540.4152\n",
      "Epoch 6/20\n",
      "16500/16500 [==============================] - 3s 167us/sample - loss: 1104.4000 - val_loss: 3169.9071\n",
      "Epoch 7/20\n",
      "16500/16500 [==============================] - 3s 174us/sample - loss: 914.5995 - val_loss: 2829.1018\n",
      "Epoch 8/20\n",
      "16500/16500 [==============================] - 3s 161us/sample - loss: 749.3585 - val_loss: 2516.5574\n",
      "Epoch 9/20\n",
      "16500/16500 [==============================] - 3s 162us/sample - loss: 607.5209 - val_loss: 2233.0698\n",
      "Epoch 10/20\n",
      "16500/16500 [==============================] - 3s 162us/sample - loss: 487.8236 - val_loss: 1977.0174\n",
      "Epoch 11/20\n",
      "16500/16500 [==============================] - 3s 166us/sample - loss: 388.9023 - val_loss: 1748.5269\n",
      "Epoch 12/20\n",
      "16500/16500 [==============================] - 3s 161us/sample - loss: 309.1250 - val_loss: 1546.3894\n",
      "Epoch 13/20\n",
      "16500/16500 [==============================] - 3s 168us/sample - loss: 246.5982 - val_loss: 1369.7267\n",
      "Epoch 14/20\n",
      "16500/16500 [==============================] - 3s 159us/sample - loss: 199.2696 - val_loss: 1217.6282\n",
      "Epoch 15/20\n",
      "16500/16500 [==============================] - 3s 172us/sample - loss: 165.0059 - val_loss: 1089.2970\n",
      "Epoch 16/20\n",
      "16500/16500 [==============================] - 3s 161us/sample - loss: 141.5290 - val_loss: 983.3937\n",
      "Epoch 17/20\n",
      "16500/16500 [==============================] - 3s 161us/sample - loss: 126.4880 - val_loss: 898.6555\n",
      "Epoch 18/20\n",
      "16500/16500 [==============================] - 3s 172us/sample - loss: 117.6403 - val_loss: 832.9713\n",
      "Epoch 19/20\n",
      "16500/16500 [==============================] - 3s 178us/sample - loss: 112.9066 - val_loss: 784.6077\n",
      "Epoch 20/20\n",
      "16500/16500 [==============================] - 3s 178us/sample - loss: 110.6566 - val_loss: 750.5994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14c4cf390>"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/20\n",
      "16500/16500 [==============================] - 3s 183us/sample - loss: 109.7586 - val_loss: 729.1833\n",
      "Epoch 2/20\n",
      "16500/16500 [==============================] - 3s 166us/sample - loss: 109.4629 - val_loss: 717.4735\n",
      "Epoch 3/20\n",
      "16500/16500 [==============================] - 3s 163us/sample - loss: 109.3833 - val_loss: 711.8775\n",
      "Epoch 4/20\n",
      "16500/16500 [==============================] - 3s 161us/sample - loss: 109.3683 - val_loss: 708.9282\n",
      "Epoch 5/20\n",
      "16500/16500 [==============================] - 3s 168us/sample - loss: 109.3620 - val_loss: 706.8166\n",
      "Epoch 6/20\n",
      "16500/16500 [==============================] - 3s 169us/sample - loss: 109.3614 - val_loss: 707.7023\n",
      "Epoch 7/20\n",
      "16500/16500 [==============================] - 3s 165us/sample - loss: 109.3625 - val_loss: 708.9257\n",
      "Epoch 8/20\n",
      "16500/16500 [==============================] - 3s 162us/sample - loss: 109.3665 - val_loss: 706.3144\n",
      "Epoch 9/20\n",
      "16500/16500 [==============================] - 3s 171us/sample - loss: 109.3630 - val_loss: 705.9467\n",
      "Epoch 10/20\n",
      "16500/16500 [==============================] - 3s 159us/sample - loss: 109.3650 - val_loss: 705.4353\n",
      "Epoch 11/20\n",
      "16500/16500 [==============================] - 3s 158us/sample - loss: 109.3717 - val_loss: 706.7183\n",
      "Epoch 12/20\n",
      "16500/16500 [==============================] - 3s 170us/sample - loss: 109.3653 - val_loss: 707.8912\n",
      "Epoch 13/20\n",
      "16500/16500 [==============================] - 3s 177us/sample - loss: 109.3689 - val_loss: 707.3366\n",
      "Epoch 14/20\n",
      "16500/16500 [==============================] - 3s 165us/sample - loss: 109.3651 - val_loss: 706.8102\n",
      "Epoch 15/20\n",
      "16500/16500 [==============================] - 3s 162us/sample - loss: 109.3672 - val_loss: 709.3584\n",
      "Epoch 16/20\n",
      "16500/16500 [==============================] - 3s 162us/sample - loss: 109.3759 - val_loss: 707.5535\n",
      "Epoch 17/20\n",
      "16500/16500 [==============================] - 3s 170us/sample - loss: 109.3658 - val_loss: 703.7241\n",
      "Epoch 18/20\n",
      "16500/16500 [==============================] - 3s 162us/sample - loss: 109.3665 - val_loss: 710.2617\n",
      "Epoch 19/20\n",
      "16500/16500 [==============================] - 3s 159us/sample - loss: 109.3739 - val_loss: 704.9416\n",
      "Epoch 20/20\n",
      "16500/16500 [==============================] - 3s 161us/sample - loss: 109.3710 - val_loss: 708.1722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14c59a090>"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_14 (SimpleRNN)    (None, 32)                1312      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    SimpleRNN(32, input_shape=(window, len(features))),\n",
    "    Dense(1),\n",
    "])\n",
    "model.build()\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/20\n",
      "16500/16500 [==============================] - 3s 205us/sample - loss: 43744.4861 - val_loss: 52791.8456\n",
      "Epoch 2/20\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 39417.0714 - val_loss: 48090.3541\n",
      "Epoch 3/20\n",
      "16500/16500 [==============================] - 2s 135us/sample - loss: 35407.1841 - val_loss: 43707.5682\n",
      "Epoch 4/20\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 31693.2392 - val_loss: 39619.5789\n",
      "Epoch 5/20\n",
      "16500/16500 [==============================] - 2s 110us/sample - loss: 28255.7276 - val_loss: 35809.1404\n",
      "Epoch 6/20\n",
      "16500/16500 [==============================] - 2s 110us/sample - loss: 25077.8794 - val_loss: 32258.6856\n",
      "Epoch 7/20\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 22145.1686 - val_loss: 28954.1052\n",
      "Epoch 8/20\n",
      "16500/16500 [==============================] - 2s 111us/sample - loss: 19444.3579 - val_loss: 25884.8197\n",
      "Epoch 9/20\n",
      "16500/16500 [==============================] - 2s 113us/sample - loss: 16964.7800 - val_loss: 23039.3409\n",
      "Epoch 10/20\n",
      "16500/16500 [==============================] - 2s 112us/sample - loss: 14691.7711 - val_loss: 20387.1877\n",
      "Epoch 11/20\n",
      "16500/16500 [==============================] - 2s 112us/sample - loss: 12623.9145 - val_loss: 17959.4870\n",
      "Epoch 12/20\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 10750.1104 - val_loss: 15730.2055\n",
      "Epoch 13/20\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 9062.0190 - val_loss: 13690.9536\n",
      "Epoch 14/20\n",
      "16500/16500 [==============================] - 2s 116us/sample - loss: 7552.2398 - val_loss: 11837.0855\n",
      "Epoch 15/20\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 6213.1846 - val_loss: 10153.5960\n",
      "Epoch 16/20\n",
      "16500/16500 [==============================] - 2s 111us/sample - loss: 5037.5249 - val_loss: 8647.9683\n",
      "Epoch 17/20\n",
      "16500/16500 [==============================] - 2s 111us/sample - loss: 4018.1626 - val_loss: 7307.1831\n",
      "Epoch 18/20\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 3146.2787 - val_loss: 6123.2397\n",
      "Epoch 19/20\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 2413.0523 - val_loss: 5089.6445\n",
      "Epoch 20/20\n",
      "16500/16500 [==============================] - 2s 118us/sample - loss: 1808.8141 - val_loss: 4198.3317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14b0b2d90>"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/20\n",
      "16500/16500 [==============================] - 2s 111us/sample - loss: 1322.8062 - val_loss: 3439.4641\n",
      "Epoch 2/20\n",
      "16500/16500 [==============================] - 2s 117us/sample - loss: 943.3676 - val_loss: 2805.0609\n",
      "Epoch 3/20\n",
      "16500/16500 [==============================] - 2s 116us/sample - loss: 657.7758 - val_loss: 2283.8627\n",
      "Epoch 4/20\n",
      "16500/16500 [==============================] - 2s 106us/sample - loss: 452.0818 - val_loss: 1864.7974\n",
      "Epoch 5/20\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 312.0048 - val_loss: 1536.3445\n",
      "Epoch 6/20\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 223.0949 - val_loss: 1287.4983\n",
      "Epoch 7/20\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 171.1751 - val_loss: 1104.2713\n",
      "Epoch 8/20\n",
      "16500/16500 [==============================] - 2s 122us/sample - loss: 143.9120 - val_loss: 975.7463\n",
      "Epoch 9/20\n",
      "16500/16500 [==============================] - 2s 113us/sample - loss: 131.2897 - val_loss: 890.1772\n",
      "Epoch 10/20\n",
      "16500/16500 [==============================] - 2s 110us/sample - loss: 126.2974 - val_loss: 838.0555\n",
      "Epoch 11/20\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 124.6442 - val_loss: 808.0453\n",
      "Epoch 12/20\n",
      "16500/16500 [==============================] - 2s 113us/sample - loss: 124.1834 - val_loss: 793.3058\n",
      "Epoch 13/20\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 123.8853 - val_loss: 769.3643\n",
      "Epoch 14/20\n",
      "16500/16500 [==============================] - 2s 119us/sample - loss: 119.8746 - val_loss: 760.8050\n",
      "Epoch 15/20\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 119.7567 - val_loss: 759.0458\n",
      "Epoch 16/20\n",
      "16500/16500 [==============================] - 2s 107us/sample - loss: 119.7288 - val_loss: 760.9418\n",
      "Epoch 17/20\n",
      "16500/16500 [==============================] - 2s 111us/sample - loss: 119.6888 - val_loss: 761.2651\n",
      "Epoch 18/20\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 119.6456 - val_loss: 760.9383\n",
      "Epoch 19/20\n",
      "16500/16500 [==============================] - 2s 110us/sample - loss: 119.5956 - val_loss: 756.6199\n",
      "Epoch 20/20\n",
      "16500/16500 [==============================] - 2s 121us/sample - loss: 119.5371 - val_loss: 760.5915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13e3b2390>"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_13 (SimpleRNN)    (None, 32)                1312      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    SimpleRNN(32, input_shape=(window, len(features))),\n",
    "    Dense(1),\n",
    "])\n",
    "model.build()\n",
    "model.compile(loss='mse', optimizer='sgd')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "16500/16500 [==============================] - 3s 175us/sample - loss: 290.1315 - val_loss: 720.6219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14cde1110>"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/10\n",
      "16500/16500 [==============================] - 2s 119us/sample - loss: 120.7651 - val_loss: 744.7262\n",
      "Epoch 2/10\n",
      "16500/16500 [==============================] - 2s 104us/sample - loss: 117.0561 - val_loss: 790.6062\n",
      "Epoch 3/10\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 114.3773 - val_loss: 809.7257\n",
      "Epoch 4/10\n",
      "16500/16500 [==============================] - 2s 110us/sample - loss: 113.1029 - val_loss: 642.6632\n",
      "Epoch 5/10\n",
      "16500/16500 [==============================] - 2s 115us/sample - loss: 111.9965 - val_loss: 654.1763\n",
      "Epoch 6/10\n",
      "16500/16500 [==============================] - 2s 113us/sample - loss: 111.4130 - val_loss: 774.6058\n",
      "Epoch 7/10\n",
      "16500/16500 [==============================] - 2s 125us/sample - loss: 111.1374 - val_loss: 697.1080\n",
      "Epoch 8/10\n",
      "16500/16500 [==============================] - 2s 123us/sample - loss: 110.8589 - val_loss: 682.0563\n",
      "Epoch 9/10\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 110.5949 - val_loss: 627.7275\n",
      "Epoch 10/10\n",
      "16500/16500 [==============================] - 2s 110us/sample - loss: 110.6254 - val_loss: 739.7249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14abcd410>"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples, validate on 1963 samples\n",
      "Epoch 1/20\n",
      "16500/16500 [==============================] - 2s 120us/sample - loss: 110.7725 - val_loss: 691.8990\n",
      "Epoch 2/20\n",
      "16500/16500 [==============================] - 2s 121us/sample - loss: 110.1673 - val_loss: 620.4467\n",
      "Epoch 3/20\n",
      "16500/16500 [==============================] - 2s 124us/sample - loss: 110.5189 - val_loss: 718.1927\n",
      "Epoch 4/20\n",
      "16500/16500 [==============================] - 2s 121us/sample - loss: 110.1622 - val_loss: 682.8046\n",
      "Epoch 5/20\n",
      "16500/16500 [==============================] - 2s 117us/sample - loss: 110.4196 - val_loss: 765.1008\n",
      "Epoch 6/20\n",
      "16500/16500 [==============================] - 2s 114us/sample - loss: 110.3792 - val_loss: 675.9035\n",
      "Epoch 7/20\n",
      "16500/16500 [==============================] - 2s 111us/sample - loss: 110.5333 - val_loss: 632.6029\n",
      "Epoch 8/20\n",
      "16500/16500 [==============================] - 2s 122us/sample - loss: 110.2806 - val_loss: 764.4253\n",
      "Epoch 9/20\n",
      "16500/16500 [==============================] - 2s 115us/sample - loss: 110.3655 - val_loss: 722.8224\n",
      "Epoch 10/20\n",
      "16500/16500 [==============================] - 2s 105us/sample - loss: 110.3473 - val_loss: 757.1707\n",
      "Epoch 11/20\n",
      "16500/16500 [==============================] - 2s 104us/sample - loss: 110.0416 - val_loss: 806.8209\n",
      "Epoch 12/20\n",
      "16500/16500 [==============================] - 2s 104us/sample - loss: 110.5190 - val_loss: 659.2229\n",
      "Epoch 13/20\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 110.3905 - val_loss: 707.0236\n",
      "Epoch 14/20\n",
      "16500/16500 [==============================] - 2s 111us/sample - loss: 110.2008 - val_loss: 697.8478\n",
      "Epoch 15/20\n",
      "16500/16500 [==============================] - 2s 115us/sample - loss: 110.3087 - val_loss: 806.5762\n",
      "Epoch 16/20\n",
      "16500/16500 [==============================] - 2s 114us/sample - loss: 110.3246 - val_loss: 849.2922\n",
      "Epoch 17/20\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 110.0890 - val_loss: 729.7543\n",
      "Epoch 18/20\n",
      "16500/16500 [==============================] - 2s 109us/sample - loss: 110.3866 - val_loss: 679.1658\n",
      "Epoch 19/20\n",
      "16500/16500 [==============================] - 2s 112us/sample - loss: 110.5417 - val_loss: 632.7462\n",
      "Epoch 20/20\n",
      "16500/16500 [==============================] - 2s 112us/sample - loss: 110.2991 - val_loss: 704.9558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14ae8b190>"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=50,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-ticker attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = \\\n",
    "    array(\n",
    "        Parallel(n_jobs=8)(delayed(load_date_arr)(date) for date in dates)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24960"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 390, 505, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape =  all.shape; shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24960, 505, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = all.reshape(shape[0] * shape[1], *shape[2:]); all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(str(data_dir / 'all.npy'), all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24960, 4040)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = all.shape\n",
    "all = all.reshape(shape[:-2] + ((shape[-2] * shape[-1],)))\n",
    "shape = all.shape\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9792"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np.isnan(all[:, aapl_avg]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15168, 4040)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = all[~np.isnan(all[:, aapl_avg])]\n",
    "shape = all.shape; shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15167,), array([ 91.835, 204.915,  85.943, ...,  61.1  ,  54.221, 138.386]))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_avg = aapl * len(features) + 4\n",
    "out = all[:, aapl_avg]\n",
    "out = np.roll(out, -1)[:-1]\n",
    "all = all[:-1]\n",
    "shape = all.shape\n",
    "out.shape, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randint, shuffle\n",
    "from numpy import arange, nan_to_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 20\n",
    "\n",
    "def make_train_val_idxs(train=None, val=None):\n",
    "    num_samples = shape[0] - time_steps\n",
    "\n",
    "    if train is None and val is None:\n",
    "        raise Exception('Specify at least one of {train, val}')\n",
    "            \n",
    "    if train is not None and train < 1:\n",
    "        train = int(train * num_samples)\n",
    "\n",
    "    if val is not None and val < 1:\n",
    "        val = int(train * num_samples)\n",
    "    \n",
    "    if val is None:\n",
    "        val = num_samples - train\n",
    "    \n",
    "    if train is None:\n",
    "        train = num_samples - val\n",
    "    \n",
    "    if train + val > num_samples:\n",
    "        raise Exception('%d + %d > %d' % (train, val, num_samples))\n",
    "\n",
    "    sample_idxs = arange(time_steps, shape[0])\n",
    "    shuffle(sample_idxs)\n",
    "    training_idxs = sample_idxs[:train]\n",
    "    validation_idxs = sample_idxs[-val:]\n",
    "    return (training_idxs, validation_idxs)\n",
    "\n",
    "def make_train_val_sets(train=None, val=None):\n",
    "    train_idxs, val_idxs = make_train_val_idxs(train, val)\n",
    "    train_x = nan_to_num(array([ all[(idx - time_steps):idx] for idx in train_idxs ]))\n",
    "    train_y = nan_to_num(array([ all[idx][aapl_avg] for idx in train_idxs ]))\n",
    "    val_x = nan_to_num(array([ all[(idx - time_steps):idx] for idx in val_idxs ]))\n",
    "    val_y = nan_to_num(array([ all[idx][aapl_avg] for idx in val_idxs ]))\n",
    "    return (\n",
    "        train_x,\n",
    "        train_y,\n",
    "        val_x,\n",
    "        val_y,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12000, 20, 4040), (12000,), (1000, 20, 4040), (1000,)]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, train_y, val_x, val_y = make_train_val_sets(12000, 1000)\n",
    "[ a.shape for a in [train_x, train_y, val_x, val_y]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15167"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{python} -m pip install -Uq tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    SimpleRNN(32, input_shape=(time_steps, num_tickers * len(features))),\n",
    "    Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_7 (SimpleRNN)     (None, 32)                130336    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 130,369\n",
      "Trainable params: 130,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples\n",
      "Epoch 1/10\n",
      "12000/12000 [==============================] - 18s 1ms/sample - loss: 16344.0626\n",
      "Epoch 2/10\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15546.2652\n",
      "Epoch 3/10\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15530.9598\n",
      "Epoch 4/10\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15515.1891\n",
      "Epoch 5/10\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15502.5735\n",
      "Epoch 6/10\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15523.4275\n",
      "Epoch 7/10\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15517.6569\n",
      "Epoch 8/10\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15560.4271\n",
      "Epoch 9/10\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15538.1058\n",
      "Epoch 10/10\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15486.1096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1270f7f50>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, \n",
    "          #validation_data=(val_x, val_y),\n",
    "          batch_size=40,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples\n",
      "Epoch 1/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15545.4982\n",
      "Epoch 2/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15530.5658\n",
      "Epoch 3/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15478.8371\n",
      "Epoch 4/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15528.6299\n",
      "Epoch 5/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15508.9193\n",
      "Epoch 6/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15532.5590\n",
      "Epoch 7/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15535.9591\n",
      "Epoch 8/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15509.6757\n",
      "Epoch 9/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15512.1479\n",
      "Epoch 10/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15517.8358\n",
      "Epoch 11/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15523.9614\n",
      "Epoch 12/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15518.6465\n",
      "Epoch 13/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15541.3638\n",
      "Epoch 14/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15542.1389\n",
      "Epoch 15/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15507.6170\n",
      "Epoch 16/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15561.0873\n",
      "Epoch 17/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15500.9340\n",
      "Epoch 18/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15539.4070\n",
      "Epoch 19/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15534.0281\n",
      "Epoch 20/20\n",
      "12000/12000 [==============================] - 14s 1ms/sample - loss: 15519.4072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x127084b10>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, \n",
    "          #validation_data=(val_x, val_y),\n",
    "          batch_size=40,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "12000/12000 [==============================] - 19s 2ms/sample - loss: 15419.7773 - val_loss: 15587.0837\n",
      "Epoch 2/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15412.6172 - val_loss: 15572.2574\n",
      "Epoch 3/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15406.8898 - val_loss: 15560.0918\n",
      "Epoch 4/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15402.4290 - val_loss: 15549.7905\n",
      "Epoch 5/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15398.7806 - val_loss: 15541.3923\n",
      "Epoch 6/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15395.8807 - val_loss: 15533.2663\n",
      "Epoch 7/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15393.4201 - val_loss: 15527.3017\n",
      "Epoch 8/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15391.4413 - val_loss: 15521.6040\n",
      "Epoch 9/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15389.8734 - val_loss: 15516.7603\n",
      "Epoch 10/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15388.4959 - val_loss: 15512.9119\n",
      "Epoch 11/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15387.0527 - val_loss: 15509.6008\n",
      "Epoch 12/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15385.9508 - val_loss: 15506.4874\n",
      "Epoch 13/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15384.9699 - val_loss: 15503.6509\n",
      "Epoch 14/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15384.1889 - val_loss: 15501.5730\n",
      "Epoch 15/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15383.2724 - val_loss: 15499.7572\n",
      "Epoch 16/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15382.4708 - val_loss: 15497.3213\n",
      "Epoch 17/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15381.7436 - val_loss: 15496.3086\n",
      "Epoch 18/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15381.1733 - val_loss: 15494.3058\n",
      "Epoch 19/20\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15380.4043 - val_loss: 15493.8809\n",
      "Epoch 20/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15379.8275 - val_loss: 15492.2244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1289c1c50>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, \n",
    "          validation_data=(val_x, val_y),\n",
    "          batch_size=40,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15379.3563 - val_loss: 15491.4467\n",
      "Epoch 2/20\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15378.7538 - val_loss: 15490.7604\n",
      "Epoch 3/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15378.3939 - val_loss: 15489.9805\n",
      "Epoch 4/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15377.8064 - val_loss: 15489.4879\n",
      "Epoch 5/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15377.2507 - val_loss: 15488.4293\n",
      "Epoch 6/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15376.9178 - val_loss: 15488.1877\n",
      "Epoch 7/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15376.4122 - val_loss: 15488.0419\n",
      "Epoch 8/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15375.9355 - val_loss: 15487.4029\n",
      "Epoch 9/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15375.5048 - val_loss: 15486.7018\n",
      "Epoch 10/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15375.1233 - val_loss: 15486.0648\n",
      "Epoch 11/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15374.7382 - val_loss: 15485.7077\n",
      "Epoch 12/20\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15374.4478 - val_loss: 15485.5669\n",
      "Epoch 13/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15374.1843 - val_loss: 15485.6775\n",
      "Epoch 14/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15373.7617 - val_loss: 15485.1194\n",
      "Epoch 15/20\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15373.3492 - val_loss: 15485.4241\n",
      "Epoch 16/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15373.1051 - val_loss: 15485.3653\n",
      "Epoch 17/20\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15372.8047 - val_loss: 15484.7645\n",
      "Epoch 18/20\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15372.7339 - val_loss: 15484.8161\n",
      "Epoch 19/20\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15372.2522 - val_loss: 15484.3374\n",
      "Epoch 20/20\n",
      "12000/12000 [==============================] - 22s 2ms/sample - loss: 15371.9052 - val_loss: 15484.4379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12939fbd0>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, \n",
    "          validation_data=(val_x, val_y),\n",
    "          batch_size=40,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 1000 samples\n",
      "Epoch 1/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15371.6789 - val_loss: 15484.1590\n",
      "Epoch 2/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15371.4278 - val_loss: 15484.0324\n",
      "Epoch 3/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15371.1502 - val_loss: 15484.1951\n",
      "Epoch 4/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15370.8957 - val_loss: 15483.6107\n",
      "Epoch 5/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15370.7880 - val_loss: 15483.7685\n",
      "Epoch 6/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15370.4712 - val_loss: 15483.7804\n",
      "Epoch 7/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15370.2009 - val_loss: 15484.2235\n",
      "Epoch 8/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15370.0815 - val_loss: 15483.6573\n",
      "Epoch 9/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15369.8132 - val_loss: 15482.9750\n",
      "Epoch 10/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15369.6613 - val_loss: 15483.3149\n",
      "Epoch 11/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15369.4625 - val_loss: 15484.1132\n",
      "Epoch 12/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15369.3379 - val_loss: 15483.3533\n",
      "Epoch 13/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15369.1234 - val_loss: 15484.1715\n",
      "Epoch 14/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15368.9816 - val_loss: 15483.5499\n",
      "Epoch 15/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15368.8965 - val_loss: 15483.5525\n",
      "Epoch 16/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15368.6454 - val_loss: 15483.6662\n",
      "Epoch 17/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15368.5599 - val_loss: 15483.7138\n",
      "Epoch 18/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15368.3201 - val_loss: 15483.7598\n",
      "Epoch 19/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15368.1804 - val_loss: 15483.7244\n",
      "Epoch 20/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15368.0417 - val_loss: 15484.0882\n",
      "Epoch 21/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15367.8634 - val_loss: 15483.8349\n",
      "Epoch 22/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15367.8055 - val_loss: 15484.6852\n",
      "Epoch 23/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15367.6273 - val_loss: 15484.4225\n",
      "Epoch 24/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15367.4939 - val_loss: 15483.9248\n",
      "Epoch 25/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15367.5515 - val_loss: 15484.5072\n",
      "Epoch 26/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15367.2620 - val_loss: 15484.0268\n",
      "Epoch 27/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15367.1751 - val_loss: 15484.4700\n",
      "Epoch 28/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15367.0119 - val_loss: 15484.5364\n",
      "Epoch 29/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15366.9254 - val_loss: 15484.7621\n",
      "Epoch 30/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15366.7972 - val_loss: 15484.0090\n",
      "Epoch 31/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15366.7314 - val_loss: 15484.5938\n",
      "Epoch 32/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15366.6675 - val_loss: 15484.6505\n",
      "Epoch 33/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15366.5920 - val_loss: 15485.5281\n",
      "Epoch 34/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15366.4706 - val_loss: 15485.0909\n",
      "Epoch 35/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15366.3468 - val_loss: 15484.9207\n",
      "Epoch 36/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15366.3199 - val_loss: 15484.9928\n",
      "Epoch 37/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15366.2021 - val_loss: 15485.0962\n",
      "Epoch 38/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15366.1154 - val_loss: 15485.0625\n",
      "Epoch 39/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15366.0865 - val_loss: 15484.7033\n",
      "Epoch 40/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.9530 - val_loss: 15484.6859\n",
      "Epoch 41/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15365.9066 - val_loss: 15484.9037\n",
      "Epoch 42/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.8852 - val_loss: 15485.7588\n",
      "Epoch 43/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.7198 - val_loss: 15485.7123\n",
      "Epoch 44/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.5846 - val_loss: 15485.8921\n",
      "Epoch 45/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.6091 - val_loss: 15485.8622\n",
      "Epoch 46/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15365.5466 - val_loss: 15485.8209\n",
      "Epoch 47/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.5100 - val_loss: 15486.5755\n",
      "Epoch 48/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.4012 - val_loss: 15486.3164\n",
      "Epoch 49/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.2905 - val_loss: 15486.0742\n",
      "Epoch 50/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.3412 - val_loss: 15486.5615\n",
      "Epoch 51/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.2883 - val_loss: 15486.1326\n",
      "Epoch 52/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.2048 - val_loss: 15486.1915\n",
      "Epoch 53/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.2716 - val_loss: 15486.2800\n",
      "Epoch 54/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15365.0775 - val_loss: 15487.2062\n",
      "Epoch 55/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.0816 - val_loss: 15486.6459\n",
      "Epoch 56/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15365.0033 - val_loss: 15487.4182\n",
      "Epoch 57/200\n",
      "12000/12000 [==============================] - 18s 1ms/sample - loss: 15364.9730 - val_loss: 15486.9547\n",
      "Epoch 58/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15364.8830 - val_loss: 15486.9924\n",
      "Epoch 59/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.9302 - val_loss: 15488.0205\n",
      "Epoch 60/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.8860 - val_loss: 15487.4170\n",
      "Epoch 61/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15364.7715 - val_loss: 15487.3907\n",
      "Epoch 62/200\n",
      "12000/12000 [==============================] - 20s 2ms/sample - loss: 15364.8262 - val_loss: 15487.7803\n",
      "Epoch 63/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15364.7199 - val_loss: 15488.1130\n",
      "Epoch 64/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.7073 - val_loss: 15487.8657\n",
      "Epoch 65/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15364.5922 - val_loss: 15487.9613\n",
      "Epoch 66/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15364.6650 - val_loss: 15487.8966\n",
      "Epoch 67/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.6510 - val_loss: 15487.7521\n",
      "Epoch 68/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.6147 - val_loss: 15488.2514\n",
      "Epoch 69/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15364.5341 - val_loss: 15488.6650\n",
      "Epoch 70/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.4567 - val_loss: 15487.8361\n",
      "Epoch 71/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.4859 - val_loss: 15488.8021\n",
      "Epoch 72/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15364.5323 - val_loss: 15488.8044\n",
      "Epoch 73/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15364.4228 - val_loss: 15488.7661\n",
      "Epoch 74/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.4240 - val_loss: 15489.0221\n",
      "Epoch 75/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.3305 - val_loss: 15488.6086\n",
      "Epoch 76/200\n",
      "12000/12000 [==============================] - 18s 2ms/sample - loss: 15364.4042 - val_loss: 15489.1560\n",
      "Epoch 77/200\n",
      "12000/12000 [==============================] - 18s 1ms/sample - loss: 15364.1848 - val_loss: 15489.3888\n",
      "Epoch 78/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15364.3073 - val_loss: 15489.8720\n",
      "Epoch 79/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15364.2523 - val_loss: 15489.4412\n",
      "Epoch 80/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15364.1253 - val_loss: 15489.1646\n",
      "Epoch 81/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.1467 - val_loss: 15489.2597\n",
      "Epoch 82/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.2014 - val_loss: 15489.4058\n",
      "Epoch 83/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.2043 - val_loss: 15489.4420\n",
      "Epoch 84/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.0430 - val_loss: 15490.0845\n",
      "Epoch 85/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15364.0453 - val_loss: 15490.0477\n",
      "Epoch 86/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.0640 - val_loss: 15489.8942\n",
      "Epoch 87/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.0791 - val_loss: 15489.7594\n",
      "Epoch 88/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.0414 - val_loss: 15489.8688\n",
      "Epoch 89/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.9893 - val_loss: 15491.1146\n",
      "Epoch 90/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.0469 - val_loss: 15490.1292\n",
      "Epoch 91/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.9962 - val_loss: 15490.6645\n",
      "Epoch 92/200\n",
      "12000/12000 [==============================] - 19s 2ms/sample - loss: 15363.9750 - val_loss: 15490.2653\n",
      "Epoch 93/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15364.0191 - val_loss: 15490.1542\n",
      "Epoch 94/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15364.0085 - val_loss: 15490.3099\n",
      "Epoch 95/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15364.0008 - val_loss: 15490.1798\n",
      "Epoch 96/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.9550 - val_loss: 15490.5604\n",
      "Epoch 97/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.7946 - val_loss: 15491.2408\n",
      "Epoch 98/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.8231 - val_loss: 15491.2425\n",
      "Epoch 99/200\n",
      "12000/12000 [==============================] - 18s 2ms/sample - loss: 15363.8095 - val_loss: 15491.2521\n",
      "Epoch 100/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.9265 - val_loss: 15491.5680\n",
      "Epoch 101/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.7955 - val_loss: 15491.9384\n",
      "Epoch 102/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.7687 - val_loss: 15491.2110\n",
      "Epoch 103/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.8176 - val_loss: 15492.2268\n",
      "Epoch 104/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.6955 - val_loss: 15491.3702\n",
      "Epoch 105/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.7407 - val_loss: 15491.8358\n",
      "Epoch 106/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.6801 - val_loss: 15492.1043\n",
      "Epoch 107/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.7715 - val_loss: 15491.4440\n",
      "Epoch 108/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.7181 - val_loss: 15491.8456\n",
      "Epoch 109/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.7679 - val_loss: 15492.1118\n",
      "Epoch 110/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.6826 - val_loss: 15492.3659\n",
      "Epoch 111/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.7242 - val_loss: 15492.4152\n",
      "Epoch 112/200\n",
      "12000/12000 [==============================] - 18s 2ms/sample - loss: 15363.6951 - val_loss: 15493.2859\n",
      "Epoch 113/200\n",
      "12000/12000 [==============================] - 20s 2ms/sample - loss: 15363.6332 - val_loss: 15492.0758\n",
      "Epoch 114/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.7628 - val_loss: 15492.5307\n",
      "Epoch 115/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.6426 - val_loss: 15492.5631\n",
      "Epoch 116/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.6874 - val_loss: 15492.9209\n",
      "Epoch 117/200\n",
      "12000/12000 [==============================] - 18s 1ms/sample - loss: 15363.6634 - val_loss: 15492.7098\n",
      "Epoch 118/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.6470 - val_loss: 15492.3780\n",
      "Epoch 119/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.5755 - val_loss: 15493.2647\n",
      "Epoch 120/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.5610 - val_loss: 15492.6952\n",
      "Epoch 121/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.5847 - val_loss: 15493.7637\n",
      "Epoch 122/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.5152 - val_loss: 15493.1302\n",
      "Epoch 123/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.6426 - val_loss: 15493.8497\n",
      "Epoch 124/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.6164 - val_loss: 15493.7640\n",
      "Epoch 125/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.7003 - val_loss: 15492.6092\n",
      "Epoch 126/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.6629 - val_loss: 15493.5451\n",
      "Epoch 127/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.7010 - val_loss: 15493.1428\n",
      "Epoch 128/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.4990 - val_loss: 15493.2272\n",
      "Epoch 129/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.5227 - val_loss: 15493.6791\n",
      "Epoch 130/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.5284 - val_loss: 15493.5030\n",
      "Epoch 131/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.5364 - val_loss: 15493.8812\n",
      "Epoch 132/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.6192 - val_loss: 15493.9941\n",
      "Epoch 133/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.6177 - val_loss: 15493.3013\n",
      "Epoch 134/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.6193 - val_loss: 15493.5246\n",
      "Epoch 135/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.5487 - val_loss: 15494.4170\n",
      "Epoch 136/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.4950 - val_loss: 15494.5055\n",
      "Epoch 137/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3594 - val_loss: 15494.6568\n",
      "Epoch 138/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.5039 - val_loss: 15494.9066\n",
      "Epoch 139/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.5146 - val_loss: 15493.8905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.4934 - val_loss: 15494.7523\n",
      "Epoch 141/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3948 - val_loss: 15494.3557\n",
      "Epoch 142/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.4620 - val_loss: 15495.2337\n",
      "Epoch 143/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.4224 - val_loss: 15494.8069\n",
      "Epoch 144/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.4144 - val_loss: 15494.9970\n",
      "Epoch 145/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.4223 - val_loss: 15495.0199\n",
      "Epoch 146/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.4744 - val_loss: 15495.5698\n",
      "Epoch 147/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3751 - val_loss: 15494.8303\n",
      "Epoch 148/200\n",
      "12000/12000 [==============================] - 19s 2ms/sample - loss: 15363.4290 - val_loss: 15495.0324\n",
      "Epoch 149/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.3788 - val_loss: 15495.3106\n",
      "Epoch 150/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3796 - val_loss: 15495.0147\n",
      "Epoch 151/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3762 - val_loss: 15495.1361\n",
      "Epoch 152/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.4002 - val_loss: 15494.7084\n",
      "Epoch 153/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3733 - val_loss: 15495.3746\n",
      "Epoch 154/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3760 - val_loss: 15495.9733\n",
      "Epoch 155/200\n",
      "12000/12000 [==============================] - 18s 1ms/sample - loss: 15363.3704 - val_loss: 15495.4700\n",
      "Epoch 156/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.4479 - val_loss: 15495.5818\n",
      "Epoch 157/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.4128 - val_loss: 15495.4421\n",
      "Epoch 158/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.4167 - val_loss: 15494.9213\n",
      "Epoch 159/200\n",
      "12000/12000 [==============================] - 17s 1ms/sample - loss: 15363.4127 - val_loss: 15495.7243\n",
      "Epoch 160/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3238 - val_loss: 15495.5377\n",
      "Epoch 161/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3957 - val_loss: 15496.4208\n",
      "Epoch 162/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.4137 - val_loss: 15495.5683\n",
      "Epoch 163/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3438 - val_loss: 15495.7751\n",
      "Epoch 164/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3569 - val_loss: 15495.5899\n",
      "Epoch 165/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2598 - val_loss: 15495.6927\n",
      "Epoch 166/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.5380 - val_loss: 15495.9599\n",
      "Epoch 167/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3724 - val_loss: 15495.6699\n",
      "Epoch 168/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3303 - val_loss: 15496.2546\n",
      "Epoch 169/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.4383 - val_loss: 15495.8824\n",
      "Epoch 170/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.4371 - val_loss: 15496.4429\n",
      "Epoch 171/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3343 - val_loss: 15496.1940\n",
      "Epoch 172/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3407 - val_loss: 15496.3231\n",
      "Epoch 173/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.4285 - val_loss: 15496.3053\n",
      "Epoch 174/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2681 - val_loss: 15496.4063\n",
      "Epoch 175/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3369 - val_loss: 15496.2381\n",
      "Epoch 176/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3454 - val_loss: 15496.4258\n",
      "Epoch 177/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3479 - val_loss: 15497.2161\n",
      "Epoch 178/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2949 - val_loss: 15496.4778\n",
      "Epoch 179/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2682 - val_loss: 15497.1458\n",
      "Epoch 180/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3693 - val_loss: 15496.5148\n",
      "Epoch 181/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3856 - val_loss: 15496.7098\n",
      "Epoch 182/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2492 - val_loss: 15496.5529\n",
      "Epoch 183/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3478 - val_loss: 15497.1580\n",
      "Epoch 184/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2718 - val_loss: 15496.9531\n",
      "Epoch 185/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3173 - val_loss: 15497.1014\n",
      "Epoch 186/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2959 - val_loss: 15497.0138\n",
      "Epoch 187/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3931 - val_loss: 15497.3296\n",
      "Epoch 188/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3893 - val_loss: 15497.1907\n",
      "Epoch 189/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2284 - val_loss: 15497.0637\n",
      "Epoch 190/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2770 - val_loss: 15496.7870\n",
      "Epoch 191/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3897 - val_loss: 15497.0820\n",
      "Epoch 192/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.4221 - val_loss: 15496.4670\n",
      "Epoch 193/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.1928 - val_loss: 15497.0653\n",
      "Epoch 194/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3465 - val_loss: 15496.9933\n",
      "Epoch 195/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2698 - val_loss: 15497.0039\n",
      "Epoch 196/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.3350 - val_loss: 15498.0570\n",
      "Epoch 197/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.3492 - val_loss: 15496.9771\n",
      "Epoch 198/200\n",
      "12000/12000 [==============================] - 16s 1ms/sample - loss: 15363.1619 - val_loss: 15497.2436\n",
      "Epoch 199/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2072 - val_loss: 15497.1660\n",
      "Epoch 200/200\n",
      "12000/12000 [==============================] - 15s 1ms/sample - loss: 15363.2826 - val_loss: 15497.1246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x128965790>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, \n",
    "          validation_data=(val_x, val_y),\n",
    "          batch_size=40,\n",
    "          epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12392.3727\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 14s 1ms/sample - loss: 12332.7983\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 16s 2ms/sample - loss: 12362.4786\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12381.8192\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12341.3580\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12337.6320\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12358.0993\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12322.7205\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12390.4263\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12381.1204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x126945dd0>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, \n",
    "          batch_size=10,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 16s 2ms/sample - loss: 12356.6821\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12356.3212\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12393.1001\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12219.4047\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12299.5797\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12324.0439\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12323.7565\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12325.0019\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 12394.5230\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12326.8734\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12363.2107\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 17s 2ms/sample - loss: 12362.7202\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12406.3008\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12312.1227\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12358.4351\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12372.3430\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12337.8851\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 16s 2ms/sample - loss: 12331.7085\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 12399.3326\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 16s 2ms/sample - loss: 12380.6395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x126c5fd90>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, \n",
    "          batch_size=10,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.46147427, 0.4936299 , 0.7725021 , 0.18668415, 0.19160269,\n",
       "        0.5329875 , 0.89422435, 0.8431803 , 0.45767853, 0.9006393 ,\n",
       "        0.30371124, 0.8654656 , 0.64627594, 0.2774724 , 0.34715426,\n",
       "        0.7767715 , 0.08706174, 0.9893154 , 0.6400852 , 0.9627552 ,\n",
       "        0.50067353, 0.56687176, 0.48472205, 0.6378169 , 0.6819773 ,\n",
       "        0.6446982 , 0.13012254, 0.27104077, 0.50481087, 0.25702876,\n",
       "        0.59998226, 0.45324805, 0.50154966, 0.43757737, 0.66555214,\n",
       "        0.9135334 , 0.7003318 , 0.23003371, 0.05756523, 0.49323606,\n",
       "        0.75259066, 0.6157169 , 0.6374104 , 0.5707051 , 0.6783405 ,\n",
       "        0.89434326, 0.8651092 , 0.9301288 , 0.586712  , 0.7044457 ,\n",
       "        0.7020338 , 0.09967529, 0.7703017 , 0.85118467, 0.14892976,\n",
       "        0.24892834, 0.2034809 , 0.26588657, 0.05641429, 0.03270473,\n",
       "        0.73204887, 0.9724218 , 0.31882647, 0.17593206, 0.7806721 ,\n",
       "        0.96902066, 0.84500116, 0.7622705 , 0.00976924, 0.772007  ,\n",
       "        0.31686476, 0.95740134, 0.16487914, 0.99371856, 0.77002376,\n",
       "        0.0585487 , 0.30136323, 0.05418719, 0.02097294, 0.8098558 ,\n",
       "        0.9993328 , 0.9676906 , 0.8079357 , 0.07865059, 0.7572921 ,\n",
       "        0.00712246, 0.6570062 , 0.316152  , 0.00867406, 0.6616431 ,\n",
       "        0.25412577, 0.3306162 , 0.14759275, 0.13746355, 0.02187528,\n",
       "        0.1780793 , 0.6548838 , 0.15741996, 0.94479674, 0.16080537],\n",
       "       dtype=float32),\n",
       " array([0.7818266 , 0.44980854, 0.65075845, 0.17491417, 0.5047283 ,\n",
       "        0.16106072, 0.5499607 , 0.8744731 , 0.6006628 , 0.8955531 ,\n",
       "        0.12414642, 0.68526095, 0.6667509 , 0.11806473, 0.359241  ,\n",
       "        0.6119286 , 0.8484664 , 0.68293065, 0.9550282 , 0.9045459 ,\n",
       "        0.88269144, 0.27150008, 0.4650287 , 0.8676415 , 0.5026252 ,\n",
       "        0.42452398, 0.8481062 , 0.15626116, 0.36071396, 0.42584082,\n",
       "        0.12930751, 0.26520145, 0.6903245 , 0.84599334, 0.13224092,\n",
       "        0.37767032, 0.97641206, 0.96301776, 0.21939163, 0.05385643,\n",
       "        0.4527225 , 0.9724792 , 0.3342038 , 0.6168115 , 0.3395587 ,\n",
       "        0.43398395, 0.9803608 , 0.7955412 , 0.23625055, 0.23964162,\n",
       "        0.02104023, 0.40777066, 0.94194674, 0.9913477 , 0.04047493,\n",
       "        0.5572203 , 0.06472664, 0.64436775, 0.24161713, 0.7522351 ,\n",
       "        0.892538  , 0.08331183, 0.26689017, 0.7610726 , 0.8750384 ,\n",
       "        0.99299073, 0.91673225, 0.7365139 , 0.9257179 , 0.5206772 ,\n",
       "        0.5923702 , 0.5963442 , 0.39472255, 0.25320303, 0.9780684 ,\n",
       "        0.2298456 , 0.43313423, 0.00417769, 0.3118336 , 0.7907522 ,\n",
       "        0.09478721, 0.30305177, 0.40730244, 0.8591287 , 0.7661657 ,\n",
       "        0.5432202 , 0.48406875, 0.77418864, 0.1522045 , 0.29970375,\n",
       "        0.35280573, 0.20427185, 0.8599315 , 0.6667513 , 0.81909835,\n",
       "        0.48030037, 0.43726304, 0.92959535, 0.6319735 , 0.87687695],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = random((100,)).astype(np.float32)\n",
    "train_y = random((100,)).astype(np.float32)\n",
    "train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    SimpleRNN(10, input_shape=(10, 1)),\n",
    "    Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_4 (SimpleRNN)     (None, 10)                120       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.46147427],\n",
       "        [0.4936299 ],\n",
       "        [0.7725021 ],\n",
       "        [0.18668415],\n",
       "        [0.19160269],\n",
       "        [0.5329875 ],\n",
       "        [0.89422435],\n",
       "        [0.8431803 ],\n",
       "        [0.45767853],\n",
       "        [0.9006393 ]],\n",
       "\n",
       "       [[0.30371124],\n",
       "        [0.8654656 ],\n",
       "        [0.64627594],\n",
       "        [0.2774724 ],\n",
       "        [0.34715426],\n",
       "        [0.7767715 ],\n",
       "        [0.08706174],\n",
       "        [0.9893154 ],\n",
       "        [0.6400852 ],\n",
       "        [0.9627552 ]],\n",
       "\n",
       "       [[0.50067353],\n",
       "        [0.56687176],\n",
       "        [0.48472205],\n",
       "        [0.6378169 ],\n",
       "        [0.6819773 ],\n",
       "        [0.6446982 ],\n",
       "        [0.13012254],\n",
       "        [0.27104077],\n",
       "        [0.50481087],\n",
       "        [0.25702876]],\n",
       "\n",
       "       [[0.59998226],\n",
       "        [0.45324805],\n",
       "        [0.50154966],\n",
       "        [0.43757737],\n",
       "        [0.66555214],\n",
       "        [0.9135334 ],\n",
       "        [0.7003318 ],\n",
       "        [0.23003371],\n",
       "        [0.05756523],\n",
       "        [0.49323606]],\n",
       "\n",
       "       [[0.75259066],\n",
       "        [0.6157169 ],\n",
       "        [0.6374104 ],\n",
       "        [0.5707051 ],\n",
       "        [0.6783405 ],\n",
       "        [0.89434326],\n",
       "        [0.8651092 ],\n",
       "        [0.9301288 ],\n",
       "        [0.586712  ],\n",
       "        [0.7044457 ]],\n",
       "\n",
       "       [[0.7020338 ],\n",
       "        [0.09967529],\n",
       "        [0.7703017 ],\n",
       "        [0.85118467],\n",
       "        [0.14892976],\n",
       "        [0.24892834],\n",
       "        [0.2034809 ],\n",
       "        [0.26588657],\n",
       "        [0.05641429],\n",
       "        [0.03270473]],\n",
       "\n",
       "       [[0.73204887],\n",
       "        [0.9724218 ],\n",
       "        [0.31882647],\n",
       "        [0.17593206],\n",
       "        [0.7806721 ],\n",
       "        [0.96902066],\n",
       "        [0.84500116],\n",
       "        [0.7622705 ],\n",
       "        [0.00976924],\n",
       "        [0.772007  ]],\n",
       "\n",
       "       [[0.31686476],\n",
       "        [0.95740134],\n",
       "        [0.16487914],\n",
       "        [0.99371856],\n",
       "        [0.77002376],\n",
       "        [0.0585487 ],\n",
       "        [0.30136323],\n",
       "        [0.05418719],\n",
       "        [0.02097294],\n",
       "        [0.8098558 ]],\n",
       "\n",
       "       [[0.9993328 ],\n",
       "        [0.9676906 ],\n",
       "        [0.8079357 ],\n",
       "        [0.07865059],\n",
       "        [0.7572921 ],\n",
       "        [0.00712246],\n",
       "        [0.6570062 ],\n",
       "        [0.316152  ],\n",
       "        [0.00867406],\n",
       "        [0.6616431 ]],\n",
       "\n",
       "       [[0.25412577],\n",
       "        [0.3306162 ],\n",
       "        [0.14759275],\n",
       "        [0.13746355],\n",
       "        [0.02187528],\n",
       "        [0.1780793 ],\n",
       "        [0.6548838 ],\n",
       "        [0.15741996],\n",
       "        [0.94479674],\n",
       "        [0.16080537]]], dtype=float32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.reshape(10, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10 samples\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 1693.9922\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 593us/sample - loss: 1245.9900\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 475us/sample - loss: 963.2513\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 502us/sample - loss: 778.3412\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 483us/sample - loss: 666.6307\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 707us/sample - loss: 877.8005\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 611us/sample - loss: 580.0933\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 693us/sample - loss: 1129.6672\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 753us/sample - loss: 948.7717\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 786us/sample - loss: 719.8773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1253a7f50>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x.reshape(10, 10, 1) * 100, train_y[:10] * 100, \n",
    "          batch_size=10,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks-3.7.4",
   "language": "python",
   "name": "notebooks-3.7.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
