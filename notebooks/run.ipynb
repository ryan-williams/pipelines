{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run stock-price prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook ([`papermill`](https://papermill.readthedocs.io/en/latest/index.html)) parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "run_time = '2019-08-01T10:00'\n",
    "stop_minutes = 10\n",
    "dir = None\n",
    "earliest_data_cutoff = '2019-04-01'\n",
    "ticker = 'AAPL'\n",
    "batch_size = 100000\n",
    "max_epochs = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date/Time helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running at 2019-08-01 10:00:00 (stopping within 10mins)\n"
     ]
    }
   ],
   "source": [
    "from sys import executable as python\n",
    "from datetime import datetime as dt, date, time, timedelta as Δ\n",
    "from dateutil.parser import parse\n",
    "\n",
    "strptime = dt.strptime\n",
    "now = dt.now()\n",
    "today = now.date()\n",
    "\n",
    "if run_time:\n",
    "    run_time = parse(run_time)\n",
    "else:\n",
    "    run_time = dt.now()\n",
    "\n",
    "run_date = run_time.date()\n",
    "\n",
    "if stop_minutes:\n",
    "    stop_at = run_time + Δ(minutes=stop_minutes)\n",
    "else:\n",
    "    stop_at = None\n",
    "\n",
    "earliest_data_cutoff = parse(earliest_data_cutoff)\n",
    "earliest_data_cutoff_date = earliest_data_cutoff.date()\n",
    "    \n",
    "print('Running at %s (stopping within %dmins)' % (run_time.strftime('%Y-%m-%d %H:%M:%S'), stop_minutes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize `data`, `models` directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "if not dir:\n",
    "    dir = Path.cwd()\n",
    "\n",
    "data_dir = dir / 'data'\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "models_dir = dir / 'models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read IEX API credentials\n",
    "Search for a secret key in:\n",
    "- `$IEX_SECRET_KEY` env var\n",
    "- `iex.secret_key` in a config file located at:\n",
    "  - `$CONFIG_PATH` if set\n",
    "  - `~/.config/iex.ini` otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ as env\n",
    "\n",
    "api = 'https://cloud.iexapis.com'\n",
    "\n",
    "SECRET_KEY_VAR = 'IEX_SECRET_KEY'\n",
    "CONFIG_PATH_VAR = 'CONFIG_PATH'\n",
    "\n",
    "if SECRET_KEY_VAR in env:\n",
    "    secret_key = env[SECRET_KEY_VAR]\n",
    "else:\n",
    "    if CONFIG_PATH_VAR in env:\n",
    "        config_path = Path(env[CONFIG_PATH_VAR])\n",
    "    else:\n",
    "        config_path = Path.home() / '.config' / 'iex.ini'\n",
    "\n",
    "    if not config_path.exists():\n",
    "        raise Exception(\"No %s env var, and config path %s doesn't exist\" % (SECRET_KEY_VAR, config_path))\n",
    "\n",
    "    from configparser import ConfigParser\n",
    "    config = ConfigParser()\n",
    "    config.read(str(config_path))\n",
    "    iex_config = config['iex']\n",
    "    secret_key = iex_config['secret_key']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize `dates` and `minutes` that trading occurs during"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching/Processing data from 89 days ([2019-04-01,2019-08-02)), 390 minutes per day\n"
     ]
    }
   ],
   "source": [
    "start_minute = time(9, 30)\n",
    "end_minute = time(16, 0)\n",
    "def get_minutes():\n",
    "    minute = start_minute\n",
    "    while minute < end_minute:\n",
    "        yield minute\n",
    "        hr = minute.hour\n",
    "        min = minute.minute\n",
    "        min += 1\n",
    "        if min == 60:\n",
    "            min = 0\n",
    "            hr += 1\n",
    "        minute = time(hr, min)\n",
    "\n",
    "minutes = list(get_minutes())\n",
    "num_minutes = len(minutes); num_minutes\n",
    "\n",
    "def get_dates(start_date, end_date, step=1):\n",
    "    date = start_date\n",
    "    while date != end_date:\n",
    "        # only emit weekdays\n",
    "        if date.weekday() <= 4:\n",
    "            yield date\n",
    "        date += Δ(days=step)\n",
    "\n",
    "start_date = earliest_data_cutoff_date\n",
    "end_date = run_date + Δ(days=1)\n",
    "dates = list(get_dates(start_date, end_date))\n",
    "num_dates = len(dates)\n",
    "\n",
    "print(\n",
    "    'Fetching/Processing data from %d days ([%s,%s)), %d minutes per day' % (\n",
    "        num_dates, \n",
    "        start_date.strftime('%Y-%m-%d'),\n",
    "        end_date.strftime('%Y-%m-%d'),\n",
    "        num_minutes,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_dir(ticker):\n",
    "    return data_dir / ticker\n",
    "\n",
    "def get_ticker_date_path(ticker, date):\n",
    "    return get_ticker_dir(ticker) / date.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{python} -m pip install -Uq requests\n",
    "from requests import get as GET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def fetch(date, ticker, refetch_partial=False):\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "    out_path = get_ticker_date_path(ticker, date)\n",
    "    refetch = False\n",
    "    prev_data = None\n",
    "    if out_path.exists():\n",
    "        if refetch_partial:\n",
    "            with out_path.open('r') as f:\n",
    "                prev_data = json.load(f)\n",
    "                if len(prev_data) < num_minutes:\n",
    "                    refetch = True\n",
    "                    print(\n",
    "                        'Re-fetching data for %s from %s (found %d per-minute quotes instead of %d)' % (\n",
    "                            ticker, \n",
    "                            date_str, \n",
    "                            len(prev_data), \n",
    "                            num_minutes\n",
    "                        )\n",
    "                    )\n",
    "                else:\n",
    "                    return True\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        print('Fetching data for %s from %s' % (ticker, date_str))\n",
    "\n",
    "    url = f'https://cloud.iexapis.com/stable/stock/{ticker}/chart/date/{date_str}?token={secret_key}'\n",
    "    resp = GET(url)\n",
    "    resp.raise_for_status()\n",
    "    data = json.loads(resp.content)\n",
    "    if prev_data is None or len(data) > len(prev_data):\n",
    "        with out_path.open('wb') as f:\n",
    "            f.write(resp.content)\n",
    "\n",
    "        if refetch:\n",
    "            print('Re-fetch found data for %s %s' % (date_str, ticker))\n",
    "        return True\n",
    "    elif len(data) < len(prev_data):\n",
    "        raise Exception('Found %d data, less than previous amount %d' % (len(data), len(prev_data)))\n",
    "    else:\n",
    "        print('Re-fetched %s, found same %d data' % (out_path, len(data)))\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{python} -m pip install -Uq joblib\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch quotes between a start point in the past (IEX seems to serve 6-7mos of historic data) and today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 453 ms, sys: 197 ms, total: 650 ms\n",
      "Wall time: 8.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "N = 32  # fetch parallelism\n",
    "refetch_empty = False\n",
    "\n",
    "Parallel(n_jobs=N)(\n",
    "    delayed(fetch)(date, ticker, refetch_partial=refetch_empty or date == today)\n",
    "    for date in dates \n",
    "); None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{python} -m pip install -Uq pandas matplotlib numpy scipy\n",
    "import numpy as np\n",
    "from numpy import \\\n",
    "    array, \\\n",
    "    nan, isnan as na, \\\n",
    "    zeros, \\\n",
    "    count_nonzero as cnz, \\\n",
    "    mean, std, \\\n",
    "    unique, \\\n",
    "    logical_and as l_and, \\\n",
    "    logical_or as l_or, \\\n",
    "    exp, log, sqrt\n",
    "from numpy.random import shuffle, permutation\n",
    "from pandas import concat, DataFrame as DF, read_csv, read_json\n",
    "import pandas as pd\n",
    "from scipy.stats import describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the columns that we receive from IEX, describing trades that took place there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [ 'open', 'close', 'high', 'low', 'average', 'volume', 'notional', 'numberOfTrades' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ticker_date_df(date, ticker, latest_data_datetime=None):\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "    out_path = get_ticker_date_path(ticker, date)\n",
    "    if not out_path.exists():\n",
    "        return None\n",
    "    df = read_json(out_path)\n",
    "    if df.empty:\n",
    "        return None\n",
    "    # Convert \"date\", \"minute\" columns into a single \"datetime\" column\n",
    "    df['datetime'] = df['date'].apply(lambda d: d.strftime('%Y-%m-%d')) + ' ' + df['minute']\n",
    "    df['datetime'] = df['datetime'].apply(lambda s: strptime(s, '%Y-%m-%d %H:%M'))\n",
    "    df.drop(columns=['date', 'minute'])\n",
    "    if latest_data_datetime:\n",
    "        df = df.loc[df.datetime <= latest_data_datetime]\n",
    "    \n",
    "    # Drop other columns (\"market\"-data columns, which are updated on a 15-min delay)\n",
    "    df = df[['datetime'] + features]\n",
    "\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ticker_df(ticker, N=None, limit=None):\n",
    "    if limit is None:\n",
    "        ds = dates\n",
    "    elif type(limit) == int:\n",
    "        ds = dates[:limit]\n",
    "    elif type(limit) == date:\n",
    "        ds = [ date for date in dates if date < limit ]        \n",
    "    elif type(limit) == dt:\n",
    "        ds = [ date for date in dates if date < limit.date() ]\n",
    "    else:\n",
    "        raise Exception('Unrecognized limit: %s' % limit)\n",
    "\n",
    "    if N is None:\n",
    "        df = concat([ load_ticker_date_df(date, ticker, latest_data_datetime=run_time) for date in ds ])\n",
    "    else:\n",
    "        df = concat(Parallel(n_jobs=N)( delayed(load_ticker_date_df)(date, ticker) for date in ds ))\n",
    "    \n",
    "    for col in features:\n",
    "        # \"quantity\" features (volume, numberOfTrades, notional) are sometimes -1 instead of NaN\n",
    "        df[col] = df[col].apply(lambda n: nan if n < 0 else n)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.6 s, sys: 47.7 ms, total: 2.65 s\n",
      "Wall time: 2.71 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>average</th>\n",
       "      <th>volume</th>\n",
       "      <th>notional</th>\n",
       "      <th>numberOfTrades</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:30:00</th>\n",
       "      <td>191.645</td>\n",
       "      <td>190.65</td>\n",
       "      <td>191.645</td>\n",
       "      <td>190.600</td>\n",
       "      <td>191.189</td>\n",
       "      <td>4320</td>\n",
       "      <td>825935.940</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:31:00</th>\n",
       "      <td>190.700</td>\n",
       "      <td>190.98</td>\n",
       "      <td>190.980</td>\n",
       "      <td>190.640</td>\n",
       "      <td>190.761</td>\n",
       "      <td>3246</td>\n",
       "      <td>619210.510</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:32:00</th>\n",
       "      <td>191.060</td>\n",
       "      <td>190.93</td>\n",
       "      <td>191.090</td>\n",
       "      <td>190.780</td>\n",
       "      <td>190.951</td>\n",
       "      <td>2253</td>\n",
       "      <td>430211.740</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:33:00</th>\n",
       "      <td>190.980</td>\n",
       "      <td>190.83</td>\n",
       "      <td>191.010</td>\n",
       "      <td>190.760</td>\n",
       "      <td>190.946</td>\n",
       "      <td>2241</td>\n",
       "      <td>427911.290</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:34:00</th>\n",
       "      <td>190.760</td>\n",
       "      <td>190.70</td>\n",
       "      <td>190.760</td>\n",
       "      <td>190.600</td>\n",
       "      <td>190.666</td>\n",
       "      <td>1069</td>\n",
       "      <td>203822.465</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:56:00</th>\n",
       "      <td>214.685</td>\n",
       "      <td>214.79</td>\n",
       "      <td>214.860</td>\n",
       "      <td>214.685</td>\n",
       "      <td>214.751</td>\n",
       "      <td>3966</td>\n",
       "      <td>851703.860</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:57:00</th>\n",
       "      <td>214.800</td>\n",
       "      <td>214.96</td>\n",
       "      <td>214.980</td>\n",
       "      <td>214.770</td>\n",
       "      <td>214.900</td>\n",
       "      <td>3028</td>\n",
       "      <td>650717.425</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:58:00</th>\n",
       "      <td>214.980</td>\n",
       "      <td>214.91</td>\n",
       "      <td>215.040</td>\n",
       "      <td>214.910</td>\n",
       "      <td>215.009</td>\n",
       "      <td>5451</td>\n",
       "      <td>1172014.895</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:59:00</th>\n",
       "      <td>214.945</td>\n",
       "      <td>214.92</td>\n",
       "      <td>214.980</td>\n",
       "      <td>214.840</td>\n",
       "      <td>214.930</td>\n",
       "      <td>3240</td>\n",
       "      <td>696374.085</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 10:00:00</th>\n",
       "      <td>214.850</td>\n",
       "      <td>214.96</td>\n",
       "      <td>215.080</td>\n",
       "      <td>214.770</td>\n",
       "      <td>214.952</td>\n",
       "      <td>4052</td>\n",
       "      <td>870986.410</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30658 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        open   close     high      low  average  volume  \\\n",
       "datetime                                                                  \n",
       "2019-04-01 09:30:00  191.645  190.65  191.645  190.600  191.189    4320   \n",
       "2019-04-01 09:31:00  190.700  190.98  190.980  190.640  190.761    3246   \n",
       "2019-04-01 09:32:00  191.060  190.93  191.090  190.780  190.951    2253   \n",
       "2019-04-01 09:33:00  190.980  190.83  191.010  190.760  190.946    2241   \n",
       "2019-04-01 09:34:00  190.760  190.70  190.760  190.600  190.666    1069   \n",
       "...                      ...     ...      ...      ...      ...     ...   \n",
       "2019-08-01 09:56:00  214.685  214.79  214.860  214.685  214.751    3966   \n",
       "2019-08-01 09:57:00  214.800  214.96  214.980  214.770  214.900    3028   \n",
       "2019-08-01 09:58:00  214.980  214.91  215.040  214.910  215.009    5451   \n",
       "2019-08-01 09:59:00  214.945  214.92  214.980  214.840  214.930    3240   \n",
       "2019-08-01 10:00:00  214.850  214.96  215.080  214.770  214.952    4052   \n",
       "\n",
       "                        notional  numberOfTrades  \n",
       "datetime                                          \n",
       "2019-04-01 09:30:00   825935.940              44  \n",
       "2019-04-01 09:31:00   619210.510              32  \n",
       "2019-04-01 09:32:00   430211.740              30  \n",
       "2019-04-01 09:33:00   427911.290              27  \n",
       "2019-04-01 09:34:00   203822.465              12  \n",
       "...                          ...             ...  \n",
       "2019-08-01 09:56:00   851703.860              41  \n",
       "2019-08-01 09:57:00   650717.425              38  \n",
       "2019-08-01 09:58:00  1172014.895              47  \n",
       "2019-08-01 09:59:00   696374.085              39  \n",
       "2019-08-01 10:00:00   870986.410              49  \n",
       "\n",
       "[30658 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "aapl = load_ticker_df('AAPL'); aapl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill missing data\n",
    "Minutes where no trades were recorded can be assigned prices based on previous minutes' closing prices\n",
    "\n",
    "We don't attempt to cross day boundaries, as the moves overnight are often much larger than minute-to-minute moves during the day, and skew the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a series representing minutes that are the first of their day (i.e. 9:30am)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_datetime = aapl.index.to_series().shift(1)\n",
    "datetime = aapl.index.to_series()\n",
    "\n",
    "def to_date(dt):\n",
    "    return dt.date()\n",
    "\n",
    "day_start = datetime.apply(to_date) != prev_datetime.apply(to_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populate each minute with the previous minute's closing price\n",
    "\n",
    "Assume each day's initial opening is the same as an imagined closing price from a minute prior (when trading wasn't open)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_close = aapl.close.shift(1)\n",
    "prev_close[day_start] = aapl.open\n",
    "aapl['prev_close'] = prev_close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Track minutes where no trades occurred:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>average</th>\n",
       "      <th>volume</th>\n",
       "      <th>notional</th>\n",
       "      <th>numberOfTrades</th>\n",
       "      <th>prev_close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-02 13:29:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>193.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-05 13:36:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>196.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-05 14:29:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>196.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-15 13:33:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>198.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-16 13:39:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>199.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-29 13:11:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>210.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-29 13:43:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>210.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-29 14:15:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>210.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-29 14:19:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>210.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-30 12:18:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>208.240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     open  close  high  low  average  volume  notional  \\\n",
       "datetime                                                                 \n",
       "2019-04-02 13:29:00   NaN    NaN   NaN  NaN      NaN       0       0.0   \n",
       "2019-04-05 13:36:00   NaN    NaN   NaN  NaN      NaN       0       0.0   \n",
       "2019-04-05 14:29:00   NaN    NaN   NaN  NaN      NaN       0       0.0   \n",
       "2019-04-15 13:33:00   NaN    NaN   NaN  NaN      NaN       0       0.0   \n",
       "2019-04-16 13:39:00   NaN    NaN   NaN  NaN      NaN       0       0.0   \n",
       "...                   ...    ...   ...  ...      ...     ...       ...   \n",
       "2019-07-29 13:11:00   NaN    NaN   NaN  NaN      NaN       0       0.0   \n",
       "2019-07-29 13:43:00   NaN    NaN   NaN  NaN      NaN       0       0.0   \n",
       "2019-07-29 14:15:00   NaN    NaN   NaN  NaN      NaN       0       0.0   \n",
       "2019-07-29 14:19:00   NaN    NaN   NaN  NaN      NaN       0       0.0   \n",
       "2019-07-30 12:18:00   NaN    NaN   NaN  NaN      NaN       0       0.0   \n",
       "\n",
       "                     numberOfTrades  prev_close  \n",
       "datetime                                         \n",
       "2019-04-02 13:29:00               0     193.000  \n",
       "2019-04-05 13:36:00               0     196.540  \n",
       "2019-04-05 14:29:00               0     196.795  \n",
       "2019-04-15 13:33:00               0     198.910  \n",
       "2019-04-16 13:39:00               0     199.725  \n",
       "...                             ...         ...  \n",
       "2019-07-29 13:11:00               0     210.070  \n",
       "2019-07-29 13:43:00               0     210.135  \n",
       "2019-07-29 14:15:00               0     210.230  \n",
       "2019-07-29 14:19:00               0     210.090  \n",
       "2019-07-30 12:18:00               0     208.240  \n",
       "\n",
       "[74 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_idxs = aapl[features].isna().any(axis=1); nan_idxs\n",
    "nans = aapl[nan_idxs]\n",
    "nans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spot-check: consecutive pairs of minutes where no trades occurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>average</th>\n",
       "      <th>volume</th>\n",
       "      <th>notional</th>\n",
       "      <th>numberOfTrades</th>\n",
       "      <th>prev_close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-24 13:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>208.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-24 13:01:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-24 13:24:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>207.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-24 13:25:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     open  close  high  low  average  volume  notional  \\\n",
       "datetime                                                                 \n",
       "2019-07-24 13:00:00   NaN    NaN   NaN  NaN      NaN       0       0.0   \n",
       "2019-07-24 13:01:00   NaN    NaN   NaN  NaN      NaN       0       0.0   \n",
       "2019-07-24 13:24:00   NaN    NaN   NaN  NaN      NaN       0       0.0   \n",
       "2019-07-24 13:25:00   NaN    NaN   NaN  NaN      NaN       0       0.0   \n",
       "\n",
       "                     numberOfTrades  prev_close  \n",
       "datetime                                         \n",
       "2019-07-24 13:00:00               0      208.12  \n",
       "2019-07-24 13:01:00               0         NaN  \n",
       "2019-07-24 13:24:00               0      207.90  \n",
       "2019-07-24 13:25:00               0         NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_pairs = l_and(nan_idxs, nan_idxs.shift(1).fillna(False))\n",
    "concat([ aapl[nan_pairs], aapl[nan_pairs.shift(-1).fillna(False)] ]).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by date, and forward-fill \"previous closing\" price.\n",
    "\n",
    "For minutes when no trades occurred, we will treat the last valid closing price as both the opening and closing price. However, we don't persist these across day boundaries (this results in apparent large jumps at opening that skew training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open              30584\n",
       "close             30584\n",
       "high              30584\n",
       "low               30584\n",
       "average           30584\n",
       "volume            30658\n",
       "notional          30658\n",
       "numberOfTrades    30658\n",
       "prev_close        30658\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = aapl.groupby(to_date)\n",
    "aapl.prev_close = grouped.prev_close.apply(lambda s: s.fillna(method='ffill'))\n",
    "aapl.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill `NaN` openings with the previous valid closing price, which is interpreted as the start and end price for a minute where no activity occurred:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open              30658\n",
       "close             30658\n",
       "high              30658\n",
       "low               30658\n",
       "average           30658\n",
       "volume            30658\n",
       "notional          30658\n",
       "numberOfTrades    30658\n",
       "prev_close        30658\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_cols = [ 'open', 'close', 'high', 'low', 'average', ]\n",
    "for col in fill_cols:\n",
    "    aapl[col].fillna(aapl.prev_close, inplace=True)\n",
    "aapl.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect that there are no remaining `NaN`s in the dataset (unless they appear during the first minute of the day; at the time of writing that has not been observed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spot check that `NaN` entries have been filled in based on the previous minute's closing price:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>average</th>\n",
       "      <th>volume</th>\n",
       "      <th>notional</th>\n",
       "      <th>numberOfTrades</th>\n",
       "      <th>prev_close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-02 13:28:00</th>\n",
       "      <td>192.990</td>\n",
       "      <td>193.000</td>\n",
       "      <td>193.05</td>\n",
       "      <td>192.990</td>\n",
       "      <td>193.014</td>\n",
       "      <td>1100</td>\n",
       "      <td>212316.000</td>\n",
       "      <td>11</td>\n",
       "      <td>192.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-02 13:29:00</th>\n",
       "      <td>193.000</td>\n",
       "      <td>193.000</td>\n",
       "      <td>193.00</td>\n",
       "      <td>193.000</td>\n",
       "      <td>193.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>193.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-05 13:35:00</th>\n",
       "      <td>196.535</td>\n",
       "      <td>196.540</td>\n",
       "      <td>196.54</td>\n",
       "      <td>196.535</td>\n",
       "      <td>196.537</td>\n",
       "      <td>205</td>\n",
       "      <td>40290.200</td>\n",
       "      <td>3</td>\n",
       "      <td>196.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-05 13:36:00</th>\n",
       "      <td>196.540</td>\n",
       "      <td>196.540</td>\n",
       "      <td>196.54</td>\n",
       "      <td>196.540</td>\n",
       "      <td>196.540</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>196.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-05 14:28:00</th>\n",
       "      <td>196.820</td>\n",
       "      <td>196.795</td>\n",
       "      <td>196.82</td>\n",
       "      <td>196.795</td>\n",
       "      <td>196.811</td>\n",
       "      <td>731</td>\n",
       "      <td>143868.985</td>\n",
       "      <td>13</td>\n",
       "      <td>196.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-29 14:15:00</th>\n",
       "      <td>210.230</td>\n",
       "      <td>210.230</td>\n",
       "      <td>210.23</td>\n",
       "      <td>210.230</td>\n",
       "      <td>210.230</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>210.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-29 14:18:00</th>\n",
       "      <td>210.110</td>\n",
       "      <td>210.090</td>\n",
       "      <td>210.11</td>\n",
       "      <td>210.090</td>\n",
       "      <td>210.100</td>\n",
       "      <td>400</td>\n",
       "      <td>84040.000</td>\n",
       "      <td>4</td>\n",
       "      <td>210.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-29 14:19:00</th>\n",
       "      <td>210.090</td>\n",
       "      <td>210.090</td>\n",
       "      <td>210.09</td>\n",
       "      <td>210.090</td>\n",
       "      <td>210.090</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>210.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-30 12:17:00</th>\n",
       "      <td>208.200</td>\n",
       "      <td>208.240</td>\n",
       "      <td>208.24</td>\n",
       "      <td>208.200</td>\n",
       "      <td>208.218</td>\n",
       "      <td>400</td>\n",
       "      <td>83287.000</td>\n",
       "      <td>4</td>\n",
       "      <td>208.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-30 12:18:00</th>\n",
       "      <td>208.240</td>\n",
       "      <td>208.240</td>\n",
       "      <td>208.24</td>\n",
       "      <td>208.240</td>\n",
       "      <td>208.240</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>208.240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        open    close    high      low  average  volume  \\\n",
       "datetime                                                                  \n",
       "2019-04-02 13:28:00  192.990  193.000  193.05  192.990  193.014    1100   \n",
       "2019-04-02 13:29:00  193.000  193.000  193.00  193.000  193.000       0   \n",
       "2019-04-05 13:35:00  196.535  196.540  196.54  196.535  196.537     205   \n",
       "2019-04-05 13:36:00  196.540  196.540  196.54  196.540  196.540       0   \n",
       "2019-04-05 14:28:00  196.820  196.795  196.82  196.795  196.811     731   \n",
       "...                      ...      ...     ...      ...      ...     ...   \n",
       "2019-07-29 14:15:00  210.230  210.230  210.23  210.230  210.230       0   \n",
       "2019-07-29 14:18:00  210.110  210.090  210.11  210.090  210.100     400   \n",
       "2019-07-29 14:19:00  210.090  210.090  210.09  210.090  210.090       0   \n",
       "2019-07-30 12:17:00  208.200  208.240  208.24  208.200  208.218     400   \n",
       "2019-07-30 12:18:00  208.240  208.240  208.24  208.240  208.240       0   \n",
       "\n",
       "                       notional  numberOfTrades  prev_close  \n",
       "datetime                                                     \n",
       "2019-04-02 13:28:00  212316.000              11     192.990  \n",
       "2019-04-02 13:29:00       0.000               0     193.000  \n",
       "2019-04-05 13:35:00   40290.200               3     196.495  \n",
       "2019-04-05 13:36:00       0.000               0     196.540  \n",
       "2019-04-05 14:28:00  143868.985              13     196.820  \n",
       "...                         ...             ...         ...  \n",
       "2019-07-29 14:15:00       0.000               0     210.230  \n",
       "2019-07-29 14:18:00   84040.000               4     210.150  \n",
       "2019-07-29 14:19:00       0.000               0     210.090  \n",
       "2019-07-30 12:17:00   83287.000               4     208.180  \n",
       "2019-07-30 12:18:00       0.000               0     208.240  \n",
       "\n",
       "[146 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl[l_or(nan_idxs, nan_idxs.shift(-1).fillna(False))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-fold transforms\n",
    "\n",
    "Market-data time-series are frequently approximated as being log-normally distributed; the fold-change from one interval to the next is considered to be normally distributed.\n",
    "\n",
    "Here we copy the price data above, make `open` a log-fold change over the previous `close`, and express other intra-minute features as a log-fold change over their corresponding `open`ing price:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-02 13:29:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-02 13:30:00</th>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-05 13:36:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-05 13:37:00</th>\n",
       "      <td>-0.000102</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-05 14:29:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-29 14:16:00</th>\n",
       "      <td>-0.000523</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-29 14:19:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-29 14:20:00</th>\n",
       "      <td>0.000167</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>-0.000095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-30 12:18:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-30 12:19:00</th>\n",
       "      <td>-0.000048</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>-0.000024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open     close      high       low   average\n",
       "datetime                                                             \n",
       "2019-04-02 13:29:00  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "2019-04-02 13:30:00  0.000414  0.000000  0.000362 -0.000052  0.000104\n",
       "2019-04-05 13:36:00  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "2019-04-05 13:37:00 -0.000102 -0.000051  0.000000 -0.000051 -0.000010\n",
       "2019-04-05 14:29:00  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "...                       ...       ...       ...       ...       ...\n",
       "2019-07-29 14:16:00 -0.000523  0.000190  0.000190  0.000000  0.000081\n",
       "2019-07-29 14:19:00  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "2019-07-29 14:20:00  0.000167 -0.000071  0.000000 -0.000119 -0.000095\n",
       "2019-07-30 12:18:00  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "2019-07-30 12:19:00 -0.000048 -0.000048  0.000000 -0.000048 -0.000024\n",
       "\n",
       "[146 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = aapl.copy()\n",
    "for col in fill_cols[1:]:\n",
    "    lg[col] = log(lg[col] / lg.open)\n",
    "lg.open = log(lg.open / lg.prev_close)\n",
    "\n",
    "lg.drop(columns='prev_close', inplace=True)\n",
    "lg[fill_cols][l_or(nan_idxs, nan_idxs.shift(1).fillna(False))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open              30658\n",
       "close             30658\n",
       "high              30658\n",
       "low               30658\n",
       "average           30658\n",
       "volume            30658\n",
       "notional          30658\n",
       "numberOfTrades    30658\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize and rename some features:\n",
    "- `trades` ⟶ `sqrt(numberOfTrades)` (variance-stabilizing transform for a Poisson distribution)\n",
    "- `volume` ⟶ `avgVol` (divide out then number of trades, and `log`-transform to attempt to normalize outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>hi</th>\n",
       "      <th>lo</th>\n",
       "      <th>avg</th>\n",
       "      <th>trades</th>\n",
       "      <th>avgVol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:30:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005468</td>\n",
       "      <td>-0.002382</td>\n",
       "      <td>6.633250</td>\n",
       "      <td>4.596955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:31:00</th>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>-0.000315</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>4.629253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:32:00</th>\n",
       "      <td>0.000419</td>\n",
       "      <td>-0.000681</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>-0.001467</td>\n",
       "      <td>-0.000571</td>\n",
       "      <td>5.477226</td>\n",
       "      <td>4.332048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:33:00</th>\n",
       "      <td>0.000262</td>\n",
       "      <td>-0.000786</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>-0.001153</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>5.196152</td>\n",
       "      <td>4.430817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:34:00</th>\n",
       "      <td>-0.000367</td>\n",
       "      <td>-0.000315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000839</td>\n",
       "      <td>-0.000493</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>4.500735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:56:00</th>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>6.403124</td>\n",
       "      <td>4.582226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:57:00</th>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>-0.000140</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>6.164414</td>\n",
       "      <td>4.390543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:58:00</th>\n",
       "      <td>0.000093</td>\n",
       "      <td>-0.000326</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>-0.000326</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>6.855655</td>\n",
       "      <td>4.761992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:59:00</th>\n",
       "      <td>0.000163</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>-0.000489</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>6.244998</td>\n",
       "      <td>4.431732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 10:00:00</th>\n",
       "      <td>-0.000326</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>-0.000372</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.427166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30658 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open     close        hi        lo       avg  \\\n",
       "datetime                                                                \n",
       "2019-04-01 09:30:00  0.000000 -0.005205  0.000000 -0.005468 -0.002382   \n",
       "2019-04-01 09:31:00  0.000262  0.001467  0.001467 -0.000315  0.000320   \n",
       "2019-04-01 09:32:00  0.000419 -0.000681  0.000157 -0.001467 -0.000571   \n",
       "2019-04-01 09:33:00  0.000262 -0.000786  0.000157 -0.001153 -0.000178   \n",
       "2019-04-01 09:34:00 -0.000367 -0.000315  0.000000 -0.000839 -0.000493   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2019-08-01 09:56:00  0.000023  0.000489  0.000815  0.000000  0.000307   \n",
       "2019-08-01 09:57:00  0.000047  0.000745  0.000838 -0.000140  0.000465   \n",
       "2019-08-01 09:58:00  0.000093 -0.000326  0.000279 -0.000326  0.000135   \n",
       "2019-08-01 09:59:00  0.000163 -0.000116  0.000163 -0.000489 -0.000070   \n",
       "2019-08-01 10:00:00 -0.000326  0.000512  0.001070 -0.000372  0.000475   \n",
       "\n",
       "                       trades    avgVol  \n",
       "datetime                                 \n",
       "2019-04-01 09:30:00  6.633250  4.596955  \n",
       "2019-04-01 09:31:00  5.656854  4.629253  \n",
       "2019-04-01 09:32:00  5.477226  4.332048  \n",
       "2019-04-01 09:33:00  5.196152  4.430817  \n",
       "2019-04-01 09:34:00  3.464102  4.500735  \n",
       "...                       ...       ...  \n",
       "2019-08-01 09:56:00  6.403124  4.582226  \n",
       "2019-08-01 09:57:00  6.164414  4.390543  \n",
       "2019-08-01 09:58:00  6.855655  4.761992  \n",
       "2019-08-01 09:59:00  6.244998  4.431732  \n",
       "2019-08-01 10:00:00  7.000000  4.427166  \n",
       "\n",
       "[30658 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.drop(columns=[ 'volume', 'notional', 'numberOfTrades' ], inplace=True)\n",
    "lg['trades'] = sqrt(aapl.numberOfTrades)  # variance-stabilizing transform for a Poisson distribution\n",
    "lg['avgVol'] = log(1 + (aapl.volume / aapl.numberOfTrades).fillna(0))  # volume-per-trade  seems extremely high-tailed, so apply log1p\n",
    "lg.rename(columns={'average': 'avg', 'high': 'hi', 'low': 'lo'}, inplace=True)\n",
    "lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add `next_close` to each minute, which is the log-fold change of the next-minute's closing price over the current minute's.\n",
    "\n",
    "This will be treated as the \"label\" for a training sample anchored at each minute: given the current minute's activity (and that of several minutes prior), can we predict the next minute's closing price?\n",
    "\n",
    "The next minute's opening- and intra-minute features (high, low, average) are not trained on / learned; IEX publishes each minute's data about halfway through to the next minute, so predicting the next minute's closing price is a good goal for the purposes of this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>hi</th>\n",
       "      <th>lo</th>\n",
       "      <th>avg</th>\n",
       "      <th>trades</th>\n",
       "      <th>avgVol</th>\n",
       "      <th>next_close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:30:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005468</td>\n",
       "      <td>-0.002382</td>\n",
       "      <td>6.633250</td>\n",
       "      <td>4.596955</td>\n",
       "      <td>0.001729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:31:00</th>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>-0.000315</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>4.629253</td>\n",
       "      <td>-0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:32:00</th>\n",
       "      <td>0.000419</td>\n",
       "      <td>-0.000681</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>-0.001467</td>\n",
       "      <td>-0.000571</td>\n",
       "      <td>5.477226</td>\n",
       "      <td>4.332048</td>\n",
       "      <td>-0.000524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:33:00</th>\n",
       "      <td>0.000262</td>\n",
       "      <td>-0.000786</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>-0.001153</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>5.196152</td>\n",
       "      <td>4.430817</td>\n",
       "      <td>-0.000681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:34:00</th>\n",
       "      <td>-0.000367</td>\n",
       "      <td>-0.000315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000839</td>\n",
       "      <td>-0.000493</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>4.500735</td>\n",
       "      <td>0.000786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:56:00</th>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>6.403124</td>\n",
       "      <td>4.582226</td>\n",
       "      <td>0.000791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:57:00</th>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>-0.000140</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>6.164414</td>\n",
       "      <td>4.390543</td>\n",
       "      <td>-0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:58:00</th>\n",
       "      <td>0.000093</td>\n",
       "      <td>-0.000326</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>-0.000326</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>6.855655</td>\n",
       "      <td>4.761992</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:59:00</th>\n",
       "      <td>0.000163</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>-0.000489</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>6.244998</td>\n",
       "      <td>4.431732</td>\n",
       "      <td>0.000186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 10:00:00</th>\n",
       "      <td>-0.000326</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>-0.000372</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.427166</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30658 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open     close        hi        lo       avg  \\\n",
       "datetime                                                                \n",
       "2019-04-01 09:30:00  0.000000 -0.005205  0.000000 -0.005468 -0.002382   \n",
       "2019-04-01 09:31:00  0.000262  0.001467  0.001467 -0.000315  0.000320   \n",
       "2019-04-01 09:32:00  0.000419 -0.000681  0.000157 -0.001467 -0.000571   \n",
       "2019-04-01 09:33:00  0.000262 -0.000786  0.000157 -0.001153 -0.000178   \n",
       "2019-04-01 09:34:00 -0.000367 -0.000315  0.000000 -0.000839 -0.000493   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2019-08-01 09:56:00  0.000023  0.000489  0.000815  0.000000  0.000307   \n",
       "2019-08-01 09:57:00  0.000047  0.000745  0.000838 -0.000140  0.000465   \n",
       "2019-08-01 09:58:00  0.000093 -0.000326  0.000279 -0.000326  0.000135   \n",
       "2019-08-01 09:59:00  0.000163 -0.000116  0.000163 -0.000489 -0.000070   \n",
       "2019-08-01 10:00:00 -0.000326  0.000512  0.001070 -0.000372  0.000475   \n",
       "\n",
       "                       trades    avgVol  next_close  \n",
       "datetime                                             \n",
       "2019-04-01 09:30:00  6.633250  4.596955    0.001729  \n",
       "2019-04-01 09:31:00  5.656854  4.629253   -0.000262  \n",
       "2019-04-01 09:32:00  5.477226  4.332048   -0.000524  \n",
       "2019-04-01 09:33:00  5.196152  4.430817   -0.000681  \n",
       "2019-04-01 09:34:00  3.464102  4.500735    0.000786  \n",
       "...                       ...       ...         ...  \n",
       "2019-08-01 09:56:00  6.403124  4.582226    0.000791  \n",
       "2019-08-01 09:57:00  6.164414  4.390543   -0.000233  \n",
       "2019-08-01 09:58:00  6.855655  4.761992    0.000047  \n",
       "2019-08-01 09:59:00  6.244998  4.431732    0.000186  \n",
       "2019-08-01 10:00:00  7.000000  4.427166         NaN  \n",
       "\n",
       "[30658 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = lg.groupby(to_date)\n",
    "\n",
    "def get_next_close(df):\n",
    "    # the next minute's closing price is a combination of:\n",
    "    # - the next minute's \"open\" field (log-fold change over current-minute close)\n",
    "    # - the next minute's \"close\" field (log-fold change over next-minute open)\n",
    "    df['next_close'] = df.open.shift(-1) + df.close.shift(-1)\n",
    "    return df\n",
    "lg = grouped.apply(get_next_close)\n",
    "lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`next_close` was populated within each day above; that means the final minute of each day is missing a label, so we drop them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open          30578\n",
       "close         30578\n",
       "hi            30578\n",
       "lo            30578\n",
       "avg           30578\n",
       "trades        30578\n",
       "avgVol        30578\n",
       "next_close    30578\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.dropna(how='any', inplace=True)\n",
    "lg.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistent assignment of labeled samples to {training, validation} sets\n",
    "Assigning samples to validation vs training should be persistent; we will train iteratively over time on the full history up to that point, and samples marked for validation should always be held out from training.\n",
    "\n",
    "We achieve this by seeding a PRNG for each sample based on that sample's minute ID (`int(strftime('%Y%m%d%H%M'))`), and pulling a single random float. The set of samples whose floats are less than $V$ should represent $100V$% of the data, and can be used collectively as a validation-split representing proportion $V$ of the total set of labeled samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24360 training samples (79.67%), 6218 validation (20.33%)\n"
     ]
    }
   ],
   "source": [
    "from random import random, seed\n",
    "validation_split = 0.2\n",
    "\n",
    "# decide whether a given minute should be treated as a validation (otherwise: training) test case\n",
    "# seed PRNG so that this info is stable over time, and we never train on samples marked for \"validation\"\n",
    "def get_validation_rand(dt):\n",
    "    seed(int(dt.strftime('%Y%m%d%H%M')))\n",
    "    return random()\n",
    "\n",
    "datetime = lg.index.to_series()  # update index since we dropped the last minute of each day\n",
    "vrs = datetime.apply(get_validation_rand).rename('validation_rand')\n",
    "vfs = (vrs < validation_split).rename('validation?')\n",
    "tn, vn = vfs[~vfs].count(), vfs[vfs].count()\n",
    "n = tn + vn\n",
    "tf, vf = tn / n, vn / n\n",
    "print('%d training samples (%.2f%%), %d validation (%.2f%%)' % (tn, 100 * tf, vn, 100 * vf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the log-transformed data into training and validation sets.\n",
    "\n",
    "Also compute {$\\mu$, $\\sigma$} of the training sets, which will be used to standardize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>μ</th>\n",
       "      <th>σ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>open</th>\n",
       "      <td>1.027963e-05</td>\n",
       "      <td>0.000199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>close</th>\n",
       "      <td>-7.768920e-06</td>\n",
       "      <td>0.000583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hi</th>\n",
       "      <td>2.871546e-04</td>\n",
       "      <td>0.000421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lo</th>\n",
       "      <td>-3.035063e-04</td>\n",
       "      <td>0.000463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg</th>\n",
       "      <td>-1.809989e-06</td>\n",
       "      <td>0.000366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trades</th>\n",
       "      <td>4.039914e+00</td>\n",
       "      <td>1.704500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgVol</th>\n",
       "      <td>4.496012e+00</td>\n",
       "      <td>0.404701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>next_close</th>\n",
       "      <td>-8.251628e-07</td>\n",
       "      <td>0.000604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       μ         σ\n",
       "open        1.027963e-05  0.000199\n",
       "close      -7.768920e-06  0.000583\n",
       "hi          2.871546e-04  0.000421\n",
       "lo         -3.035063e-04  0.000463\n",
       "avg        -1.809989e-06  0.000366\n",
       "trades      4.039914e+00  1.704500\n",
       "avgVol      4.496012e+00  0.404701\n",
       "next_close -8.251628e-07  0.000604"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_t = lg[~vfs]\n",
    "means = lg_t.mean(axis=0).rename('μ')\n",
    "stddevs = lg_t.std(axis=0).rename('σ')\n",
    "concat([ means, stddevs ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpers for showing descriptive statistics of each column of a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desc(df):\n",
    "    stats = DF([ describe(df[col]) for col in df.columns ]).set_index(df.columns)\n",
    "    return desc_df(stats)\n",
    "\n",
    "def desc_df(stats):\n",
    "    stats['min'] = stats.minmax.apply(lambda t: t[0])\n",
    "    stats['max'] = stats.minmax.apply(lambda t: t[1])\n",
    "    stats['σ'] = sqrt(stats.variance)\n",
    "    stats.rename(columns={ 'mean': 'μ', 'nobs': 'n' }, inplace=True)\n",
    "    stats.drop(columns=[ 'minmax', 'variance' ], inplace=True)\n",
    "    cs = list(stats.columns)\n",
    "    stats = stats[cs[:2] + [ 'σ' ] + cs[2:-1]]\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>μ</th>\n",
       "      <th>σ</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>open</th>\n",
       "      <td>30578</td>\n",
       "      <td>1.002744e-05</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.019562</td>\n",
       "      <td>5.404455</td>\n",
       "      <td>-0.002417</td>\n",
       "      <td>0.001974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>close</th>\n",
       "      <td>30578</td>\n",
       "      <td>-6.704045e-06</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>-0.920087</td>\n",
       "      <td>54.075943</td>\n",
       "      <td>-0.018992</td>\n",
       "      <td>0.009130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hi</th>\n",
       "      <td>30578</td>\n",
       "      <td>2.869340e-04</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>4.252302</td>\n",
       "      <td>36.806992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lo</th>\n",
       "      <td>30578</td>\n",
       "      <td>-3.017802e-04</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>-8.754134</td>\n",
       "      <td>287.759067</td>\n",
       "      <td>-0.023854</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg</th>\n",
       "      <td>30578</td>\n",
       "      <td>-9.964208e-07</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>-2.223047</td>\n",
       "      <td>118.005609</td>\n",
       "      <td>-0.015078</td>\n",
       "      <td>0.005855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trades</th>\n",
       "      <td>30578</td>\n",
       "      <td>4.037606e+00</td>\n",
       "      <td>1.707964</td>\n",
       "      <td>1.323137</td>\n",
       "      <td>4.148110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.679483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgVol</th>\n",
       "      <td>30578</td>\n",
       "      <td>4.494934e+00</td>\n",
       "      <td>0.407469</td>\n",
       "      <td>-3.796551</td>\n",
       "      <td>45.024909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.509961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>next_close</th>\n",
       "      <td>30578</td>\n",
       "      <td>1.506654e-06</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>-1.142262</td>\n",
       "      <td>44.320374</td>\n",
       "      <td>-0.018822</td>\n",
       "      <td>0.007816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                n             μ         σ  skewness    kurtosis       min  \\\n",
       "open        30578  1.002744e-05  0.000199  0.019562    5.404455 -0.002417   \n",
       "close       30578 -6.704045e-06  0.000575 -0.920087   54.075943 -0.018992   \n",
       "hi          30578  2.869340e-04  0.000420  4.252302   36.806992  0.000000   \n",
       "lo          30578 -3.017802e-04  0.000453 -8.754134  287.759067 -0.023854   \n",
       "avg         30578 -9.964208e-07  0.000360 -2.223047  118.005609 -0.015078   \n",
       "trades      30578  4.037606e+00  1.707964  1.323137    4.148110  0.000000   \n",
       "avgVol      30578  4.494934e+00  0.407469 -3.796551   45.024909  0.000000   \n",
       "next_close  30578  1.506654e-06  0.000600 -1.142262   44.320374 -0.018822   \n",
       "\n",
       "                  max  \n",
       "open         0.001974  \n",
       "close        0.009130  \n",
       "hi           0.009336  \n",
       "lo           0.000000  \n",
       "avg          0.005855  \n",
       "trades      21.679483  \n",
       "avgVol       7.509961  \n",
       "next_close   0.007816  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc(lg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log-transform has captures the idea that, intuitively, a price is as likely to double as half. \n",
    "\n",
    "However, it's worth noting that the high kurtosis values imply that the data is not perfectly *normally distributed* after the log-transform; price movements are empirically \"heavy-tailed\", as we see here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize data\n",
    "Subtract and divide out the mean and stddev of the training features.\n",
    "\n",
    "Note that:\n",
    "- the training {$\\mu$,$\\sigma$} will be used for validation samples as well\n",
    "- we store $-\\mu/\\sigma$ (pre-standardization $0$) in `zeros`, for use padding sliding windows later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>hi</th>\n",
       "      <th>lo</th>\n",
       "      <th>avg</th>\n",
       "      <th>trades</th>\n",
       "      <th>avgVol</th>\n",
       "      <th>next_close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:30:00</th>\n",
       "      <td>-0.051703</td>\n",
       "      <td>-8.913373</td>\n",
       "      <td>-0.682214</td>\n",
       "      <td>-11.149967</td>\n",
       "      <td>-6.500041</td>\n",
       "      <td>1.521464</td>\n",
       "      <td>0.249426</td>\n",
       "      <td>2.865734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:31:00</th>\n",
       "      <td>1.267194</td>\n",
       "      <td>2.529400</td>\n",
       "      <td>2.803515</td>\n",
       "      <td>-0.024125</td>\n",
       "      <td>0.878258</td>\n",
       "      <td>0.948630</td>\n",
       "      <td>0.329233</td>\n",
       "      <td>-0.432310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:32:00</th>\n",
       "      <td>2.054721</td>\n",
       "      <td>-1.153908</td>\n",
       "      <td>-0.309203</td>\n",
       "      <td>-2.511184</td>\n",
       "      <td>-1.553326</td>\n",
       "      <td>0.843245</td>\n",
       "      <td>-0.405147</td>\n",
       "      <td>-0.866328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:33:00</th>\n",
       "      <td>1.265260</td>\n",
       "      <td>-1.334117</td>\n",
       "      <td>-0.309046</td>\n",
       "      <td>-1.833304</td>\n",
       "      <td>-0.481231</td>\n",
       "      <td>0.678344</td>\n",
       "      <td>-0.161094</td>\n",
       "      <td>-1.127316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:34:00</th>\n",
       "      <td>-1.896997</td>\n",
       "      <td>-0.526147</td>\n",
       "      <td>-0.682214</td>\n",
       "      <td>-1.156398</td>\n",
       "      <td>-1.340947</td>\n",
       "      <td>-0.337819</td>\n",
       "      <td>0.011672</td>\n",
       "      <td>1.303625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:55:00</th>\n",
       "      <td>0.417303</td>\n",
       "      <td>1.531735</td>\n",
       "      <td>2.195901</td>\n",
       "      <td>0.655297</td>\n",
       "      <td>2.231919</td>\n",
       "      <td>1.565438</td>\n",
       "      <td>0.934855</td>\n",
       "      <td>0.849799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:56:00</th>\n",
       "      <td>0.065438</td>\n",
       "      <td>0.851849</td>\n",
       "      <td>1.253603</td>\n",
       "      <td>0.655297</td>\n",
       "      <td>0.844281</td>\n",
       "      <td>1.386454</td>\n",
       "      <td>0.213032</td>\n",
       "      <td>1.311725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:57:00</th>\n",
       "      <td>0.182456</td>\n",
       "      <td>1.290230</td>\n",
       "      <td>1.307823</td>\n",
       "      <td>0.353727</td>\n",
       "      <td>1.275886</td>\n",
       "      <td>1.246406</td>\n",
       "      <td>-0.260609</td>\n",
       "      <td>-0.383925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:58:00</th>\n",
       "      <td>0.416234</td>\n",
       "      <td>-0.545155</td>\n",
       "      <td>-0.019239</td>\n",
       "      <td>-0.047842</td>\n",
       "      <td>0.373268</td>\n",
       "      <td>1.651945</td>\n",
       "      <td>0.657226</td>\n",
       "      <td>0.078432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:59:00</th>\n",
       "      <td>0.767348</td>\n",
       "      <td>-0.186145</td>\n",
       "      <td>-0.295393</td>\n",
       "      <td>-0.399669</td>\n",
       "      <td>-0.185622</td>\n",
       "      <td>1.293684</td>\n",
       "      <td>-0.158832</td>\n",
       "      <td>0.309593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30578 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open     close        hi         lo       avg  \\\n",
       "datetime                                                                 \n",
       "2019-04-01 09:30:00 -0.051703 -8.913373 -0.682214 -11.149967 -6.500041   \n",
       "2019-04-01 09:31:00  1.267194  2.529400  2.803515  -0.024125  0.878258   \n",
       "2019-04-01 09:32:00  2.054721 -1.153908 -0.309203  -2.511184 -1.553326   \n",
       "2019-04-01 09:33:00  1.265260 -1.334117 -0.309046  -1.833304 -0.481231   \n",
       "2019-04-01 09:34:00 -1.896997 -0.526147 -0.682214  -1.156398 -1.340947   \n",
       "...                       ...       ...       ...        ...       ...   \n",
       "2019-08-01 09:55:00  0.417303  1.531735  2.195901   0.655297  2.231919   \n",
       "2019-08-01 09:56:00  0.065438  0.851849  1.253603   0.655297  0.844281   \n",
       "2019-08-01 09:57:00  0.182456  1.290230  1.307823   0.353727  1.275886   \n",
       "2019-08-01 09:58:00  0.416234 -0.545155 -0.019239  -0.047842  0.373268   \n",
       "2019-08-01 09:59:00  0.767348 -0.186145 -0.295393  -0.399669 -0.185622   \n",
       "\n",
       "                       trades    avgVol  next_close  \n",
       "datetime                                             \n",
       "2019-04-01 09:30:00  1.521464  0.249426    2.865734  \n",
       "2019-04-01 09:31:00  0.948630  0.329233   -0.432310  \n",
       "2019-04-01 09:32:00  0.843245 -0.405147   -0.866328  \n",
       "2019-04-01 09:33:00  0.678344 -0.161094   -1.127316  \n",
       "2019-04-01 09:34:00 -0.337819  0.011672    1.303625  \n",
       "...                       ...       ...         ...  \n",
       "2019-08-01 09:55:00  1.565438  0.934855    0.849799  \n",
       "2019-08-01 09:56:00  1.386454  0.213032    1.311725  \n",
       "2019-08-01 09:57:00  1.246406 -0.260609   -0.383925  \n",
       "2019-08-01 09:58:00  1.651945  0.657226    0.078432  \n",
       "2019-08-01 09:59:00  1.293684 -0.158832    0.309593  \n",
       "\n",
       "[30578 rows x 8 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed = lg.copy()\n",
    "zeros = -means / stddevs; zeros\n",
    "\n",
    "for col in normed.columns:\n",
    "    normed[col] = (normed[col] - means[col]) / stddevs[col]\n",
    "\n",
    "trn = normed[~vfs]\n",
    "val = normed[ vfs]\n",
    "normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>μ</th>\n",
       "      <th>σ</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>open</th>\n",
       "      <td>30578</td>\n",
       "      <td>-0.001268</td>\n",
       "      <td>0.999390</td>\n",
       "      <td>0.019562</td>\n",
       "      <td>5.404455</td>\n",
       "      <td>-12.207524</td>\n",
       "      <td>9.877919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>close</th>\n",
       "      <td>30578</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>0.986841</td>\n",
       "      <td>-0.920087</td>\n",
       "      <td>54.075943</td>\n",
       "      <td>-32.554993</td>\n",
       "      <td>15.669810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hi</th>\n",
       "      <td>30578</td>\n",
       "      <td>-0.000524</td>\n",
       "      <td>0.996702</td>\n",
       "      <td>4.252302</td>\n",
       "      <td>36.806992</td>\n",
       "      <td>-0.682214</td>\n",
       "      <td>21.497438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lo</th>\n",
       "      <td>30578</td>\n",
       "      <td>0.003727</td>\n",
       "      <td>0.977146</td>\n",
       "      <td>-8.754134</td>\n",
       "      <td>287.759067</td>\n",
       "      <td>-50.848302</td>\n",
       "      <td>0.655297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg</th>\n",
       "      <td>30578</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.981712</td>\n",
       "      <td>-2.223047</td>\n",
       "      <td>118.005609</td>\n",
       "      <td>-41.167308</td>\n",
       "      <td>15.993808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trades</th>\n",
       "      <td>30578</td>\n",
       "      <td>-0.001354</td>\n",
       "      <td>1.002032</td>\n",
       "      <td>1.323137</td>\n",
       "      <td>4.148110</td>\n",
       "      <td>-2.370146</td>\n",
       "      <td>10.348823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgVol</th>\n",
       "      <td>30578</td>\n",
       "      <td>-0.002662</td>\n",
       "      <td>1.006839</td>\n",
       "      <td>-3.796551</td>\n",
       "      <td>45.024909</td>\n",
       "      <td>-11.109455</td>\n",
       "      <td>7.447342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>next_close</th>\n",
       "      <td>30578</td>\n",
       "      <td>0.003862</td>\n",
       "      <td>0.993841</td>\n",
       "      <td>-1.142262</td>\n",
       "      <td>44.320374</td>\n",
       "      <td>-31.171880</td>\n",
       "      <td>12.947016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                n         μ         σ  skewness    kurtosis        min  \\\n",
       "open        30578 -0.001268  0.999390  0.019562    5.404455 -12.207524   \n",
       "close       30578  0.001826  0.986841 -0.920087   54.075943 -32.554993   \n",
       "hi          30578 -0.000524  0.996702  4.252302   36.806992  -0.682214   \n",
       "lo          30578  0.003727  0.977146 -8.754134  287.759067 -50.848302   \n",
       "avg         30578  0.002222  0.981712 -2.223047  118.005609 -41.167308   \n",
       "trades      30578 -0.001354  1.002032  1.323137    4.148110  -2.370146   \n",
       "avgVol      30578 -0.002662  1.006839 -3.796551   45.024909 -11.109455   \n",
       "next_close  30578  0.003862  0.993841 -1.142262   44.320374 -31.171880   \n",
       "\n",
       "                  max  \n",
       "open         9.877919  \n",
       "close       15.669810  \n",
       "hi          21.497438  \n",
       "lo           0.655297  \n",
       "avg         15.993808  \n",
       "trades      10.348823  \n",
       "avgVol       7.447342  \n",
       "next_close  12.947016  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc(normed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue to observe the presence of heavy outliers (≈10s of standard deviations, as evidenced by the `min`/`max` values in many columns). \n",
    "\n",
    "Dropping outliers seems unwise (sudden large price movements are arguably most important to be aware of!), so we'll proceed without further corrections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the `next_close` (\"label\") column, and name it `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>hi</th>\n",
       "      <th>lo</th>\n",
       "      <th>avg</th>\n",
       "      <th>trades</th>\n",
       "      <th>avgVol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:30:00</th>\n",
       "      <td>-0.051703</td>\n",
       "      <td>-8.913373</td>\n",
       "      <td>-0.682214</td>\n",
       "      <td>-11.149967</td>\n",
       "      <td>-6.500041</td>\n",
       "      <td>1.521464</td>\n",
       "      <td>0.249426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:31:00</th>\n",
       "      <td>1.267194</td>\n",
       "      <td>2.529400</td>\n",
       "      <td>2.803515</td>\n",
       "      <td>-0.024125</td>\n",
       "      <td>0.878258</td>\n",
       "      <td>0.948630</td>\n",
       "      <td>0.329233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:32:00</th>\n",
       "      <td>2.054721</td>\n",
       "      <td>-1.153908</td>\n",
       "      <td>-0.309203</td>\n",
       "      <td>-2.511184</td>\n",
       "      <td>-1.553326</td>\n",
       "      <td>0.843245</td>\n",
       "      <td>-0.405147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:33:00</th>\n",
       "      <td>1.265260</td>\n",
       "      <td>-1.334117</td>\n",
       "      <td>-0.309046</td>\n",
       "      <td>-1.833304</td>\n",
       "      <td>-0.481231</td>\n",
       "      <td>0.678344</td>\n",
       "      <td>-0.161094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:34:00</th>\n",
       "      <td>-1.896997</td>\n",
       "      <td>-0.526147</td>\n",
       "      <td>-0.682214</td>\n",
       "      <td>-1.156398</td>\n",
       "      <td>-1.340947</td>\n",
       "      <td>-0.337819</td>\n",
       "      <td>0.011672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:55:00</th>\n",
       "      <td>0.417303</td>\n",
       "      <td>1.531735</td>\n",
       "      <td>2.195901</td>\n",
       "      <td>0.655297</td>\n",
       "      <td>2.231919</td>\n",
       "      <td>1.565438</td>\n",
       "      <td>0.934855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:56:00</th>\n",
       "      <td>0.065438</td>\n",
       "      <td>0.851849</td>\n",
       "      <td>1.253603</td>\n",
       "      <td>0.655297</td>\n",
       "      <td>0.844281</td>\n",
       "      <td>1.386454</td>\n",
       "      <td>0.213032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:57:00</th>\n",
       "      <td>0.182456</td>\n",
       "      <td>1.290230</td>\n",
       "      <td>1.307823</td>\n",
       "      <td>0.353727</td>\n",
       "      <td>1.275886</td>\n",
       "      <td>1.246406</td>\n",
       "      <td>-0.260609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:58:00</th>\n",
       "      <td>0.416234</td>\n",
       "      <td>-0.545155</td>\n",
       "      <td>-0.019239</td>\n",
       "      <td>-0.047842</td>\n",
       "      <td>0.373268</td>\n",
       "      <td>1.651945</td>\n",
       "      <td>0.657226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:59:00</th>\n",
       "      <td>0.767348</td>\n",
       "      <td>-0.186145</td>\n",
       "      <td>-0.295393</td>\n",
       "      <td>-0.399669</td>\n",
       "      <td>-0.185622</td>\n",
       "      <td>1.293684</td>\n",
       "      <td>-0.158832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30578 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open     close        hi         lo       avg  \\\n",
       "datetime                                                                 \n",
       "2019-04-01 09:30:00 -0.051703 -8.913373 -0.682214 -11.149967 -6.500041   \n",
       "2019-04-01 09:31:00  1.267194  2.529400  2.803515  -0.024125  0.878258   \n",
       "2019-04-01 09:32:00  2.054721 -1.153908 -0.309203  -2.511184 -1.553326   \n",
       "2019-04-01 09:33:00  1.265260 -1.334117 -0.309046  -1.833304 -0.481231   \n",
       "2019-04-01 09:34:00 -1.896997 -0.526147 -0.682214  -1.156398 -1.340947   \n",
       "...                       ...       ...       ...        ...       ...   \n",
       "2019-08-01 09:55:00  0.417303  1.531735  2.195901   0.655297  2.231919   \n",
       "2019-08-01 09:56:00  0.065438  0.851849  1.253603   0.655297  0.844281   \n",
       "2019-08-01 09:57:00  0.182456  1.290230  1.307823   0.353727  1.275886   \n",
       "2019-08-01 09:58:00  0.416234 -0.545155 -0.019239  -0.047842  0.373268   \n",
       "2019-08-01 09:59:00  0.767348 -0.186145 -0.295393  -0.399669 -0.185622   \n",
       "\n",
       "                       trades    avgVol  \n",
       "datetime                                 \n",
       "2019-04-01 09:30:00  1.521464  0.249426  \n",
       "2019-04-01 09:31:00  0.948630  0.329233  \n",
       "2019-04-01 09:32:00  0.843245 -0.405147  \n",
       "2019-04-01 09:33:00  0.678344 -0.161094  \n",
       "2019-04-01 09:34:00 -0.337819  0.011672  \n",
       "...                       ...       ...  \n",
       "2019-08-01 09:55:00  1.565438  0.934855  \n",
       "2019-08-01 09:56:00  1.386454  0.213032  \n",
       "2019-08-01 09:57:00  1.246406 -0.260609  \n",
       "2019-08-01 09:58:00  1.651945  0.657226  \n",
       "2019-08-01 09:59:00  1.293684 -0.158832  \n",
       "\n",
       "[30578 rows x 7 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = normed.next_close\n",
    "normed.drop(columns='next_close', inplace=True)\n",
    "normed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling window, numpy `ndarray` conversion\n",
    "Create a numpy array from a rolling 30-minute window of the standardized features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30578, 30, 7)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window = 30\n",
    "\n",
    "cols = normed.columns\n",
    "x = np.moveaxis(\n",
    "    array([ \n",
    "        concat(\n",
    "            [ \n",
    "                normed[col].shift(i)\n",
    "                for i in reversed(range(window)) \n",
    "            ], \n",
    "            axis=1\n",
    "        ) \\\n",
    "        .fillna(zeros[col]) \\\n",
    "        .values\n",
    "        for col in cols\n",
    "    ]),\n",
    "    0, 2\n",
    ")\n",
    "x.shape    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each minute, we have the last 30-minutes of data about the 7 features.\n",
    "\n",
    "Partial windows are padded with \"0\"s (pre-standardization 0; actually $-\\mu/\\sigma$ in post-standardization space, taken from the `zeros` array above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store training/validation data, and assign the full `x` and `y` datasets as a concatenation of training and validation samples, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24360, 30, 7), (24360,), (6218, 30, 7), (6218,), (30578, 30, 7), (30578,)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx = x[~vfs]\n",
    "vx = x[ vfs]\n",
    "ty = y[~vfs].to_numpy()\n",
    "vy = y[ vfs].to_numpy()\n",
    "[ a.shape for a in [ tx,ty, vx,vy, x,y ] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>average</th>\n",
       "      <th>volume</th>\n",
       "      <th>notional</th>\n",
       "      <th>numberOfTrades</th>\n",
       "      <th>prev_close</th>\n",
       "      <th>next_close</th>\n",
       "      <th>factor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:30:00</th>\n",
       "      <td>191.645</td>\n",
       "      <td>190.65</td>\n",
       "      <td>191.645</td>\n",
       "      <td>190.600</td>\n",
       "      <td>191.189</td>\n",
       "      <td>4320</td>\n",
       "      <td>825935.940</td>\n",
       "      <td>44</td>\n",
       "      <td>191.645</td>\n",
       "      <td>190.98</td>\n",
       "      <td>1.001731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:31:00</th>\n",
       "      <td>190.700</td>\n",
       "      <td>190.98</td>\n",
       "      <td>190.980</td>\n",
       "      <td>190.640</td>\n",
       "      <td>190.761</td>\n",
       "      <td>3246</td>\n",
       "      <td>619210.510</td>\n",
       "      <td>32</td>\n",
       "      <td>190.650</td>\n",
       "      <td>190.93</td>\n",
       "      <td>0.999738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:32:00</th>\n",
       "      <td>191.060</td>\n",
       "      <td>190.93</td>\n",
       "      <td>191.090</td>\n",
       "      <td>190.780</td>\n",
       "      <td>190.951</td>\n",
       "      <td>2253</td>\n",
       "      <td>430211.740</td>\n",
       "      <td>30</td>\n",
       "      <td>190.980</td>\n",
       "      <td>190.83</td>\n",
       "      <td>0.999476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:33:00</th>\n",
       "      <td>190.980</td>\n",
       "      <td>190.83</td>\n",
       "      <td>191.010</td>\n",
       "      <td>190.760</td>\n",
       "      <td>190.946</td>\n",
       "      <td>2241</td>\n",
       "      <td>427911.290</td>\n",
       "      <td>27</td>\n",
       "      <td>190.930</td>\n",
       "      <td>190.70</td>\n",
       "      <td>0.999319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 09:34:00</th>\n",
       "      <td>190.760</td>\n",
       "      <td>190.70</td>\n",
       "      <td>190.760</td>\n",
       "      <td>190.600</td>\n",
       "      <td>190.666</td>\n",
       "      <td>1069</td>\n",
       "      <td>203822.465</td>\n",
       "      <td>12</td>\n",
       "      <td>190.830</td>\n",
       "      <td>190.85</td>\n",
       "      <td>1.000787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:56:00</th>\n",
       "      <td>214.685</td>\n",
       "      <td>214.79</td>\n",
       "      <td>214.860</td>\n",
       "      <td>214.685</td>\n",
       "      <td>214.751</td>\n",
       "      <td>3966</td>\n",
       "      <td>851703.860</td>\n",
       "      <td>41</td>\n",
       "      <td>214.680</td>\n",
       "      <td>214.96</td>\n",
       "      <td>1.000791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:57:00</th>\n",
       "      <td>214.800</td>\n",
       "      <td>214.96</td>\n",
       "      <td>214.980</td>\n",
       "      <td>214.770</td>\n",
       "      <td>214.900</td>\n",
       "      <td>3028</td>\n",
       "      <td>650717.425</td>\n",
       "      <td>38</td>\n",
       "      <td>214.790</td>\n",
       "      <td>214.91</td>\n",
       "      <td>0.999767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:58:00</th>\n",
       "      <td>214.980</td>\n",
       "      <td>214.91</td>\n",
       "      <td>215.040</td>\n",
       "      <td>214.910</td>\n",
       "      <td>215.009</td>\n",
       "      <td>5451</td>\n",
       "      <td>1172014.895</td>\n",
       "      <td>47</td>\n",
       "      <td>214.960</td>\n",
       "      <td>214.92</td>\n",
       "      <td>1.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 09:59:00</th>\n",
       "      <td>214.945</td>\n",
       "      <td>214.92</td>\n",
       "      <td>214.980</td>\n",
       "      <td>214.840</td>\n",
       "      <td>214.930</td>\n",
       "      <td>3240</td>\n",
       "      <td>696374.085</td>\n",
       "      <td>39</td>\n",
       "      <td>214.910</td>\n",
       "      <td>214.96</td>\n",
       "      <td>1.000186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01 10:00:00</th>\n",
       "      <td>214.850</td>\n",
       "      <td>214.96</td>\n",
       "      <td>215.080</td>\n",
       "      <td>214.770</td>\n",
       "      <td>214.952</td>\n",
       "      <td>4052</td>\n",
       "      <td>870986.410</td>\n",
       "      <td>49</td>\n",
       "      <td>214.920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30658 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        open   close     high      low  average  volume  \\\n",
       "datetime                                                                  \n",
       "2019-04-01 09:30:00  191.645  190.65  191.645  190.600  191.189    4320   \n",
       "2019-04-01 09:31:00  190.700  190.98  190.980  190.640  190.761    3246   \n",
       "2019-04-01 09:32:00  191.060  190.93  191.090  190.780  190.951    2253   \n",
       "2019-04-01 09:33:00  190.980  190.83  191.010  190.760  190.946    2241   \n",
       "2019-04-01 09:34:00  190.760  190.70  190.760  190.600  190.666    1069   \n",
       "...                      ...     ...      ...      ...      ...     ...   \n",
       "2019-08-01 09:56:00  214.685  214.79  214.860  214.685  214.751    3966   \n",
       "2019-08-01 09:57:00  214.800  214.96  214.980  214.770  214.900    3028   \n",
       "2019-08-01 09:58:00  214.980  214.91  215.040  214.910  215.009    5451   \n",
       "2019-08-01 09:59:00  214.945  214.92  214.980  214.840  214.930    3240   \n",
       "2019-08-01 10:00:00  214.850  214.96  215.080  214.770  214.952    4052   \n",
       "\n",
       "                        notional  numberOfTrades  prev_close  next_close  \\\n",
       "datetime                                                                   \n",
       "2019-04-01 09:30:00   825935.940              44     191.645      190.98   \n",
       "2019-04-01 09:31:00   619210.510              32     190.650      190.93   \n",
       "2019-04-01 09:32:00   430211.740              30     190.980      190.83   \n",
       "2019-04-01 09:33:00   427911.290              27     190.930      190.70   \n",
       "2019-04-01 09:34:00   203822.465              12     190.830      190.85   \n",
       "...                          ...             ...         ...         ...   \n",
       "2019-08-01 09:56:00   851703.860              41     214.680      214.96   \n",
       "2019-08-01 09:57:00   650717.425              38     214.790      214.91   \n",
       "2019-08-01 09:58:00  1172014.895              47     214.960      214.92   \n",
       "2019-08-01 09:59:00   696374.085              39     214.910      214.96   \n",
       "2019-08-01 10:00:00   870986.410              49     214.920         NaN   \n",
       "\n",
       "                       factor  \n",
       "datetime                       \n",
       "2019-04-01 09:30:00  1.001731  \n",
       "2019-04-01 09:31:00  0.999738  \n",
       "2019-04-01 09:32:00  0.999476  \n",
       "2019-04-01 09:33:00  0.999319  \n",
       "2019-04-01 09:34:00  1.000787  \n",
       "...                       ...  \n",
       "2019-08-01 09:56:00  1.000791  \n",
       "2019-08-01 09:57:00  0.999767  \n",
       "2019-08-01 09:58:00  1.000047  \n",
       "2019-08-01 09:59:00  1.000186  \n",
       "2019-08-01 10:00:00       NaN  \n",
       "\n",
       "[30658 rows x 11 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor = exp(y * stddevs.next_close + means.next_close).rename('factor')\n",
    "next_close = (aapl.close * factor).rename('next_close')\n",
    "concat([ aapl, next_close, factor ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, SimpleRNN, Dense\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(4, input_shape=(window, len(cols))))\n",
    "    model.add(Dense(1))\n",
    "    model.build()\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pre-existing models found; using untrained model\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 4)                 48        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 53\n",
      "Trainable params: 53\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "regex = '^\\d{4}-\\d\\d-\\d\\dT\\d\\d:\\d\\d(?:_\\d{4,})?.ckpt$'\n",
    "models = sorted([\n",
    "    dir\n",
    "    for dir in models_dir.iterdir() \n",
    "    if re.match(regex, dir.name)\n",
    "])\n",
    "if models:\n",
    "    ckpt = models[-1]\n",
    "    print('Loading model from %s' % ckpt)\n",
    "    model = load_model(str(ckpt))\n",
    "else:\n",
    "    print('No pre-existing models found; using untrained model')\n",
    "    model = create_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a baseline for evaluating our model's training progress, compute the mean absolute error we'd expect from a network that simply learned to predict the mean of the training labels for every sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6508239909124275, 0.6373937431098421)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(abs(ty - mean(ty))), mean(abs(vy - mean(vy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def diffs_df(model):\n",
    "    def stats(x, y, name=None, predict=True):\n",
    "        suffix = ' (%s)' % name if name else ''\n",
    "        if predict:\n",
    "            predx = model.predict(x)[:, 0]\n",
    "        else:\n",
    "            predx = x\n",
    "\n",
    "        diffs = (y - predx)\n",
    "        mae = abs(diffs)\n",
    "        mse = mae**2\n",
    "\n",
    "        return DF({\n",
    "            ('y^' + suffix): predx,\n",
    "            ('Δ' + suffix): diffs,\n",
    "            ('|Δ|' + suffix): mae,\n",
    "            ('Δ²' + suffix): mse,\n",
    "        })\n",
    "\n",
    "    train = stats(tx, ty, 't')\n",
    "    val = stats(vx, vy, 'v')\n",
    "    predx_t = train['y^ (t)']\n",
    "    predx_v = val['y^ (v)']\n",
    "    predx = concat([ predx_t, predx_v ])\n",
    "    all = stats(predx, np.concatenate([ ty, vy ]), name='*', predict=False)\n",
    "\n",
    "    return concat([\n",
    "        desc(train),\n",
    "        desc(val),\n",
    "        desc(all)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>μ</th>\n",
       "      <th>σ</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y^ (t)</th>\n",
       "      <td>24360</td>\n",
       "      <td>0.081158</td>\n",
       "      <td>0.543712</td>\n",
       "      <td>-0.273228</td>\n",
       "      <td>-1.302285</td>\n",
       "      <td>-1.127019e+00</td>\n",
       "      <td>1.185293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Δ (t)</th>\n",
       "      <td>24360</td>\n",
       "      <td>-0.081158</td>\n",
       "      <td>1.137633</td>\n",
       "      <td>-0.510861</td>\n",
       "      <td>27.956164</td>\n",
       "      <td>-3.053473e+01</td>\n",
       "      <td>12.028514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>|Δ| (t)</th>\n",
       "      <td>24360</td>\n",
       "      <td>0.822517</td>\n",
       "      <td>0.790085</td>\n",
       "      <td>4.989367</td>\n",
       "      <td>102.367542</td>\n",
       "      <td>6.947894e-05</td>\n",
       "      <td>30.534734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Δ² (t)</th>\n",
       "      <td>24360</td>\n",
       "      <td>1.300743</td>\n",
       "      <td>7.102967</td>\n",
       "      <td>96.518940</td>\n",
       "      <td>12231.028383</td>\n",
       "      <td>4.827323e-09</td>\n",
       "      <td>932.369999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y^ (v)</th>\n",
       "      <td>6218</td>\n",
       "      <td>0.079702</td>\n",
       "      <td>0.544012</td>\n",
       "      <td>-0.281580</td>\n",
       "      <td>-1.308155</td>\n",
       "      <td>-1.084793e+00</td>\n",
       "      <td>1.120143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Δ (v)</th>\n",
       "      <td>6218</td>\n",
       "      <td>-0.060710</td>\n",
       "      <td>1.110025</td>\n",
       "      <td>0.239085</td>\n",
       "      <td>8.549961</td>\n",
       "      <td>-1.345827e+01</td>\n",
       "      <td>10.315575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>|Δ| (v)</th>\n",
       "      <td>6218</td>\n",
       "      <td>0.804857</td>\n",
       "      <td>0.766775</td>\n",
       "      <td>3.301423</td>\n",
       "      <td>25.887396</td>\n",
       "      <td>1.130682e-04</td>\n",
       "      <td>13.458269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Δ² (v)</th>\n",
       "      <td>6218</td>\n",
       "      <td>1.235643</td>\n",
       "      <td>3.994149</td>\n",
       "      <td>21.961379</td>\n",
       "      <td>792.259542</td>\n",
       "      <td>1.278441e-08</td>\n",
       "      <td>181.124992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y^ (*)</th>\n",
       "      <td>30578</td>\n",
       "      <td>0.080862</td>\n",
       "      <td>0.543765</td>\n",
       "      <td>-0.274929</td>\n",
       "      <td>-1.303462</td>\n",
       "      <td>-1.127019e+00</td>\n",
       "      <td>1.185293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Δ (*)</th>\n",
       "      <td>30578</td>\n",
       "      <td>-0.077000</td>\n",
       "      <td>1.132086</td>\n",
       "      <td>-0.367589</td>\n",
       "      <td>24.327143</td>\n",
       "      <td>-3.053473e+01</td>\n",
       "      <td>12.028514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>|Δ| (*)</th>\n",
       "      <td>30578</td>\n",
       "      <td>0.818926</td>\n",
       "      <td>0.785421</td>\n",
       "      <td>4.671146</td>\n",
       "      <td>88.315824</td>\n",
       "      <td>6.947894e-05</td>\n",
       "      <td>30.534734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Δ² (*)</th>\n",
       "      <td>30578</td>\n",
       "      <td>1.287505</td>\n",
       "      <td>6.590657</td>\n",
       "      <td>97.249354</td>\n",
       "      <td>13168.005957</td>\n",
       "      <td>4.827323e-09</td>\n",
       "      <td>932.369999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             n         μ         σ   skewness      kurtosis           min  \\\n",
       "y^ (t)   24360  0.081158  0.543712  -0.273228     -1.302285 -1.127019e+00   \n",
       "Δ (t)    24360 -0.081158  1.137633  -0.510861     27.956164 -3.053473e+01   \n",
       "|Δ| (t)  24360  0.822517  0.790085   4.989367    102.367542  6.947894e-05   \n",
       "Δ² (t)   24360  1.300743  7.102967  96.518940  12231.028383  4.827323e-09   \n",
       "y^ (v)    6218  0.079702  0.544012  -0.281580     -1.308155 -1.084793e+00   \n",
       "Δ (v)     6218 -0.060710  1.110025   0.239085      8.549961 -1.345827e+01   \n",
       "|Δ| (v)   6218  0.804857  0.766775   3.301423     25.887396  1.130682e-04   \n",
       "Δ² (v)    6218  1.235643  3.994149  21.961379    792.259542  1.278441e-08   \n",
       "y^ (*)   30578  0.080862  0.543765  -0.274929     -1.303462 -1.127019e+00   \n",
       "Δ (*)    30578 -0.077000  1.132086  -0.367589     24.327143 -3.053473e+01   \n",
       "|Δ| (*)  30578  0.818926  0.785421   4.671146     88.315824  6.947894e-05   \n",
       "Δ² (*)   30578  1.287505  6.590657  97.249354  13168.005957  4.827323e-09   \n",
       "\n",
       "                max  \n",
       "y^ (t)     1.185293  \n",
       "Δ (t)     12.028514  \n",
       "|Δ| (t)   30.534734  \n",
       "Δ² (t)   932.369999  \n",
       "y^ (v)     1.120143  \n",
       "Δ (v)     10.315575  \n",
       "|Δ| (v)   13.458269  \n",
       "Δ² (v)   181.124992  \n",
       "y^ (*)     1.185293  \n",
       "Δ (*)     12.028514  \n",
       "|Δ| (*)   30.534734  \n",
       "Δ² (*)   932.369999  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffs_df(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ryan/c/pipelines/notebooks/models/2019-08-01T10:00_{epoch:04d}.ckpt')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ckpt_path = models_dir / run_time.strftime('%Y-%m-%dT%H:%M_{epoch:04d}.ckpt'); model_ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train on 24360 samples, validate on 6218 samples\n",
      "Epoch 1/10000\n",
      "24360/24360 [==============================] - 1s 52us/sample - loss: 0.8225 - val_loss: 0.8031\n",
      "Epoch 2/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.8206 - val_loss: 0.8013\n",
      "Epoch 3/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.8187 - val_loss: 0.7995\n",
      "Epoch 4/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.8168 - val_loss: 0.7978\n",
      "Epoch 5/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.8150 - val_loss: 0.7960\n",
      "Epoch 6/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.8132 - val_loss: 0.7944\n",
      "Epoch 7/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.8114 - val_loss: 0.7927\n",
      "Epoch 8/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.8096 - val_loss: 0.7911\n",
      "Epoch 9/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.8078 - val_loss: 0.7895\n",
      "Epoch 10/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.8061 - val_loss: 0.7880\n",
      "Epoch 11/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.8044 - val_loss: 0.7864\n",
      "Epoch 12/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.8027 - val_loss: 0.7849\n",
      "Epoch 13/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.8010 - val_loss: 0.7833\n",
      "Epoch 14/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7994 - val_loss: 0.7819\n",
      "Epoch 15/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7977 - val_loss: 0.7804\n",
      "Epoch 16/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7961 - val_loss: 0.7790\n",
      "Epoch 17/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7946 - val_loss: 0.7775\n",
      "Epoch 18/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7930 - val_loss: 0.7761\n",
      "Epoch 19/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7915 - val_loss: 0.7747\n",
      "Epoch 20/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7900 - val_loss: 0.7733\n",
      "Epoch 21/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7885 - val_loss: 0.7720\n",
      "Epoch 22/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7871 - val_loss: 0.7706\n",
      "Epoch 23/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7856 - val_loss: 0.7693\n",
      "Epoch 24/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7842 - val_loss: 0.7680\n",
      "Epoch 25/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7829 - val_loss: 0.7667\n",
      "Epoch 26/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7815 - val_loss: 0.7655\n",
      "Epoch 27/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7802 - val_loss: 0.7643\n",
      "Epoch 28/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7789 - val_loss: 0.7631\n",
      "Epoch 29/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7776 - val_loss: 0.7620\n",
      "Epoch 30/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7763 - val_loss: 0.7609\n",
      "Epoch 31/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7750 - val_loss: 0.7598\n",
      "Epoch 32/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7738 - val_loss: 0.7587\n",
      "Epoch 33/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7726 - val_loss: 0.7577\n",
      "Epoch 34/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7714 - val_loss: 0.7566\n",
      "Epoch 35/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7702 - val_loss: 0.7556\n",
      "Epoch 36/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7691 - val_loss: 0.7546\n",
      "Epoch 37/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7680 - val_loss: 0.7536\n",
      "Epoch 38/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7669 - val_loss: 0.7526\n",
      "Epoch 39/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7658 - val_loss: 0.7516\n",
      "Epoch 40/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7647 - val_loss: 0.7506\n",
      "Epoch 41/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7637 - val_loss: 0.7497\n",
      "Epoch 42/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7626 - val_loss: 0.7487\n",
      "Epoch 43/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7616 - val_loss: 0.7478\n",
      "Epoch 44/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7606 - val_loss: 0.7469\n",
      "Epoch 45/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7596 - val_loss: 0.7460\n",
      "Epoch 46/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7586 - val_loss: 0.7452\n",
      "Epoch 47/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7577 - val_loss: 0.7443\n",
      "Epoch 48/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7567 - val_loss: 0.7434\n",
      "Epoch 49/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7558 - val_loss: 0.7426\n",
      "Epoch 50/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7548 - val_loss: 0.7418\n",
      "Epoch 51/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7539 - val_loss: 0.7409\n",
      "Epoch 52/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7530 - val_loss: 0.7401\n",
      "Epoch 53/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7521 - val_loss: 0.7393\n",
      "Epoch 54/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7512 - val_loss: 0.7385\n",
      "Epoch 55/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7503 - val_loss: 0.7377\n",
      "Epoch 56/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7494 - val_loss: 0.7369\n",
      "Epoch 57/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7486 - val_loss: 0.7361\n",
      "Epoch 58/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7477 - val_loss: 0.7353\n",
      "Epoch 59/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7469 - val_loss: 0.7344\n",
      "Epoch 60/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7460 - val_loss: 0.7336\n",
      "Epoch 61/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7452 - val_loss: 0.7329\n",
      "Epoch 62/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7444 - val_loss: 0.7321\n",
      "Epoch 63/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7435 - val_loss: 0.7313\n",
      "Epoch 64/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7427 - val_loss: 0.7305\n",
      "Epoch 65/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7419 - val_loss: 0.7297\n",
      "Epoch 66/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7411 - val_loss: 0.7289\n",
      "Epoch 67/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7403 - val_loss: 0.7282\n",
      "Epoch 68/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7395 - val_loss: 0.7274\n",
      "Epoch 69/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7387 - val_loss: 0.7266\n",
      "Epoch 70/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7380 - val_loss: 0.7259\n",
      "Epoch 71/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7372 - val_loss: 0.7251\n",
      "Epoch 72/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7364 - val_loss: 0.7244\n",
      "Epoch 73/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7357 - val_loss: 0.7236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7349 - val_loss: 0.7229\n",
      "Epoch 75/10000\n",
      "24360/24360 [==============================] - 0s 5us/sample - loss: 0.7342 - val_loss: 0.7221\n",
      "Epoch 76/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7335 - val_loss: 0.7214\n",
      "Epoch 77/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7327 - val_loss: 0.7207\n",
      "Epoch 78/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7320 - val_loss: 0.7200\n",
      "Epoch 79/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7313 - val_loss: 0.7193\n",
      "Epoch 80/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7306 - val_loss: 0.7186\n",
      "Epoch 81/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7299 - val_loss: 0.7179\n",
      "Epoch 82/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7292 - val_loss: 0.7172\n",
      "Epoch 83/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7285 - val_loss: 0.7165\n",
      "Epoch 84/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7278 - val_loss: 0.7158\n",
      "Epoch 85/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7271 - val_loss: 0.7151\n",
      "Epoch 86/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7264 - val_loss: 0.7144\n",
      "Epoch 87/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7257 - val_loss: 0.7137\n",
      "Epoch 88/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7250 - val_loss: 0.7131\n",
      "Epoch 89/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7244 - val_loss: 0.7124\n",
      "Epoch 90/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7237 - val_loss: 0.7117\n",
      "Epoch 91/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7230 - val_loss: 0.7111\n",
      "Epoch 92/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7224 - val_loss: 0.7104\n",
      "Epoch 93/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7217 - val_loss: 0.7098\n",
      "Epoch 94/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7211 - val_loss: 0.7091\n",
      "Epoch 95/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7204 - val_loss: 0.7085\n",
      "Epoch 96/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7198 - val_loss: 0.7079\n",
      "Epoch 97/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7192 - val_loss: 0.7073\n",
      "Epoch 98/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7185 - val_loss: 0.7067\n",
      "Epoch 99/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7179 - val_loss: 0.7060\n",
      "Epoch 100/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7173 - val_loss: 0.7054\n",
      "Epoch 101/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7167 - val_loss: 0.7048\n",
      "Epoch 102/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7161 - val_loss: 0.7042\n",
      "Epoch 103/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7155 - val_loss: 0.7036\n",
      "Epoch 104/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7149 - val_loss: 0.7031\n",
      "Epoch 105/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7143 - val_loss: 0.7025\n",
      "Epoch 106/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7137 - val_loss: 0.7019\n",
      "Epoch 107/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7131 - val_loss: 0.7013\n",
      "Epoch 108/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7125 - val_loss: 0.7008\n",
      "Epoch 109/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7119 - val_loss: 0.7002\n",
      "Epoch 110/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7114 - val_loss: 0.6997\n",
      "Epoch 111/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7108 - val_loss: 0.6991\n",
      "Epoch 112/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7102 - val_loss: 0.6986\n",
      "Epoch 113/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7097 - val_loss: 0.6980\n",
      "Epoch 114/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7091 - val_loss: 0.6975\n",
      "Epoch 115/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7086 - val_loss: 0.6970\n",
      "Epoch 116/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7080 - val_loss: 0.6964\n",
      "Epoch 117/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7075 - val_loss: 0.6959\n",
      "Epoch 118/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7070 - val_loss: 0.6954\n",
      "Epoch 119/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7065 - val_loss: 0.6948\n",
      "Epoch 120/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7059 - val_loss: 0.6943\n",
      "Epoch 121/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7054 - val_loss: 0.6938\n",
      "Epoch 122/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7049 - val_loss: 0.6933\n",
      "Epoch 123/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7044 - val_loss: 0.6928\n",
      "Epoch 124/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7039 - val_loss: 0.6923\n",
      "Epoch 125/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7034 - val_loss: 0.6918\n",
      "Epoch 126/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7029 - val_loss: 0.6913\n",
      "Epoch 127/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7024 - val_loss: 0.6908\n",
      "Epoch 128/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7019 - val_loss: 0.6903\n",
      "Epoch 129/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7014 - val_loss: 0.6898\n",
      "Epoch 130/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7010 - val_loss: 0.6894\n",
      "Epoch 131/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.7005 - val_loss: 0.6889\n",
      "Epoch 132/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.7000 - val_loss: 0.6884\n",
      "Epoch 133/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6996 - val_loss: 0.6879\n",
      "Epoch 134/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6991 - val_loss: 0.6875\n",
      "Epoch 135/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6986 - val_loss: 0.6870\n",
      "Epoch 136/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6982 - val_loss: 0.6866\n",
      "Epoch 137/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6977 - val_loss: 0.6861\n",
      "Epoch 138/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6973 - val_loss: 0.6857\n",
      "Epoch 139/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6968 - val_loss: 0.6852\n",
      "Epoch 140/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6964 - val_loss: 0.6848\n",
      "Epoch 141/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6960 - val_loss: 0.6843\n",
      "Epoch 142/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6955 - val_loss: 0.6839\n",
      "Epoch 143/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6951 - val_loss: 0.6835\n",
      "Epoch 144/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6947 - val_loss: 0.6831\n",
      "Epoch 145/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6943 - val_loss: 0.6826\n",
      "Epoch 146/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6938 - val_loss: 0.6822\n",
      "Epoch 147/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6934 - val_loss: 0.6818\n",
      "Epoch 148/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6930 - val_loss: 0.6814\n",
      "Epoch 149/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6926 - val_loss: 0.6810\n",
      "Epoch 150/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6922 - val_loss: 0.6806\n",
      "Epoch 151/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6918 - val_loss: 0.6802\n",
      "Epoch 152/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6914 - val_loss: 0.6798\n",
      "Epoch 153/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6910 - val_loss: 0.6794\n",
      "Epoch 154/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6906 - val_loss: 0.6790\n",
      "Epoch 155/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6902 - val_loss: 0.6786\n",
      "Epoch 156/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6898 - val_loss: 0.6782\n",
      "Epoch 157/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6894 - val_loss: 0.6778\n",
      "Epoch 158/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6890 - val_loss: 0.6774\n",
      "Epoch 159/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6887 - val_loss: 0.6770\n",
      "Epoch 160/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6883 - val_loss: 0.6767\n",
      "Epoch 161/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6879 - val_loss: 0.6763\n",
      "Epoch 162/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6875 - val_loss: 0.6759\n",
      "Epoch 163/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6872 - val_loss: 0.6756\n",
      "Epoch 164/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6868 - val_loss: 0.6752\n",
      "Epoch 165/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6864 - val_loss: 0.6749\n",
      "Epoch 166/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6861 - val_loss: 0.6745\n",
      "Epoch 167/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6857 - val_loss: 0.6742\n",
      "Epoch 168/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6854 - val_loss: 0.6738\n",
      "Epoch 169/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6850 - val_loss: 0.6735\n",
      "Epoch 170/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6847 - val_loss: 0.6731\n",
      "Epoch 171/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6844 - val_loss: 0.6728\n",
      "Epoch 172/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6840 - val_loss: 0.6725\n",
      "Epoch 173/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6837 - val_loss: 0.6721\n",
      "Epoch 174/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6834 - val_loss: 0.6718\n",
      "Epoch 175/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6830 - val_loss: 0.6715\n",
      "Epoch 176/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6827 - val_loss: 0.6711\n",
      "Epoch 177/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6824 - val_loss: 0.6708\n",
      "Epoch 178/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6821 - val_loss: 0.6705\n",
      "Epoch 179/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6818 - val_loss: 0.6702\n",
      "Epoch 180/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6815 - val_loss: 0.6698\n",
      "Epoch 181/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6812 - val_loss: 0.6695\n",
      "Epoch 182/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6809 - val_loss: 0.6692\n",
      "Epoch 183/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6806 - val_loss: 0.6689\n",
      "Epoch 184/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6803 - val_loss: 0.6686\n",
      "Epoch 185/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6800 - val_loss: 0.6683\n",
      "Epoch 186/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6797 - val_loss: 0.6680\n",
      "Epoch 187/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6794 - val_loss: 0.6677\n",
      "Epoch 188/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6791 - val_loss: 0.6674\n",
      "Epoch 189/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6788 - val_loss: 0.6671\n",
      "Epoch 190/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6785 - val_loss: 0.6668\n",
      "Epoch 191/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6783 - val_loss: 0.6665\n",
      "Epoch 192/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6780 - val_loss: 0.6662\n",
      "Epoch 193/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6777 - val_loss: 0.6660\n",
      "Epoch 194/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6775 - val_loss: 0.6657\n",
      "Epoch 195/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6772 - val_loss: 0.6654\n",
      "Epoch 196/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6769 - val_loss: 0.6651\n",
      "Epoch 197/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6767 - val_loss: 0.6649\n",
      "Epoch 198/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6764 - val_loss: 0.6646\n",
      "Epoch 199/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6762 - val_loss: 0.6643\n",
      "Epoch 200/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6759 - val_loss: 0.6641\n",
      "Epoch 201/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6757 - val_loss: 0.6638\n",
      "Epoch 202/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6754 - val_loss: 0.6635\n",
      "Epoch 203/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6752 - val_loss: 0.6633\n",
      "Epoch 204/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6749 - val_loss: 0.6630\n",
      "Epoch 205/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6747 - val_loss: 0.6628\n",
      "Epoch 206/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6745 - val_loss: 0.6625\n",
      "Epoch 207/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6742 - val_loss: 0.6623\n",
      "Epoch 208/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6740 - val_loss: 0.6620\n",
      "Epoch 209/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6738 - val_loss: 0.6618\n",
      "Epoch 210/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6735 - val_loss: 0.6615\n",
      "Epoch 211/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6733 - val_loss: 0.6613\n",
      "Epoch 212/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6731 - val_loss: 0.6611\n",
      "Epoch 213/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6729 - val_loss: 0.6608\n",
      "Epoch 214/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6726 - val_loss: 0.6606\n",
      "Epoch 215/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6724 - val_loss: 0.6604\n",
      "Epoch 216/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6722 - val_loss: 0.6601\n",
      "Epoch 217/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6720 - val_loss: 0.6599\n",
      "Epoch 218/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6718 - val_loss: 0.6597\n",
      "Epoch 219/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6716 - val_loss: 0.6595\n",
      "Epoch 220/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6714 - val_loss: 0.6593\n",
      "Epoch 221/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6712 - val_loss: 0.6590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6710 - val_loss: 0.6588\n",
      "Epoch 223/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6708 - val_loss: 0.6586\n",
      "Epoch 224/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6706 - val_loss: 0.6584\n",
      "Epoch 225/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6704 - val_loss: 0.6582\n",
      "Epoch 226/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6702 - val_loss: 0.6580\n",
      "Epoch 227/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6700 - val_loss: 0.6578\n",
      "Epoch 228/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6698 - val_loss: 0.6575\n",
      "Epoch 229/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6696 - val_loss: 0.6573\n",
      "Epoch 230/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6694 - val_loss: 0.6571\n",
      "Epoch 231/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6693 - val_loss: 0.6569\n",
      "Epoch 232/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6691 - val_loss: 0.6567\n",
      "Epoch 233/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6689 - val_loss: 0.6565\n",
      "Epoch 234/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6687 - val_loss: 0.6564\n",
      "Epoch 235/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6685 - val_loss: 0.6562\n",
      "Epoch 236/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6684 - val_loss: 0.6560\n",
      "Epoch 237/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6682 - val_loss: 0.6558\n",
      "Epoch 238/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6680 - val_loss: 0.6556\n",
      "Epoch 239/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6678 - val_loss: 0.6554\n",
      "Epoch 240/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6677 - val_loss: 0.6552\n",
      "Epoch 241/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6675 - val_loss: 0.6551\n",
      "Epoch 242/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6673 - val_loss: 0.6549\n",
      "Epoch 243/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6672 - val_loss: 0.6547\n",
      "Epoch 244/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6670 - val_loss: 0.6545\n",
      "Epoch 245/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6668 - val_loss: 0.6544\n",
      "Epoch 246/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6667 - val_loss: 0.6542\n",
      "Epoch 247/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6665 - val_loss: 0.6540\n",
      "Epoch 248/10000\n",
      "24360/24360 [==============================] - 0s 8us/sample - loss: 0.6664 - val_loss: 0.6539\n",
      "Epoch 249/10000\n",
      "24360/24360 [==============================] - 0s 9us/sample - loss: 0.6662 - val_loss: 0.6537\n",
      "Epoch 250/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6661 - val_loss: 0.6535\n",
      "Epoch 251/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6659 - val_loss: 0.6534\n",
      "Epoch 252/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6658 - val_loss: 0.6532\n",
      "Epoch 253/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6656 - val_loss: 0.6531\n",
      "Epoch 254/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6655 - val_loss: 0.6529\n",
      "Epoch 255/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6653 - val_loss: 0.6527\n",
      "Epoch 256/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6652 - val_loss: 0.6526\n",
      "Epoch 257/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6650 - val_loss: 0.6524\n",
      "Epoch 258/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6649 - val_loss: 0.6523\n",
      "Epoch 259/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6647 - val_loss: 0.6521\n",
      "Epoch 260/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6646 - val_loss: 0.6520\n",
      "Epoch 261/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6645 - val_loss: 0.6518\n",
      "Epoch 262/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6643 - val_loss: 0.6517\n",
      "Epoch 263/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6642 - val_loss: 0.6516\n",
      "Epoch 264/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6641 - val_loss: 0.6514\n",
      "Epoch 265/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6639 - val_loss: 0.6513\n",
      "Epoch 266/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6638 - val_loss: 0.6511\n",
      "Epoch 267/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6637 - val_loss: 0.6510\n",
      "Epoch 268/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6635 - val_loss: 0.6508\n",
      "Epoch 269/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6634 - val_loss: 0.6507\n",
      "Epoch 270/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6633 - val_loss: 0.6506\n",
      "Epoch 271/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6631 - val_loss: 0.6504\n",
      "Epoch 272/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6630 - val_loss: 0.6503\n",
      "Epoch 273/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6629 - val_loss: 0.6502\n",
      "Epoch 274/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6628 - val_loss: 0.6500\n",
      "Epoch 275/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6626 - val_loss: 0.6499\n",
      "Epoch 276/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6625 - val_loss: 0.6498\n",
      "Epoch 277/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6624 - val_loss: 0.6496\n",
      "Epoch 278/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6623 - val_loss: 0.6495\n",
      "Epoch 279/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6622 - val_loss: 0.6494\n",
      "Epoch 280/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6621 - val_loss: 0.6493\n",
      "Epoch 281/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6619 - val_loss: 0.6491\n",
      "Epoch 282/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6618 - val_loss: 0.6490\n",
      "Epoch 283/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6617 - val_loss: 0.6489\n",
      "Epoch 284/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6616 - val_loss: 0.6488\n",
      "Epoch 285/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6615 - val_loss: 0.6487\n",
      "Epoch 286/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6614 - val_loss: 0.6485\n",
      "Epoch 287/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6613 - val_loss: 0.6484\n",
      "Epoch 288/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6612 - val_loss: 0.6483\n",
      "Epoch 289/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6610 - val_loss: 0.6482\n",
      "Epoch 290/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6609 - val_loss: 0.6481\n",
      "Epoch 291/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6608 - val_loss: 0.6480\n",
      "Epoch 292/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6607 - val_loss: 0.6478\n",
      "Epoch 293/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6606 - val_loss: 0.6477\n",
      "Epoch 294/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6605 - val_loss: 0.6476\n",
      "Epoch 295/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6604 - val_loss: 0.6475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6603 - val_loss: 0.6474\n",
      "Epoch 297/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6602 - val_loss: 0.6473\n",
      "Epoch 298/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6601 - val_loss: 0.6472\n",
      "Epoch 299/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6600 - val_loss: 0.6471\n",
      "Epoch 300/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6599 - val_loss: 0.6470\n",
      "Epoch 301/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6598 - val_loss: 0.6469\n",
      "Epoch 302/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6597 - val_loss: 0.6468\n",
      "Epoch 303/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6596 - val_loss: 0.6467\n",
      "Epoch 304/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6595 - val_loss: 0.6466\n",
      "Epoch 305/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6594 - val_loss: 0.6465\n",
      "Epoch 306/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6593 - val_loss: 0.6464\n",
      "Epoch 307/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6592 - val_loss: 0.6463\n",
      "Epoch 308/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6592 - val_loss: 0.6462\n",
      "Epoch 309/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6591 - val_loss: 0.6461\n",
      "Epoch 310/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6590 - val_loss: 0.6460\n",
      "Epoch 311/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6589 - val_loss: 0.6459\n",
      "Epoch 312/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6588 - val_loss: 0.6458\n",
      "Epoch 313/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6587 - val_loss: 0.6457\n",
      "Epoch 314/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6586 - val_loss: 0.6456\n",
      "Epoch 315/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6585 - val_loss: 0.6455\n",
      "Epoch 316/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6585 - val_loss: 0.6454\n",
      "Epoch 317/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6584 - val_loss: 0.6453\n",
      "Epoch 318/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6583 - val_loss: 0.6453\n",
      "Epoch 319/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6582 - val_loss: 0.6452\n",
      "Epoch 320/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6581 - val_loss: 0.6451\n",
      "Epoch 321/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6581 - val_loss: 0.6450\n",
      "Epoch 322/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6580 - val_loss: 0.6449\n",
      "Epoch 323/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6579 - val_loss: 0.6448\n",
      "Epoch 324/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6578 - val_loss: 0.6448\n",
      "Epoch 325/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6578 - val_loss: 0.6447\n",
      "Epoch 326/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6577 - val_loss: 0.6446\n",
      "Epoch 327/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6576 - val_loss: 0.6445\n",
      "Epoch 328/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6575 - val_loss: 0.6444\n",
      "Epoch 329/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6575 - val_loss: 0.6444\n",
      "Epoch 330/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6574 - val_loss: 0.6443\n",
      "Epoch 331/10000\n",
      "24360/24360 [==============================] - 0s 5us/sample - loss: 0.6573 - val_loss: 0.6442\n",
      "Epoch 332/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6573 - val_loss: 0.6441\n",
      "Epoch 333/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6572 - val_loss: 0.6440\n",
      "Epoch 334/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6571 - val_loss: 0.6440\n",
      "Epoch 335/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6571 - val_loss: 0.6439\n",
      "Epoch 336/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6570 - val_loss: 0.6438\n",
      "Epoch 337/10000\n",
      "24360/24360 [==============================] - 0s 5us/sample - loss: 0.6569 - val_loss: 0.6437\n",
      "Epoch 338/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6569 - val_loss: 0.6437\n",
      "Epoch 339/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6568 - val_loss: 0.6436\n",
      "Epoch 340/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6567 - val_loss: 0.6435\n",
      "Epoch 341/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6567 - val_loss: 0.6435\n",
      "Epoch 342/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6566 - val_loss: 0.6434\n",
      "Epoch 343/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6566 - val_loss: 0.6433\n",
      "Epoch 344/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6565 - val_loss: 0.6433\n",
      "Epoch 345/10000\n",
      "24360/24360 [==============================] - 0s 5us/sample - loss: 0.6564 - val_loss: 0.6432\n",
      "Epoch 346/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6564 - val_loss: 0.6431\n",
      "Epoch 347/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6563 - val_loss: 0.6431\n",
      "Epoch 348/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6563 - val_loss: 0.6430\n",
      "Epoch 349/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6562 - val_loss: 0.6429\n",
      "Epoch 350/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6562 - val_loss: 0.6429\n",
      "Epoch 351/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6561 - val_loss: 0.6428\n",
      "Epoch 352/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6560 - val_loss: 0.6427\n",
      "Epoch 353/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6560 - val_loss: 0.6427\n",
      "Epoch 354/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6559 - val_loss: 0.6426\n",
      "Epoch 355/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6559 - val_loss: 0.6426\n",
      "Epoch 356/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6558 - val_loss: 0.6425\n",
      "Epoch 357/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6558 - val_loss: 0.6425\n",
      "Epoch 358/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6557 - val_loss: 0.6424\n",
      "Epoch 359/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6557 - val_loss: 0.6423\n",
      "Epoch 360/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6556 - val_loss: 0.6423\n",
      "Epoch 361/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6556 - val_loss: 0.6422\n",
      "Epoch 362/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6555 - val_loss: 0.6422\n",
      "Epoch 363/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6555 - val_loss: 0.6421\n",
      "Epoch 364/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6554 - val_loss: 0.6420\n",
      "Epoch 365/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6554 - val_loss: 0.6420\n",
      "Epoch 366/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6553 - val_loss: 0.6419\n",
      "Epoch 367/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6553 - val_loss: 0.6419\n",
      "Epoch 368/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6552 - val_loss: 0.6418\n",
      "Epoch 369/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6552 - val_loss: 0.6418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 370/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6552 - val_loss: 0.6417\n",
      "Epoch 371/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6551 - val_loss: 0.6417\n",
      "Epoch 372/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6551 - val_loss: 0.6416\n",
      "Epoch 373/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6550 - val_loss: 0.6416\n",
      "Epoch 374/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6550 - val_loss: 0.6415\n",
      "Epoch 375/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6549 - val_loss: 0.6415\n",
      "Epoch 376/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6549 - val_loss: 0.6414\n",
      "Epoch 377/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6549 - val_loss: 0.6414\n",
      "Epoch 378/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6548 - val_loss: 0.6413\n",
      "Epoch 379/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6548 - val_loss: 0.6413\n",
      "Epoch 380/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6547 - val_loss: 0.6412\n",
      "Epoch 381/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6547 - val_loss: 0.6412\n",
      "Epoch 382/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6547 - val_loss: 0.6411\n",
      "Epoch 383/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6546 - val_loss: 0.6411\n",
      "Epoch 384/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6546 - val_loss: 0.6410\n",
      "Epoch 385/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6545 - val_loss: 0.6410\n",
      "Epoch 386/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6545 - val_loss: 0.6409\n",
      "Epoch 387/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6545 - val_loss: 0.6409\n",
      "Epoch 388/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6544 - val_loss: 0.6409\n",
      "Epoch 389/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6544 - val_loss: 0.6408\n",
      "Epoch 390/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6544 - val_loss: 0.6408\n",
      "Epoch 391/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6543 - val_loss: 0.6407\n",
      "Epoch 392/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6543 - val_loss: 0.6407\n",
      "Epoch 393/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6543 - val_loss: 0.6406\n",
      "Epoch 394/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6542 - val_loss: 0.6406\n",
      "Epoch 395/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6542 - val_loss: 0.6406\n",
      "Epoch 396/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6542 - val_loss: 0.6405\n",
      "Epoch 397/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6541 - val_loss: 0.6405\n",
      "Epoch 398/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6541 - val_loss: 0.6404\n",
      "Epoch 399/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6540 - val_loss: 0.6404\n",
      "Epoch 400/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6540 - val_loss: 0.6404\n",
      "Epoch 401/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6540 - val_loss: 0.6403\n",
      "Epoch 402/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6540 - val_loss: 0.6403\n",
      "Epoch 403/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6539 - val_loss: 0.6403\n",
      "Epoch 404/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6539 - val_loss: 0.6402\n",
      "Epoch 405/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6539 - val_loss: 0.6402\n",
      "Epoch 406/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6538 - val_loss: 0.6402\n",
      "Epoch 407/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6538 - val_loss: 0.6401\n",
      "Epoch 408/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6538 - val_loss: 0.6401\n",
      "Epoch 409/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6537 - val_loss: 0.6401\n",
      "Epoch 410/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6537 - val_loss: 0.6400\n",
      "Epoch 411/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6537 - val_loss: 0.6400\n",
      "Epoch 412/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6537 - val_loss: 0.6400\n",
      "Epoch 413/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6536 - val_loss: 0.6399\n",
      "Epoch 414/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6536 - val_loss: 0.6399\n",
      "Epoch 415/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6536 - val_loss: 0.6399\n",
      "Epoch 416/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6536 - val_loss: 0.6398\n",
      "Epoch 417/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6535 - val_loss: 0.6398\n",
      "Epoch 418/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6535 - val_loss: 0.6398\n",
      "Epoch 419/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6535 - val_loss: 0.6397\n",
      "Epoch 420/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6534 - val_loss: 0.6397\n",
      "Epoch 421/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6534 - val_loss: 0.6397\n",
      "Epoch 422/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6534 - val_loss: 0.6397\n",
      "Epoch 423/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6534 - val_loss: 0.6396\n",
      "Epoch 424/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6534 - val_loss: 0.6396\n",
      "Epoch 425/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6533 - val_loss: 0.6396\n",
      "Epoch 426/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6533 - val_loss: 0.6395\n",
      "Epoch 427/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6533 - val_loss: 0.6395\n",
      "Epoch 428/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6533 - val_loss: 0.6395\n",
      "Epoch 429/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6532 - val_loss: 0.6395\n",
      "Epoch 430/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6532 - val_loss: 0.6394\n",
      "Epoch 431/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6532 - val_loss: 0.6394\n",
      "Epoch 432/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6532 - val_loss: 0.6394\n",
      "Epoch 433/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6531 - val_loss: 0.6394\n",
      "Epoch 434/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6531 - val_loss: 0.6393\n",
      "Epoch 435/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6531 - val_loss: 0.6393\n",
      "Epoch 436/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6531 - val_loss: 0.6393\n",
      "Epoch 437/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6531 - val_loss: 0.6393\n",
      "Epoch 438/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6530 - val_loss: 0.6392\n",
      "Epoch 439/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6530 - val_loss: 0.6392\n",
      "Epoch 440/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6530 - val_loss: 0.6392\n",
      "Epoch 441/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6530 - val_loss: 0.6392\n",
      "Epoch 442/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6530 - val_loss: 0.6391\n",
      "Epoch 443/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6530 - val_loss: 0.6391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6529 - val_loss: 0.6391\n",
      "Epoch 445/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6529 - val_loss: 0.6391\n",
      "Epoch 446/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6529 - val_loss: 0.6390\n",
      "Epoch 447/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6529 - val_loss: 0.6390\n",
      "Epoch 448/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6529 - val_loss: 0.6390\n",
      "Epoch 449/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6528 - val_loss: 0.6390\n",
      "Epoch 450/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6528 - val_loss: 0.6390\n",
      "Epoch 451/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6528 - val_loss: 0.6389\n",
      "Epoch 452/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6528 - val_loss: 0.6389\n",
      "Epoch 453/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6528 - val_loss: 0.6389\n",
      "Epoch 454/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6528 - val_loss: 0.6389\n",
      "Epoch 455/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6527 - val_loss: 0.6389\n",
      "Epoch 456/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6527 - val_loss: 0.6388\n",
      "Epoch 457/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6527 - val_loss: 0.6388\n",
      "Epoch 458/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6527 - val_loss: 0.6388\n",
      "Epoch 459/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6527 - val_loss: 0.6388\n",
      "Epoch 460/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6527 - val_loss: 0.6387\n",
      "Epoch 461/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6526 - val_loss: 0.6387\n",
      "Epoch 462/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6526 - val_loss: 0.6387\n",
      "Epoch 463/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6526 - val_loss: 0.6387\n",
      "Epoch 464/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6526 - val_loss: 0.6387\n",
      "Epoch 465/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6526 - val_loss: 0.6386\n",
      "Epoch 466/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6526 - val_loss: 0.6386\n",
      "Epoch 467/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6526 - val_loss: 0.6386\n",
      "Epoch 468/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6525 - val_loss: 0.6386\n",
      "Epoch 469/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6525 - val_loss: 0.6386\n",
      "Epoch 470/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6525 - val_loss: 0.6385\n",
      "Epoch 471/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6525 - val_loss: 0.6385\n",
      "Epoch 472/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6525 - val_loss: 0.6385\n",
      "Epoch 473/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6525 - val_loss: 0.6385\n",
      "Epoch 474/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6525 - val_loss: 0.6385\n",
      "Epoch 475/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6524 - val_loss: 0.6385\n",
      "Epoch 476/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6524 - val_loss: 0.6384\n",
      "Epoch 477/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6524 - val_loss: 0.6384\n",
      "Epoch 478/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6524 - val_loss: 0.6384\n",
      "Epoch 479/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6524 - val_loss: 0.6384\n",
      "Epoch 480/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6524 - val_loss: 0.6384\n",
      "Epoch 481/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6524 - val_loss: 0.6383\n",
      "Epoch 482/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6523 - val_loss: 0.6383\n",
      "Epoch 483/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6523 - val_loss: 0.6383\n",
      "Epoch 484/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6523 - val_loss: 0.6383\n",
      "Epoch 485/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6523 - val_loss: 0.6383\n",
      "Epoch 486/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6523 - val_loss: 0.6383\n",
      "Epoch 487/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6523 - val_loss: 0.6382\n",
      "Epoch 488/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6523 - val_loss: 0.6382\n",
      "Epoch 489/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6523 - val_loss: 0.6382\n",
      "Epoch 490/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6522 - val_loss: 0.6382\n",
      "Epoch 491/10000\n",
      "24360/24360 [==============================] - 0s 8us/sample - loss: 0.6522 - val_loss: 0.6382\n",
      "Epoch 492/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6522 - val_loss: 0.6382\n",
      "Epoch 493/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6522 - val_loss: 0.6381\n",
      "Epoch 494/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6522 - val_loss: 0.6381\n",
      "Epoch 495/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6522 - val_loss: 0.6381\n",
      "Epoch 496/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6522 - val_loss: 0.6381\n",
      "Epoch 497/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6522 - val_loss: 0.6381\n",
      "Epoch 498/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6522 - val_loss: 0.6381\n",
      "Epoch 499/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6521 - val_loss: 0.6380\n",
      "Epoch 500/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6521 - val_loss: 0.6380\n",
      "Epoch 501/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6521 - val_loss: 0.6380\n",
      "Epoch 502/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6521 - val_loss: 0.6380\n",
      "Epoch 503/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6521 - val_loss: 0.6380\n",
      "Epoch 504/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6521 - val_loss: 0.6380\n",
      "Epoch 505/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6521 - val_loss: 0.6379\n",
      "Epoch 506/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6521 - val_loss: 0.6379\n",
      "Epoch 507/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6521 - val_loss: 0.6379\n",
      "Epoch 508/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6521 - val_loss: 0.6379\n",
      "Epoch 509/10000\n",
      "24360/24360 [==============================] - 0s 8us/sample - loss: 0.6520 - val_loss: 0.6379\n",
      "Epoch 510/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6520 - val_loss: 0.6379\n",
      "Epoch 511/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6520 - val_loss: 0.6379\n",
      "Epoch 512/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6520 - val_loss: 0.6378\n",
      "Epoch 513/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6520 - val_loss: 0.6378\n",
      "Epoch 514/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6520 - val_loss: 0.6378\n",
      "Epoch 515/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6520 - val_loss: 0.6378\n",
      "Epoch 516/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6520 - val_loss: 0.6378\n",
      "Epoch 517/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6520 - val_loss: 0.6378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 518/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6520 - val_loss: 0.6378\n",
      "Epoch 519/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6519 - val_loss: 0.6378\n",
      "Epoch 520/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6519 - val_loss: 0.6377\n",
      "Epoch 521/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6519 - val_loss: 0.6377\n",
      "Epoch 522/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6519 - val_loss: 0.6377\n",
      "Epoch 523/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6519 - val_loss: 0.6377\n",
      "Epoch 524/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6519 - val_loss: 0.6377\n",
      "Epoch 525/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6519 - val_loss: 0.6377\n",
      "Epoch 526/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6519 - val_loss: 0.6377\n",
      "Epoch 527/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6519 - val_loss: 0.6377\n",
      "Epoch 528/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6519 - val_loss: 0.6377\n",
      "Epoch 529/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6519 - val_loss: 0.6377\n",
      "Epoch 530/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6519 - val_loss: 0.6376\n",
      "Epoch 531/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6518 - val_loss: 0.6376\n",
      "Epoch 532/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6518 - val_loss: 0.6376\n",
      "Epoch 533/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6518 - val_loss: 0.6376\n",
      "Epoch 534/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6518 - val_loss: 0.6376\n",
      "Epoch 535/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6518 - val_loss: 0.6376\n",
      "Epoch 536/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6518 - val_loss: 0.6376\n",
      "Epoch 537/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6518 - val_loss: 0.6376\n",
      "Epoch 538/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6518 - val_loss: 0.6375\n",
      "Epoch 539/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6518 - val_loss: 0.6375\n",
      "Epoch 540/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6518 - val_loss: 0.6375\n",
      "Epoch 541/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6518 - val_loss: 0.6375\n",
      "Epoch 542/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6518 - val_loss: 0.6375\n",
      "Epoch 543/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6518 - val_loss: 0.6375\n",
      "Epoch 544/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6517 - val_loss: 0.6375\n",
      "Epoch 545/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6517 - val_loss: 0.6375\n",
      "Epoch 546/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6517 - val_loss: 0.6375\n",
      "Epoch 547/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6517 - val_loss: 0.6374\n",
      "Epoch 548/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6517 - val_loss: 0.6374\n",
      "Epoch 549/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6517 - val_loss: 0.6374\n",
      "Epoch 550/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6517 - val_loss: 0.6374\n",
      "Epoch 551/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6517 - val_loss: 0.6374\n",
      "Epoch 552/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6517 - val_loss: 0.6374\n",
      "Epoch 553/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6517 - val_loss: 0.6374\n",
      "Epoch 554/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6517 - val_loss: 0.6374\n",
      "Epoch 555/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6517 - val_loss: 0.6374\n",
      "Epoch 556/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6517 - val_loss: 0.6374\n",
      "Epoch 557/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6517 - val_loss: 0.6373\n",
      "Epoch 558/10000\n",
      "24360/24360 [==============================] - 0s 8us/sample - loss: 0.6516 - val_loss: 0.6373\n",
      "Epoch 559/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6516 - val_loss: 0.6373\n",
      "Epoch 560/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6516 - val_loss: 0.6373\n",
      "Epoch 561/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6516 - val_loss: 0.6373\n",
      "Epoch 562/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6516 - val_loss: 0.6373\n",
      "Epoch 563/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6516 - val_loss: 0.6373\n",
      "Epoch 564/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6516 - val_loss: 0.6373\n",
      "Epoch 565/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6516 - val_loss: 0.6373\n",
      "Epoch 566/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6516 - val_loss: 0.6373\n",
      "Epoch 567/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6516 - val_loss: 0.6373\n",
      "Epoch 568/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6516 - val_loss: 0.6372\n",
      "Epoch 569/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6516 - val_loss: 0.6372\n",
      "Epoch 570/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6516 - val_loss: 0.6372\n",
      "Epoch 571/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6516 - val_loss: 0.6372\n",
      "Epoch 572/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6516 - val_loss: 0.6372\n",
      "Epoch 573/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6516 - val_loss: 0.6372\n",
      "Epoch 574/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6515 - val_loss: 0.6372\n",
      "Epoch 575/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6515 - val_loss: 0.6372\n",
      "Epoch 576/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6515 - val_loss: 0.6372\n",
      "Epoch 577/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6515 - val_loss: 0.6372\n",
      "Epoch 578/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6515 - val_loss: 0.6372\n",
      "Epoch 579/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6515 - val_loss: 0.6372\n",
      "Epoch 580/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6515 - val_loss: 0.6372\n",
      "Epoch 581/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6515 - val_loss: 0.6372\n",
      "Epoch 582/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6515 - val_loss: 0.6372\n",
      "Epoch 583/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6515 - val_loss: 0.6372\n",
      "Epoch 584/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6515 - val_loss: 0.6371\n",
      "Epoch 585/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6515 - val_loss: 0.6371\n",
      "Epoch 586/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6515 - val_loss: 0.6371\n",
      "Epoch 587/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6515 - val_loss: 0.6371\n",
      "Epoch 588/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6515 - val_loss: 0.6371\n",
      "Epoch 589/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6515 - val_loss: 0.6371\n",
      "Epoch 590/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6515 - val_loss: 0.6371\n",
      "Epoch 591/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6515 - val_loss: 0.6371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 592/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6514 - val_loss: 0.6371\n",
      "Epoch 593/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6514 - val_loss: 0.6371\n",
      "Epoch 594/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6514 - val_loss: 0.6371\n",
      "Epoch 595/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6514 - val_loss: 0.6371\n",
      "Epoch 596/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6514 - val_loss: 0.6371\n",
      "Epoch 597/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6514 - val_loss: 0.6371\n",
      "Epoch 598/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6514 - val_loss: 0.6371\n",
      "Epoch 599/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6514 - val_loss: 0.6371\n",
      "Epoch 600/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6514 - val_loss: 0.6371\n",
      "Epoch 601/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6514 - val_loss: 0.6371\n",
      "Epoch 602/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6514 - val_loss: 0.6370\n",
      "Epoch 603/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6514 - val_loss: 0.6370\n",
      "Epoch 604/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6514 - val_loss: 0.6370\n",
      "Epoch 605/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6514 - val_loss: 0.6370\n",
      "Epoch 606/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6514 - val_loss: 0.6370\n",
      "Epoch 607/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6514 - val_loss: 0.6370\n",
      "Epoch 608/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6514 - val_loss: 0.6370\n",
      "Epoch 609/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6514 - val_loss: 0.6370\n",
      "Epoch 610/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6514 - val_loss: 0.6370\n",
      "Epoch 611/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6514 - val_loss: 0.6370\n",
      "Epoch 612/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6513 - val_loss: 0.6370\n",
      "Epoch 613/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6513 - val_loss: 0.6370\n",
      "Epoch 614/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6513 - val_loss: 0.6370\n",
      "Epoch 615/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6513 - val_loss: 0.6370\n",
      "Epoch 616/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6513 - val_loss: 0.6370\n",
      "Epoch 617/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6513 - val_loss: 0.6370\n",
      "Epoch 618/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6513 - val_loss: 0.6370\n",
      "Epoch 619/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6513 - val_loss: 0.6369\n",
      "Epoch 620/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6513 - val_loss: 0.6369\n",
      "Epoch 621/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6513 - val_loss: 0.6369\n",
      "Epoch 622/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6513 - val_loss: 0.6369\n",
      "Epoch 623/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6513 - val_loss: 0.6369\n",
      "Epoch 624/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6513 - val_loss: 0.6369\n",
      "Epoch 625/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6513 - val_loss: 0.6369\n",
      "Epoch 626/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6513 - val_loss: 0.6369\n",
      "Epoch 627/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6513 - val_loss: 0.6369\n",
      "Epoch 628/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6513 - val_loss: 0.6369\n",
      "Epoch 629/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6513 - val_loss: 0.6369\n",
      "Epoch 630/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6513 - val_loss: 0.6369\n",
      "Epoch 631/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6513 - val_loss: 0.6369\n",
      "Epoch 632/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6513 - val_loss: 0.6369\n",
      "Epoch 633/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6513 - val_loss: 0.6369\n",
      "Epoch 634/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6512 - val_loss: 0.6368\n",
      "Epoch 635/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6512 - val_loss: 0.6368\n",
      "Epoch 636/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6512 - val_loss: 0.6368\n",
      "Epoch 637/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6512 - val_loss: 0.6368\n",
      "Epoch 638/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6512 - val_loss: 0.6368\n",
      "Epoch 639/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6512 - val_loss: 0.6368\n",
      "Epoch 640/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6512 - val_loss: 0.6368\n",
      "Epoch 641/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6512 - val_loss: 0.6368\n",
      "Epoch 642/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6512 - val_loss: 0.6368\n",
      "Epoch 643/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6512 - val_loss: 0.6368\n",
      "Epoch 644/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6512 - val_loss: 0.6368\n",
      "Epoch 645/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6512 - val_loss: 0.6368\n",
      "Epoch 646/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6512 - val_loss: 0.6368\n",
      "Epoch 647/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6512 - val_loss: 0.6368\n",
      "Epoch 648/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6512 - val_loss: 0.6368\n",
      "Epoch 649/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6512 - val_loss: 0.6368\n",
      "Epoch 650/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6512 - val_loss: 0.6368\n",
      "Epoch 651/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6512 - val_loss: 0.6368\n",
      "Epoch 652/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6512 - val_loss: 0.6368\n",
      "Epoch 653/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6512 - val_loss: 0.6368\n",
      "Epoch 654/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6512 - val_loss: 0.6367\n",
      "Epoch 655/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6512 - val_loss: 0.6367\n",
      "Epoch 656/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6512 - val_loss: 0.6367\n",
      "Epoch 657/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6512 - val_loss: 0.6367\n",
      "Epoch 658/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6512 - val_loss: 0.6367\n",
      "Epoch 659/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6511 - val_loss: 0.6367\n",
      "Epoch 660/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6511 - val_loss: 0.6367\n",
      "Epoch 661/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6511 - val_loss: 0.6367\n",
      "Epoch 662/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6511 - val_loss: 0.6367\n",
      "Epoch 663/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6511 - val_loss: 0.6367\n",
      "Epoch 664/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6511 - val_loss: 0.6367\n",
      "Epoch 665/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6511 - val_loss: 0.6367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 666/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6511 - val_loss: 0.6367\n",
      "Epoch 667/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6511 - val_loss: 0.6367\n",
      "Epoch 668/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6511 - val_loss: 0.6367\n",
      "Epoch 669/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6511 - val_loss: 0.6367\n",
      "Epoch 670/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6511 - val_loss: 0.6367\n",
      "Epoch 671/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6511 - val_loss: 0.6367\n",
      "Epoch 672/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6511 - val_loss: 0.6367\n",
      "Epoch 673/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6511 - val_loss: 0.6367\n",
      "Epoch 674/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6511 - val_loss: 0.6367\n",
      "Epoch 675/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6511 - val_loss: 0.6367\n",
      "Epoch 676/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6511 - val_loss: 0.6367\n",
      "Epoch 677/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6511 - val_loss: 0.6367\n",
      "Epoch 678/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6511 - val_loss: 0.6367\n",
      "Epoch 679/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6511 - val_loss: 0.6367\n",
      "Epoch 680/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6511 - val_loss: 0.6366\n",
      "Epoch 681/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6511 - val_loss: 0.6366\n",
      "Epoch 682/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6511 - val_loss: 0.6366\n",
      "Epoch 683/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6511 - val_loss: 0.6366\n",
      "Epoch 684/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6511 - val_loss: 0.6366\n",
      "Epoch 685/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6511 - val_loss: 0.6366\n",
      "Epoch 686/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6511 - val_loss: 0.6366\n",
      "Epoch 687/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6511 - val_loss: 0.6366\n",
      "Epoch 688/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6510 - val_loss: 0.6366\n",
      "Epoch 689/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6510 - val_loss: 0.6366\n",
      "Epoch 690/10000\n",
      "24360/24360 [==============================] - 0s 9us/sample - loss: 0.6510 - val_loss: 0.6366\n",
      "Epoch 691/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6510 - val_loss: 0.6366\n",
      "Epoch 692/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6510 - val_loss: 0.6366\n",
      "Epoch 693/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6510 - val_loss: 0.6366\n",
      "Epoch 694/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6510 - val_loss: 0.6366\n",
      "Epoch 695/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6510 - val_loss: 0.6366\n",
      "Epoch 696/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6510 - val_loss: 0.6366\n",
      "Epoch 697/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6510 - val_loss: 0.6366\n",
      "Epoch 698/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6510 - val_loss: 0.6366\n",
      "Epoch 699/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6510 - val_loss: 0.6366\n",
      "Epoch 700/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6510 - val_loss: 0.6366\n",
      "Epoch 701/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6510 - val_loss: 0.6366\n",
      "Epoch 702/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6510 - val_loss: 0.6366\n",
      "Epoch 703/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6510 - val_loss: 0.6366\n",
      "Epoch 704/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6510 - val_loss: 0.6366\n",
      "Epoch 705/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6510 - val_loss: 0.6366\n",
      "Epoch 706/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6510 - val_loss: 0.6366\n",
      "Epoch 707/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6510 - val_loss: 0.6366\n",
      "Epoch 708/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6510 - val_loss: 0.6366\n",
      "Epoch 709/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6510 - val_loss: 0.6366\n",
      "Epoch 710/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6510 - val_loss: 0.6365\n",
      "Epoch 711/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6510 - val_loss: 0.6365\n",
      "Epoch 712/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6510 - val_loss: 0.6365\n",
      "Epoch 713/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6510 - val_loss: 0.6365\n",
      "Epoch 714/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6510 - val_loss: 0.6365\n",
      "Epoch 715/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6510 - val_loss: 0.6365\n",
      "Epoch 716/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6510 - val_loss: 0.6365\n",
      "Epoch 717/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6510 - val_loss: 0.6365\n",
      "Epoch 718/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6510 - val_loss: 0.6365\n",
      "Epoch 719/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6510 - val_loss: 0.6365\n",
      "Epoch 720/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6510 - val_loss: 0.6365\n",
      "Epoch 721/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 722/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 723/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 724/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 725/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 726/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 727/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 728/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 729/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 730/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 731/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 732/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 733/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 734/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 735/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 736/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 737/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 738/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 739/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6509 - val_loss: 0.6365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 740/10000\n",
      "24360/24360 [==============================] - 0s 8us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 741/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 742/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 743/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 744/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 745/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 746/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 747/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 748/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 749/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 750/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 751/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 752/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 753/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 754/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 755/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 756/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 757/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6509 - val_loss: 0.6365\n",
      "Epoch 758/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6509 - val_loss: 0.6364\n",
      "Epoch 759/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6509 - val_loss: 0.6364\n",
      "Epoch 760/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 761/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 762/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 763/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 764/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 765/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 766/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 767/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 768/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 769/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 770/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 771/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 772/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 773/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 774/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 775/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 776/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 777/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 778/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 779/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 780/10000\n",
      "24360/24360 [==============================] - 0s 8us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 781/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 782/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 783/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 784/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 785/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 786/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 787/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 788/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 789/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 790/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 791/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 792/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 793/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 794/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 795/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 796/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 797/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 798/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 799/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 800/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 801/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 802/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 803/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6508 - val_loss: 0.6364\n",
      "Epoch 804/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6508 - val_loss: 0.6363\n",
      "Epoch 805/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 806/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 807/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 808/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 809/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 810/10000\n",
      "24360/24360 [==============================] - 0s 8us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 811/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 812/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 813/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6507 - val_loss: 0.6363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 814/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 815/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 816/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 817/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 818/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 819/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 820/10000\n",
      "24360/24360 [==============================] - 0s 8us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 821/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 822/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 823/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 824/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 825/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 826/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 827/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 828/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 829/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 830/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 831/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 832/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 833/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 834/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 835/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 836/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 837/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 838/10000\n",
      "24360/24360 [==============================] - 0s 8us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 839/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 840/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 841/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 842/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 843/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 844/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 845/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 846/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 847/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 848/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 849/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 850/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 851/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 852/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 853/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 854/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 855/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 856/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 857/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 858/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 859/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6507 - val_loss: 0.6363\n",
      "Epoch 860/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6506 - val_loss: 0.6363\n",
      "Epoch 861/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 862/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 863/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 864/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 865/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 866/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 867/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 868/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 869/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 870/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 871/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 872/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 873/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 874/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 875/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 876/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 877/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 878/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 879/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 880/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 881/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 882/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 883/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 884/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 885/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 886/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 887/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 888/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 889/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 890/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 891/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 892/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 893/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 894/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 895/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 896/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 897/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 898/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 899/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 900/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 901/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 902/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 903/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 904/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 905/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 906/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 907/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 908/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 909/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 910/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 911/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 912/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 913/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 914/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 915/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 916/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 917/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 918/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 919/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 920/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 921/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 922/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 923/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 924/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 925/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 926/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 927/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 928/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6506 - val_loss: 0.6362\n",
      "Epoch 929/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 930/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 931/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 932/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 933/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 934/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 935/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 936/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 937/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 938/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 939/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 940/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 941/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 942/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 943/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 944/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 945/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 946/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 947/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 948/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 949/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 950/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 951/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 952/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 953/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 954/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 955/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 956/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 957/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 958/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 959/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 960/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 961/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 962/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 963/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 964/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 965/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 966/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 967/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 968/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 969/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 970/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 971/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 972/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 973/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 974/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 975/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 976/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 977/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 978/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 979/10000\n",
      "24360/24360 [==============================] - 0s 8us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 980/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 981/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 982/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 983/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 984/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 985/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 986/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 987/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 988/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 989/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 990/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 991/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 992/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 993/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 994/10000\n",
      "24360/24360 [==============================] - 0s 8us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 995/10000\n",
      "24360/24360 [==============================] - 0s 11us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 996/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 997/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 998/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 999/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 1000/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 1001/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 1002/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 1003/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 1004/10000\n",
      "24360/24360 [==============================] - 0s 5us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 1005/10000\n",
      "24360/24360 [==============================] - 0s 5us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 1006/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 1007/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 1008/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 1009/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 1010/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 1011/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 1012/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 1013/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 1014/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 1015/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 1016/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 1017/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 1018/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 1019/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 1020/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6505 - val_loss: 0.6362\n",
      "Epoch 1021/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1022/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1023/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1024/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1025/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1026/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1027/10000\n",
      "24360/24360 [==============================] - 1s 28us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1028/10000\n",
      "24360/24360 [==============================] - 0s 13us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1029/10000\n",
      "24360/24360 [==============================] - 0s 9us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1030/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1031/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1032/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1033/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1034/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1035/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1036/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1037/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1038/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1039/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1040/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1041/10000\n",
      "24360/24360 [==============================] - 0s 8us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1042/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1043/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1044/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1045/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1046/10000\n",
      "24360/24360 [==============================] - 0s 8us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1047/10000\n",
      "24360/24360 [==============================] - 0s 9us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1048/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1049/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1050/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1051/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1052/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1053/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1054/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1055/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1056/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1057/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1058/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1059/10000\n",
      "24360/24360 [==============================] - 0s 8us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1060/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1061/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1062/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1063/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1064/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1065/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1066/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1067/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1068/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1069/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1070/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1071/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1072/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1073/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1074/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1075/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1076/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1077/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1078/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1079/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1080/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1081/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1082/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1083/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1084/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1085/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1086/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1087/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1088/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1089/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1090/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1091/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1092/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1093/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1094/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1095/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1096/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1097/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1098/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1099/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1100/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1101/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1102/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1103/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1104/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1105/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1106/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1107/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1108/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1109/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1110/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1111/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1112/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1113/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1114/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1115/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1116/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1117/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1118/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1119/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1120/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1121/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1122/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1123/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1124/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1125/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1126/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1127/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1128/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1129/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1130/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1131/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1132/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1133/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1134/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1135/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1136/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1137/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1138/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1139/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1140/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1141/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1142/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1143/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1144/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1145/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1146/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1147/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1148/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1149/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1150/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1151/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1152/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1153/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1154/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1155/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1156/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1157/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1158/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1159/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1160/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1161/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1162/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1163/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6504 - val_loss: 0.6362\n",
      "Epoch 1164/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1165/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1166/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1167/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1168/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1169/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1170/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1171/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1172/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1173/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1174/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1175/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1176/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1177/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1178/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1179/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1180/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1181/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1182/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1183/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1184/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1185/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1186/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1187/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1188/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1189/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1190/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1191/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1192/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1193/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1194/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1195/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1196/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1197/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1198/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1199/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1200/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1201/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1202/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1203/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1204/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1205/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1206/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1207/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1208/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1209/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1210/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1211/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1212/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1213/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1214/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1215/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1216/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1217/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1218/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1219/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1220/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1221/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1222/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1223/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1224/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1225/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1226/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1227/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1228/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1229/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1230/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1231/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1232/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1233/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1234/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1235/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1236/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1237/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1238/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1239/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1240/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1241/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1242/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1243/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1244/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1245/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1246/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1247/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1248/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1249/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1250/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1251/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1252/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1253/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1254/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1255/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1256/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1257/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1258/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1259/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1260/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1261/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1262/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1263/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1264/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1265/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1266/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1267/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1268/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1269/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1270/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1271/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1272/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1273/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1274/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1275/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1276/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1277/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1278/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1279/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1280/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1281/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1282/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1283/10000\n",
      "24360/24360 [==============================] - 0s 5us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1284/10000\n",
      "24360/24360 [==============================] - 0s 5us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1285/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1286/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1287/10000\n",
      "24360/24360 [==============================] - 0s 5us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1288/10000\n",
      "24360/24360 [==============================] - 0s 5us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1289/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1290/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1291/10000\n",
      "24360/24360 [==============================] - 0s 5us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1292/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1293/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1294/10000\n",
      "24360/24360 [==============================] - 0s 5us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1295/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1296/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1297/10000\n",
      "24360/24360 [==============================] - 0s 5us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1298/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1299/10000\n",
      "24360/24360 [==============================] - 0s 5us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1300/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1301/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1302/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1303/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1304/10000\n",
      "24360/24360 [==============================] - 0s 5us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1305/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1306/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1307/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1308/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1309/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1310/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1311/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1312/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1313/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1314/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1315/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1316/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1317/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1318/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1319/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1320/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1321/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1322/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1323/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1324/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1325/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1326/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1327/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1328/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1329/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1330/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1331/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1332/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1333/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1334/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1335/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1336/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1337/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1338/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1339/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1340/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1341/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6362\n",
      "Epoch 1342/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1343/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1344/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1345/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1346/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1347/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1348/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1349/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1350/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1351/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1352/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1353/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1354/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1355/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1356/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1357/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1358/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1359/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1360/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1361/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1362/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1363/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1364/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1365/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1366/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1367/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1368/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1369/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1370/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1371/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1372/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1373/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1374/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1375/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1376/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1377/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1378/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1379/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1380/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1381/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1382/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1383/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1384/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1385/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1386/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1387/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1388/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1389/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1390/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1391/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1392/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1393/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1394/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1395/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1396/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1397/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1398/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1399/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1400/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1401/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1402/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1403/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1404/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1405/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1406/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1407/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1408/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1409/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6503 - val_loss: 0.6361\n",
      "Epoch 1410/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1411/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1412/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1413/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1414/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1415/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1416/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1417/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1418/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1419/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1420/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1421/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1422/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1423/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1424/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1425/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1426/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1427/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1428/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1429/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1430/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1431/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1432/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1433/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1434/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1435/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1436/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1437/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1438/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1439/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1440/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1441/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1442/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1443/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1444/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1445/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1446/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1447/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1448/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1449/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1450/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1451/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1452/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1453/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1454/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1455/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1456/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1457/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1458/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1459/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1460/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1461/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1462/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1463/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1464/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1465/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1466/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1467/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1468/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1469/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1470/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1471/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1472/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1473/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1474/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1475/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1476/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1477/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1478/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1479/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1480/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1481/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1482/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1483/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1484/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1485/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1486/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1487/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1488/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1489/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1490/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1491/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1492/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1493/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1494/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1495/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1496/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1497/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1498/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1499/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1500/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1501/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1502/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1503/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1504/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1505/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1506/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1507/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1508/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1509/10000\n",
      "24360/24360 [==============================] - 0s 5us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1510/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1511/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1512/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1513/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1514/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1515/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1516/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1517/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1518/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1519/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1520/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1521/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1522/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1523/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1524/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1525/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1526/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1527/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1528/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1529/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1530/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1531/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1532/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1533/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1534/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1535/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1536/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1537/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1538/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1539/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1540/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1541/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1542/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1543/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1544/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1545/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1546/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1547/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1548/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1549/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1550/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1551/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1552/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1553/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1554/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1555/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1556/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1557/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1558/10000\n",
      "24360/24360 [==============================] - 0s 8us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1559/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1560/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1561/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1562/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1563/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1564/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1565/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1566/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1567/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1568/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1569/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1570/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1571/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1572/10000\n",
      "24360/24360 [==============================] - 0s 8us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1573/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1574/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1575/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1576/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1577/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1578/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1579/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1580/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1581/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1582/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1583/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1584/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1585/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1586/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1587/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1588/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1589/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1590/10000\n",
      "24360/24360 [==============================] - 0s 8us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1591/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1592/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1593/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1594/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1595/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1596/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1597/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1598/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1599/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1600/10000\n",
      "24360/24360 [==============================] - 0s 8us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1601/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1602/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1603/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1604/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1605/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1606/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1607/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1608/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1609/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1610/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1611/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1612/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1613/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1614/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1615/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1616/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1617/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1618/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1619/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1620/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1621/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1622/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1623/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1624/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1625/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1626/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1627/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1628/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1629/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1630/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1631/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1632/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1633/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1634/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1635/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1636/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1637/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1638/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1639/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1640/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1641/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1642/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1643/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1644/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1645/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1646/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1647/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1648/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1649/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1650/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1651/10000\n",
      "24360/24360 [==============================] - 0s 8us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1652/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1653/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1654/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1655/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1656/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1657/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1658/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1659/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1660/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1661/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1662/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1663/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1664/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1665/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1666/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1667/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1668/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1669/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1670/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1671/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1672/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1673/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1674/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6502 - val_loss: 0.6361\n",
      "Epoch 1675/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1676/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1677/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1678/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1679/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1680/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1681/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1682/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1683/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1684/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1685/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1686/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1687/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1688/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1689/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1690/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1691/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1692/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1693/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1694/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1695/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1696/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1697/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1698/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1699/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1700/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1701/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1702/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1703/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1704/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1705/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1706/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1707/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1708/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1709/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1710/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1711/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1712/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1713/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1714/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1715/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1716/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1717/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1718/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1719/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1720/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1721/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1722/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1723/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1724/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1725/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1726/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1727/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1728/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1729/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1730/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1731/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1732/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1733/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1734/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1735/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1736/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1737/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1738/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1739/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1740/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1741/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1742/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1743/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1744/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1745/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1746/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1747/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1748/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1749/10000\n",
      "24360/24360 [==============================] - 0s 7us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1750/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1751/10000\n",
      "24360/24360 [==============================] - 0s 6us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "Epoch 1752/10000\n",
      "24360/24360 [==============================] - 0s 8us/sample - loss: 0.6501 - val_loss: 0.6361\n",
      "CPU times: user 9min 5s, sys: 7min 34s, total: 16min 40s\n",
      "Wall time: 4min 34s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>μ</th>\n",
       "      <th>σ</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y^ (t)</th>\n",
       "      <td>24360</td>\n",
       "      <td>0.019619</td>\n",
       "      <td>0.043864</td>\n",
       "      <td>1.012658</td>\n",
       "      <td>2.502317</td>\n",
       "      <td>-1.897469e-01</td>\n",
       "      <td>0.406207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Δ (t)</th>\n",
       "      <td>24360</td>\n",
       "      <td>-0.019619</td>\n",
       "      <td>0.999297</td>\n",
       "      <td>-1.415224</td>\n",
       "      <td>52.017261</td>\n",
       "      <td>-3.140312e+01</td>\n",
       "      <td>12.819992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>|Δ| (t)</th>\n",
       "      <td>24360</td>\n",
       "      <td>0.650158</td>\n",
       "      <td>0.759115</td>\n",
       "      <td>6.019415</td>\n",
       "      <td>136.992603</td>\n",
       "      <td>1.741015e-05</td>\n",
       "      <td>31.403115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Δ² (t)</th>\n",
       "      <td>24360</td>\n",
       "      <td>0.998938</td>\n",
       "      <td>7.346811</td>\n",
       "      <td>103.074363</td>\n",
       "      <td>13393.219163</td>\n",
       "      <td>3.031135e-10</td>\n",
       "      <td>986.155661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y^ (v)</th>\n",
       "      <td>6218</td>\n",
       "      <td>0.018944</td>\n",
       "      <td>0.043306</td>\n",
       "      <td>1.023321</td>\n",
       "      <td>2.396901</td>\n",
       "      <td>-1.155139e-01</td>\n",
       "      <td>0.374952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Δ (v)</th>\n",
       "      <td>6218</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.969040</td>\n",
       "      <td>-0.374125</td>\n",
       "      <td>14.374930</td>\n",
       "      <td>-1.284923e+01</td>\n",
       "      <td>10.736257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>|Δ| (v)</th>\n",
       "      <td>6218</td>\n",
       "      <td>0.636099</td>\n",
       "      <td>0.730993</td>\n",
       "      <td>3.877348</td>\n",
       "      <td>32.043209</td>\n",
       "      <td>2.407221e-05</td>\n",
       "      <td>12.849234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Δ² (v)</th>\n",
       "      <td>6218</td>\n",
       "      <td>0.938887</td>\n",
       "      <td>3.799591</td>\n",
       "      <td>22.245721</td>\n",
       "      <td>758.895324</td>\n",
       "      <td>5.794713e-10</td>\n",
       "      <td>165.102824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y^ (*)</th>\n",
       "      <td>30578</td>\n",
       "      <td>0.019482</td>\n",
       "      <td>0.043751</td>\n",
       "      <td>1.014934</td>\n",
       "      <td>2.482415</td>\n",
       "      <td>-1.897469e-01</td>\n",
       "      <td>0.406207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Δ (*)</th>\n",
       "      <td>30578</td>\n",
       "      <td>-0.015620</td>\n",
       "      <td>0.993235</td>\n",
       "      <td>-1.219416</td>\n",
       "      <td>45.123572</td>\n",
       "      <td>-3.140312e+01</td>\n",
       "      <td>12.819992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>|Δ| (*)</th>\n",
       "      <td>30578</td>\n",
       "      <td>0.647299</td>\n",
       "      <td>0.753491</td>\n",
       "      <td>5.623943</td>\n",
       "      <td>118.233171</td>\n",
       "      <td>1.741015e-05</td>\n",
       "      <td>31.403115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Δ² (*)</th>\n",
       "      <td>30578</td>\n",
       "      <td>0.986727</td>\n",
       "      <td>6.777560</td>\n",
       "      <td>105.390513</td>\n",
       "      <td>14747.859487</td>\n",
       "      <td>3.031135e-10</td>\n",
       "      <td>986.155661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             n         μ         σ    skewness      kurtosis           min  \\\n",
       "y^ (t)   24360  0.019619  0.043864    1.012658      2.502317 -1.897469e-01   \n",
       "Δ (t)    24360 -0.019619  0.999297   -1.415224     52.017261 -3.140312e+01   \n",
       "|Δ| (t)  24360  0.650158  0.759115    6.019415    136.992603  1.741015e-05   \n",
       "Δ² (t)   24360  0.998938  7.346811  103.074363  13393.219163  3.031135e-10   \n",
       "y^ (v)    6218  0.018944  0.043306    1.023321      2.396901 -1.155139e-01   \n",
       "Δ (v)     6218  0.000048  0.969040   -0.374125     14.374930 -1.284923e+01   \n",
       "|Δ| (v)   6218  0.636099  0.730993    3.877348     32.043209  2.407221e-05   \n",
       "Δ² (v)    6218  0.938887  3.799591   22.245721    758.895324  5.794713e-10   \n",
       "y^ (*)   30578  0.019482  0.043751    1.014934      2.482415 -1.897469e-01   \n",
       "Δ (*)    30578 -0.015620  0.993235   -1.219416     45.123572 -3.140312e+01   \n",
       "|Δ| (*)  30578  0.647299  0.753491    5.623943    118.233171  1.741015e-05   \n",
       "Δ² (*)   30578  0.986727  6.777560  105.390513  14747.859487  3.031135e-10   \n",
       "\n",
       "                max  \n",
       "y^ (t)     0.406207  \n",
       "Δ (t)     12.819992  \n",
       "|Δ| (t)   31.403115  \n",
       "Δ² (t)   986.155661  \n",
       "y^ (v)     0.374952  \n",
       "Δ (v)     10.736257  \n",
       "|Δ| (v)   12.849234  \n",
       "Δ² (v)   165.102824  \n",
       "y^ (*)     0.406207  \n",
       "Δ (*)     12.819992  \n",
       "|Δ| (*)   31.403115  \n",
       "Δ² (*)   986.155661  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(tx, ty, \n",
    "          validation_data=(vx, vy),\n",
    "          batch_size=batch_size,\n",
    "          epochs=max_epochs,\n",
    "          callbacks=[\n",
    "              EarlyStopping(patience=100, restore_best_weights=True),\n",
    "              ModelCheckpoint(str(model_ckpt_path), save_weights_only=True, save_best_only=True, period=20),\n",
    "          ]\n",
    "         )\n",
    "diffs_df(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = DF(model.history.history)\n",
    "hist.iloc[-110:-90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.iloc[-200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model.get_weights(); w, [ l.shape for l in w ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(ty)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks-3.7.4",
   "language": "python",
   "name": "notebooks-3.7.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
