{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit Kubeflow Pipelines as `ScheduledWorkflow`s\n",
    "This notebook shows examples of submitting Kubeflow [`ScheduledWorkflow`s](https://github.com/kubeflow/pipelines/blob/0.1.31/backend/src/crd/pkg/apis/scheduledworkflow/register.go) (SWFs) that run [Kubeflow Pipelines](https://www.kubeflow.org/docs/pipelines/) (KFPs).\n",
    "\n",
    "It contains helper-functions for easy fetching and wrapping of KFPs in SWFs, as well as [examples demonstrating these capabilities](#examples).\n",
    "\n",
    "## Wrapping a Kubeflow Pipeline in a `ScheduledWorkflow`\n",
    "Conceptually, a \"scheduled\" Kubeflow Pipeline must take exactly one argument: the timestamp it was scheduled to run at. Any other parameters it normally accepts must be [partially-applied](https://en.wikipedia.org/wiki/Partial_application) away (i.e. assigned specific, concrete values), leaving just the timestamp parameter to be filled by the SWF machinery on each pipeline instantiation. \n",
    "\n",
    "## Past and Present Runs\n",
    "\n",
    "The timestamp passed by the SWF controller to each KFP instance it spawns will generally be one of two types:\n",
    "- a timestamp close to the current time (when the SWF is caught up to the present, and spawning KFPs according to a `crontab`-style schedule or fixed interval)\n",
    "- a timestamp in the past (when the SWF is created with a \"start\" time in the past, and is back-filling KFP runs to catch up to the present)\n",
    "\n",
    "\n",
    "## TODOs\n",
    "- [ ] factor out helpers\n",
    "- tests:\n",
    "  - example pipelines:\n",
    "      - [x] `gs://ml-pipeline-playground/coin.tar.gz`\n",
    "      - [ ] [`https://storage.googleapis.com/ml-pipeline-playground/coin.tar.gz`](https://storage.googleapis.com/ml-pipeline-playground/coin.tar.gz)\n",
    "      - [x] [`https://raw.githubusercontent.com/kubeflow/pipelines/0.1.31/samples/core/condition/condition.py`](https://raw.githubusercontent.com/kubeflow/pipelines/0.1.31/samples/core/condition/condition.py)\n",
    "      - [ ] `component.yaml` example(s) (TODO: which one(s)?)\n",
    "      - [ ] Bitcoin BigQuery monthly rollups\n",
    "      - [ ] Current Weather (OpenWeather)\n",
    "      - [ ] Stock movements (IEX API)\n",
    "  - scheduling:\n",
    "      - [ ] intervals\n",
    "      - [x] start/end times\n",
    "      - [ ] updating/clearing time-bounds\n",
    "- [x] `!pip install` requirements\n",
    "- [ ] (optionally) pass scheduled time to pipeline\n",
    "- [ ] verify provided pipelines take no arguments (other than e.g. scheduled datetime)\n",
    "- [ ] parameterize notebook w/ `papermill`\n",
    "- [ ] support wrapping `component.yaml`s into Pipelines and running\n",
    "  - [ ] verify no extra arguments to provided components\n",
    "- [x] publish runner container publicly\n",
    "- [x] publish SWF+KFP YAML template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install KFP SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import executable as python\n",
    "kfp_version = '0.1.31'\n",
    "!{python} -m pip install kfp=={kfp_version} --upgrade -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "Below are utilities for:\n",
    "- [fetching/loading pipelines](#Pipeline-fetching/loading)\n",
    "- [parsing their YAML definitions](#Pipeline-spec-accessors)\n",
    "- [building `ScheduledWorkflow` resources](#ScheduledWorkflow-builders)\n",
    "- [`import`ing remote `.py` files](#importing-remote-modules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline fetching/loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "def url_to_stream(url):\n",
    "    \"\"\"Return a file-like-object from a local or remote (\"gs\" or \"https?\") URL\"\"\"\n",
    "    from urllib.parse import urlparse\n",
    "    parsed = urlparse(url)\n",
    "    scheme = parsed.scheme\n",
    "    if not scheme:\n",
    "        return open(url, 'rb')\n",
    "    elif scheme == 'http' or scheme == 'https':\n",
    "        @contextmanager\n",
    "        def UrlOpen(url):\n",
    "            from urllib.request import urlopen\n",
    "            stream = urlopen(url)\n",
    "            try:\n",
    "                yield stream\n",
    "            finally:\n",
    "                stream.close()\n",
    "\n",
    "        return UrlOpen(url)\n",
    "    elif scheme == 'gs':\n",
    "        from google.cloud import storage\n",
    "        gcs = storage.Client()\n",
    "        from tempfile import NamedTemporaryFile, TemporaryDirectory\n",
    "        tmp = TemporaryDirectory()\n",
    "        from os.path import basename, join, exists\n",
    "        name = basename(parsed.path)\n",
    "        path = join(tmp.name, name)\n",
    "\n",
    "        with open(path, 'wb') as dest:\n",
    "            gcs.download_blob_to_file(url, dest)\n",
    "\n",
    "        @contextmanager\n",
    "        def GcsFetchOpen(url):\n",
    "            try:\n",
    "                yield open(path, 'rb')\n",
    "            finally:\n",
    "                with tmp:\n",
    "                    pass\n",
    "                \n",
    "        return GcsFetchOpen(url)\n",
    "    else:\n",
    "        raise Exception(\"Unsure how to handle URL scheme '%s' (%s)\" % (scheme, url))\n",
    "\n",
    "def url_to_bytes(url):\n",
    "    \"\"\"Return the contents of a local or remote (\"gs\" or \"https?\") URL\"\"\"\n",
    "    with url_to_stream(url) as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_extract_pipeline_tar(bytes):\n",
    "    \"\"\"Attempt to parse `bytes` as a TAR archive and extract a `pipeline.yaml`\"\"\"\n",
    "    import tarfile\n",
    "    from tarfile import TarError\n",
    "    try:\n",
    "        from io import BytesIO\n",
    "        with tarfile.open(fileobj=BytesIO(bytes), mode='r') as f:\n",
    "            names = f.getnames()\n",
    "            if names == ['pipeline.yaml']:\n",
    "                tar_info = f.getmember('pipeline.yaml')\n",
    "                if tar_info.isfile():\n",
    "                    return f.extractfile(tar_info).read()\n",
    "                raise Exception('\"pipeline.yaml\" in TAR archive is not a regular file')\n",
    "            raise Exception('Expected TAR archive to contain only a \"pipeline.yaml\"; found %s' % names)\n",
    "    except TarError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_extract_pipeline_zip(bytes):\n",
    "    \"\"\"Attempt to parse `bytes` as a ZIP archive and extract a `pipeline.yaml`\"\"\"\n",
    "    from zipfile import BadZipFile, ZipFile\n",
    "    try:\n",
    "        from io import BytesIO\n",
    "        with ZipFile(BytesIO(bytes), mode='r') as f:\n",
    "            names = f.namelist()\n",
    "            if names == ['pipeline.yaml']:\n",
    "                return f.read('pipeline.yaml')\n",
    "            raise Exception('Expected ZIP archive to contain only a \"pipeline.yaml\"; found %s' % names)\n",
    "    except BadZipFile:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pipeline_func(pipeline):\n",
    "    return \\\n",
    "        hasattr(pipeline, '__call__') and \\\n",
    "        hasattr(pipeline, '_pipeline_name') and \\\n",
    "        hasattr(pipeline, '_pipeline_description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pipeline(pipeline):\n",
    "    \"\"\"Load a pipeline's spec as a dict\n",
    "    \n",
    "    Input pipeline can be:\n",
    "    - a @dsl.pipeline function (in which case it is compiled to YAML which is then parsed)\n",
    "    - a local or remote (\"gs\" and \"https?\" schemes supported) YAML file (or ZIP or TAR archive containing a pipeline.yaml)\n",
    "    \"\"\"\n",
    "    import yaml\n",
    "    if is_pipeline_func(pipeline):\n",
    "        from kfp.compiler import Compiler\n",
    "        compiler = Compiler()\n",
    "        pipeline_yaml = compiler.compile(pipeline, package_path=None)\n",
    "        return yaml.safe_load(pipeline_yaml)\n",
    "    bytes = url_to_bytes(pipeline)\n",
    "    pipeline_yaml = try_extract_pipeline_tar(bytes)\n",
    "    if pipeline_yaml is None:\n",
    "        pipeline_yaml = try_extract_pipeline_zip(bytes)\n",
    "        if pipeline_yaml is None:\n",
    "            pipeline_yaml = bytes\n",
    "    return yaml.safe_load(pipeline_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yaml(path):\n",
    "    \"\"\"Load YAML from a local or remote URL\"\"\"\n",
    "    import yaml\n",
    "    return yaml.safe_load(url_to_bytes(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline-spec accessors\n",
    "Utilities for pulling various fields out of a Kubeflow Pipeline's spec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(pipeline):\n",
    "    if 'metadata' not in pipeline:\n",
    "        raise Exception('No \"metadata\" found in pipeline')\n",
    "    return pipeline['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations(pipeline):\n",
    "    metadata = get_metadata(pipeline)\n",
    "    if 'annotations' not in metadata:\n",
    "        return (\"\", \"\")\n",
    "    annotations = metadata['annotations']\n",
    "    if 'pipelines.kubeflow.org/pipeline_spec' not in annotations:\n",
    "        return (\"\", \"\")\n",
    "    import json\n",
    "    annotations = json.loads(annotations['pipelines.kubeflow.org/pipeline_spec'])\n",
    "    return annotations['name'], annotations['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(pipeline):\n",
    "    metadata = get_metadata(pipeline)\n",
    "\n",
    "    if 'generateName' not in metadata:\n",
    "        raise Exception('No \"generateName\" found in pipeline metadata')\n",
    "\n",
    "    name = metadata['generateName']\n",
    "    if name[-1] == '-':\n",
    "        name = name[:-1]\n",
    "\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_description(pipeline):\n",
    "    (_, description) = get_annotations(pipeline)\n",
    "    return description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ScheduledWorkflow` builders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load template `ScheduledWorkflow`+KFP YAML\n",
    "To construct `ScheduledWorkflow`s below, we start with this template and fill in a few missing fields (pipeline spec, name, and description, as well as any other parameter overrides the user provides)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "SWF_TEMPLATE_URL = 'https://raw.githubusercontent.com/ryan-williams/pipelines/swf/backend/src/crd/samples/scheduledworkflow/kfp.yaml'\n",
    "SWF_TEMPLATE = load_yaml(SWF_TEMPLATE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{python} -m pip install -q pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate `ScheduledWorkflow`s for running Kubeflow Pipelines\n",
    "`make_swf_kfp` generates the spec for a `ScheduledWorkflow` resource that will run a given KFP on a desired schedule.\n",
    "\n",
    "#### Parameters\n",
    "| Type | Name | Description |\n",
    "| :-:| :-:| :---|\n",
    "| `pipeline` | `str` | `dsl.pipeline` function or path to a file (or ZIP or TAR archive) containing the pipeline's YAML specification (paths can be to local files or `gs`- or `http`-schemed URLs). |\n",
    "| `name` | `str` | Name of the ScheduledWorkflow resource to create; constructed from the underlying pipeline's name by default. |\n",
    "| `description` | `str` | Description of the ScheduledWorkflow resource to create; constructed from the underlying pipeline's description by default. |\n",
    "| `cron` | `str` | Crontab-formatted string specifying the schedule the pipeline should be run on; if neither `cron` nor `intervalSecond` is provided, the `DEFAULT_CRON_SCHEDULE` above is used. At most one of `cron` and `intervalSecond` should be provided. |\n",
    "| `intervalSecond` | `int` | Interval at which to trigger runs of the provided pipeline. At most one of `cron` and `intervalSecond` should be provided. |\n",
    "| `start` | `datetime` \\| `str` | If provided, begin scheduling pipelines at this date+time (UTC is assumed if timezone is not made explicit) |\n",
    "| `end` | `datetime` \\| `str` | If provided, stop scheduling pipelines at this date+time (UTC is assumed if timezone is not made explicit) |\n",
    "| `maxHistory` | `int` | Maximum number of pipeline runs' histories to store (default: 10) |\n",
    "| `maxConcurrency` | `int` | Maximum number of concurrent runs of the pipeline (default: 10) |\n",
    "| `enabled` | `bool` | Whether the generated ScheduledWorkflow should be enabled when it is created (default: True) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "class KfpSwf(object):\n",
    "\n",
    "    DEFAULT_CRON_SCHEDULE = \"1 * * * * *\"\n",
    "    ARGS = dict(\n",
    "        group=\"kubeflow.org\",\n",
    "        version=\"v1beta1\",\n",
    "        namespace=\"default\",\n",
    "        plural=\"scheduledworkflows\",\n",
    "    )    \n",
    "    \n",
    "    def __init__(self, pipeline, **kwargs):\n",
    "        self._init_pipeline(pipeline)\n",
    "        self.kwargs = kwargs\n",
    "        self._build()\n",
    "        from kubernetes import config\n",
    "        from kubernetes.client import CustomObjectsApi\n",
    "        config.load_kube_config()\n",
    "        self.api = CustomObjectsApi()\n",
    "        self.name = None\n",
    "        self.description = None\n",
    "    \n",
    "    def _init_pipeline(self, pipeline):\n",
    "        if pipeline is None:\n",
    "            return\n",
    "        self.pipeline = pipeline\n",
    "        self.parsed_pipeline = load_pipeline(pipeline)\n",
    "\n",
    "    def create(self):\n",
    "        obj = api.create_namespaced_custom_object(body=self.body, **self.ARGS)\n",
    "        self.name = obj['metadata']['name']\n",
    "        self.description = obj\n",
    "        return self.description\n",
    "    \n",
    "    def describe(self):\n",
    "        self.description = api.get_namespaced_custom_object(name=self.name, **self.ARGS)\n",
    "        return self.description\n",
    "    \n",
    "    def history(self, key=None):\n",
    "        history = self.describe()['status']['workflowHistory']\n",
    "\n",
    "        if key is None:\n",
    "            return history\n",
    "\n",
    "        if key in history:\n",
    "            runs = pd.DataFrame(self.history()[key])\n",
    "            for k in [ 'started', 'scheduled', 'created', 'finished' ]:\n",
    "                key = k + 'At'\n",
    "                runs[key] = pd.to_datetime(runs[key])\n",
    "\n",
    "            return runs\n",
    "    \n",
    "    def completed(self):\n",
    "        return self.history(key='completed')\n",
    "\n",
    "    def active(self):\n",
    "        return self.history(key='active')\n",
    "\n",
    "    def patch(self, **kwargs):\n",
    "        name = self.name\n",
    "        if name is None:\n",
    "            raise Exception('Must call create() before you can patch()')\n",
    "\n",
    "        new_pipeline = kwargs.pop('pipeline', None)\n",
    "        self._init_pipeline(new_pipeline)\n",
    "\n",
    "        new_args = deepcopy(self.kwargs)\n",
    "        new_args.update(kwargs)\n",
    "        self.kwargs = new_args\n",
    "        \n",
    "        self._build()\n",
    "        \n",
    "        return api.patch_namespaced_custom_object(name=name, body=self.body, **self.ARGS)\n",
    "\n",
    "    def delete(self):\n",
    "        name = self.name\n",
    "        if name is None:\n",
    "            raise Exception('Must call create() before you can patch()')\n",
    "\n",
    "        from kubernetes.client import V1DeleteOptions\n",
    "        return api.delete_namespaced_custom_object(name=name, body=V1DeleteOptions(), **self.ARGS)\n",
    "    \n",
    "    def _build(self):\n",
    "        self.body = self.build(self.parsed_pipeline, **self.kwargs)\n",
    "    \n",
    "    @classmethod\n",
    "    def build(\n",
    "        self, \n",
    "        pipeline,\n",
    "        name=None, description=None, \n",
    "        cron=None, intervalSecond=None, \n",
    "        start=None, end=None,\n",
    "        maxHistory=10, maxConcurrency=10, enabled=True\n",
    "    ):\n",
    "        \"\"\"Create a ScheduledWorkflow resource that will run a given pipeline on a desired schedule.\n",
    "\n",
    "        :param str pipeline @dsl.pipeline function or path to a file (or ZIP or TAR archive) containing the pipeline's YAML specification (paths can be to local files or \"gs\"- or \"http\"-schemed URLs).\n",
    "        :param str name Name of the ScheduledWorkflow resource to create; constructed from the underlying pipeline's name by default.\n",
    "        :param str description Description of the ScheduledWorkflow resource to create; constructed from the underlying pipeline's description by default.\n",
    "        :param str cron Crontab-formatted string specifying the schedule the pipeline should be run on; if neither `cron` nor `intervalSecond` is provided, the `DEFAULT_CRON_SCHEDULE` above is used. At most one of `cron` and `intervalSecond` should be provided.\n",
    "        :param int intervalSecond Interval at which to trigger runs of the provided pipeline. At most one of `cron` and `intervalSecond` should be provided.\n",
    "        :param datetime|str start If provided, begin scheduling pipelines at this date+time (UTC is assumed if timezone is not made explicit)\n",
    "        :param datetime|str end If provided, stop scheduling pipelines at this date+time (UTC is assumed if timezone is not made explicit)\n",
    "        :param int maxHistory Maximum number of pipeline runs' histories to store (default: 10)\n",
    "        :param int maxConcurrency Maximum number of concurrent runs of the pipeline (default: 10)\n",
    "        :param bool enabled Whether the generated ScheduledWorkflow should be enabled when it is created (default: True)    \n",
    "        \"\"\"\n",
    "        swf = deepcopy(SWF_TEMPLATE)\n",
    "\n",
    "        spec = swf['spec']\n",
    "\n",
    "        if name is None:\n",
    "            name = get_name(pipeline)\n",
    "            \n",
    "        if description is None:\n",
    "            description = get_description(pipeline)\n",
    "\n",
    "        if (cron is not None) and (intervalSecond is not None):\n",
    "            raise Exception('At most one of {\"cron\",\"interval\"} should be provided; received cron %s, interval %s' % (cron, intervalSecond))\n",
    "\n",
    "        if (cron is None) and (intervalSecond is None):\n",
    "            cron = DEFAULT_CRON_SCHEDULE\n",
    "\n",
    "        def set_date(key, dt):\n",
    "            from dateutil.parser import parse\n",
    "            if dt is not None:\n",
    "                if isinstance(dt, str):\n",
    "                    dt = parse(dt)\n",
    "                if dt.tzinfo is None:\n",
    "                    from pytz import utc\n",
    "                    dt = utc.localize(dt)\n",
    "                schedule[key] = dt\n",
    "\n",
    "        schedule = {}\n",
    "        set_date('startTime', start)\n",
    "        set_date('endTime', end)\n",
    "\n",
    "        msg_parts = []  # accumulate pieces of scheduling metadata here (for inclusion in the ScheduledWorkflow's description)\n",
    "        trigger = {}\n",
    "        if cron is not None:\n",
    "            schedule['cron'] = cron\n",
    "            msg_parts.append('cron: %s' % cron)\n",
    "            trigger['cronSchedule'] = schedule\n",
    "        else:\n",
    "            schedule['intervalSecond'] = intervalSecond\n",
    "            msg_parts.append('interval: %ds' % intervalSecond)\n",
    "            trigger['periodicSchedule'] = schedule\n",
    "\n",
    "        spec['enabled'] = enabled\n",
    "        spec['maxHistory'] = maxHistory\n",
    "        spec['maxConcurrency'] = maxConcurrency\n",
    "        spec['trigger'] = trigger\n",
    "\n",
    "        if start is not None:\n",
    "            msg_parts.append('start: %s' % str(start))\n",
    "        if end is not None:\n",
    "            msg_parts.append('end: %s' % str(end))\n",
    "\n",
    "        spec['description'] = 'ScheduledWorkflow (%s): %s' % (', '.join(msg_parts), description)\n",
    "\n",
    "        # Name for the SWF resource\n",
    "        swf_name = 'swf-%s' % name\n",
    "        spec['name'] = swf_name\n",
    "        metadata = swf['metadata']\n",
    "        metadata['name'] = swf_name\n",
    "\n",
    "        workflow = spec['workflow']\n",
    "\n",
    "        # Inline pipeline YAML into SWF YAML as a parameter to each run of the SWF, \n",
    "        # which will parse the pipeline and submit it\n",
    "        parameters = workflow['parameters']\n",
    "        import yaml\n",
    "        parameters[1]['value'] = yaml.dump(pipeline)\n",
    "\n",
    "        workflow_spec = workflow['spec']\n",
    "        templates = workflow_spec['templates']\n",
    "        template = templates[0]\n",
    "        container = template['container']\n",
    "        args = container['args']\n",
    "\n",
    "        # populate \"name\" argument in template\n",
    "        assert args[-2:] == [ '--name', '' ], \"Unexpected final SWF args: %s\" % args[-2:]\n",
    "        args[-1] = name\n",
    "\n",
    "        return swf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `import`ing remote modules\n",
    "ContextManager used for downloading (or moving) a file to a temporary location and importing from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "class Import(object):\n",
    "    \"\"\"ContextManager used for downloading (or moving) a file to a temporary location and importing from it\"\"\"\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.tmpdir = None\n",
    "    \n",
    "    def __enter__(self):\n",
    "        from urllib.parse import urlparse\n",
    "        url = self.url\n",
    "        parsed = urlparse(url)\n",
    "        scheme = parsed.scheme\n",
    "\n",
    "        from tempfile import TemporaryDirectory\n",
    "        self.tmpdir = TemporaryDirectory()\n",
    "\n",
    "        from os.path import basename, join\n",
    "        path = parsed.path\n",
    "        name = basename(path)  # Preserve file's basename (for ease of importing from it)\n",
    "        tmpdir = self.tmpdir.name\n",
    "        dest = join(tmpdir, name)  # File to import from will be downloaded here\n",
    "        \n",
    "        if not scheme:\n",
    "            # Local file: copy it to temporary directory (for consistent import-isolation semantics with remote \"import\"s)\n",
    "            with open(url, 'rb') as src, open(dest, 'wb') as dst:\n",
    "                from shutil import copyfileobj\n",
    "                copyfileobj(src, dst)\n",
    "        elif scheme == 'http' or scheme == 'https':\n",
    "            from urllib.request import urlretrieve\n",
    "            urlretrieve(url, dest)\n",
    "        elif scheme == 'gs':\n",
    "            from google.cloud import storage\n",
    "            gcs = storage.Client()\n",
    "            bucket_name = parsed.hostname\n",
    "            bucket = gcs.get_bucket(bucket_name)\n",
    "            key = parsed.path\n",
    "            blob = bucket.blob(key)\n",
    "            blob.download_to_file(dest)\n",
    "        else:\n",
    "            raise Exception(\"Unsure how to handle URL scheme '%s' (%s)\" % (scheme, url))    \n",
    "\n",
    "        # Add temporary directory to \"import\" path\n",
    "        sys.path.append(tmpdir)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        # Close+Delete the temporary directory\n",
    "        self.tmpdir.__exit__(exc_type, exc_val, exc_tb)\n",
    "        tmpdir = self.tmpdir.name\n",
    "        # Remove it from sys.path\n",
    "        sys.path.remove(tmpdir)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Coin flip\" sample\n",
    "- wrap [the \"coin flip\" example from the Kubeflow Pipelines repo](https://github.com/kubeflow/pipelines/blob/0.1.31/samples/core/condition/condition.py) in a `ScheduledWorkflow`\n",
    "- create it, let it run for a few minutes, update (\"patch\") it, and delete it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples\n",
    "- [\"Coin flip\" sample](#coin-flip-sample) (via GitHub)\n",
    "- [\"Coin flip\" sample](#coin.tar.gz) (via Google Cloud Storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `import` pipeline definition from latest GitHub release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_flip_sample_url = 'https://raw.githubusercontent.com/kubeflow/pipelines/%s/samples/core/condition/condition.py' % kfp_version\n",
    "with Import(coin_flip_sample_url):\n",
    "    # The condition.py has been downloaded to a temporary directory and placed on sys.path\n",
    "    from condition import flipcoin_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a `ScheduledWorkflow` wrapping the pipeline\n",
    "Build a `ScheduledWorkflow` spec that runs the \"coin flip\" pipeline every minute, on the minute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "swf = KfpSwf(flipcoin_pipeline, cron=\"0 * * * * *\", start='2019-09-29 00:00', end='2019-09-29 00:10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create, Read, Update, and Delete the `ScheduledWorkflow`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apiVersion': 'kubeflow.org/v1beta1',\n",
       " 'kind': 'ScheduledWorkflow',\n",
       " 'metadata': {'creationTimestamp': '2019-09-30T03:29:48Z',\n",
       "  'generation': 1,\n",
       "  'name': 'swf-conditional-execution-pipeline',\n",
       "  'namespace': 'default',\n",
       "  'resourceVersion': '287261',\n",
       "  'selfLink': '/apis/kubeflow.org/v1beta1/namespaces/default/scheduledworkflows/swf-conditional-execution-pipeline',\n",
       "  'uid': 'c91da570-0a32-4101-885f-21404ea8375f'},\n",
       " 'spec': {'description': 'ScheduledWorkflow (cron: 0 * * * * *, start: 2019-09-29 00:00, end: 2019-09-29 00:10): Shows how to use dsl.Condition().',\n",
       "  'enabled': True,\n",
       "  'maxConcurrency': 10,\n",
       "  'maxHistory': 10,\n",
       "  'name': 'swf-conditional-execution-pipeline',\n",
       "  'trigger': {'cronSchedule': {'cron': '0 * * * * *',\n",
       "    'endTime': '2019-09-29T00:10:00+00:00',\n",
       "    'startTime': '2019-09-29T00:00:00+00:00'}},\n",
       "  'workflow': {'parameters': [{'name': 'datetime',\n",
       "     'value': '[[ScheduledTime.20060102-15:04:05]]'},\n",
       "    {'name': 'pipeline_yaml',\n",
       "     'value': 'apiVersion: argoproj.io/v1alpha1\\nkind: Workflow\\nmetadata:\\n  annotations: {pipelines.kubeflow.org/pipeline_spec: \\'{\"description\": \"Shows how\\n      to use dsl.Condition().\", \"name\": \"Conditional execution pipeline\"}\\'}\\n  generateName: conditional-execution-pipeline-\\nspec:\\n  arguments:\\n    parameters: []\\n  entrypoint: conditional-execution-pipeline\\n  serviceAccountName: pipeline-runner\\n  templates:\\n  - dag:\\n      tasks:\\n      - arguments:\\n          parameters:\\n          - {name: generate-random-number-output, value: \\'{{tasks.generate-random-number.outputs.parameters.generate-random-number-output}}\\'}\\n        dependencies: [generate-random-number]\\n        name: condition-2\\n        template: condition-2\\n        when: \\'{{tasks.generate-random-number.outputs.parameters.generate-random-number-output}}\\n          > 5\\'\\n      - arguments:\\n          parameters:\\n          - {name: generate-random-number-output, value: \\'{{tasks.generate-random-number.outputs.parameters.generate-random-number-output}}\\'}\\n        dependencies: [generate-random-number]\\n        name: condition-3\\n        template: condition-3\\n        when: \\'{{tasks.generate-random-number.outputs.parameters.generate-random-number-output}}\\n          <= 5\\'\\n      - {name: generate-random-number, template: generate-random-number}\\n    name: condition-1\\n  - dag:\\n      tasks:\\n      - arguments:\\n          parameters:\\n          - {name: generate-random-number-output, value: \\'{{inputs.parameters.generate-random-number-output}}\\'}\\n        name: print\\n        template: print\\n    inputs:\\n      parameters:\\n      - {name: generate-random-number-output}\\n    name: condition-2\\n  - dag:\\n      tasks:\\n      - arguments:\\n          parameters:\\n          - {name: generate-random-number-output, value: \\'{{inputs.parameters.generate-random-number-output}}\\'}\\n        name: print-2\\n        template: print-2\\n    inputs:\\n      parameters:\\n      - {name: generate-random-number-output}\\n    name: condition-3\\n  - dag:\\n      tasks:\\n      - arguments:\\n          parameters:\\n          - {name: generate-random-number-2-output, value: \\'{{tasks.generate-random-number-2.outputs.parameters.generate-random-number-2-output}}\\'}\\n        dependencies: [generate-random-number-2]\\n        name: condition-5\\n        template: condition-5\\n        when: \\'{{tasks.generate-random-number-2.outputs.parameters.generate-random-number-2-output}}\\n          > 15\\'\\n      - arguments:\\n          parameters:\\n          - {name: generate-random-number-2-output, value: \\'{{tasks.generate-random-number-2.outputs.parameters.generate-random-number-2-output}}\\'}\\n        dependencies: [generate-random-number-2]\\n        name: condition-6\\n        template: condition-6\\n        when: \\'{{tasks.generate-random-number-2.outputs.parameters.generate-random-number-2-output}}\\n          <= 15\\'\\n      - {name: generate-random-number-2, template: generate-random-number-2}\\n    name: condition-4\\n  - dag:\\n      tasks:\\n      - arguments:\\n          parameters:\\n          - {name: generate-random-number-2-output, value: \\'{{inputs.parameters.generate-random-number-2-output}}\\'}\\n        name: print-3\\n        template: print-3\\n    inputs:\\n      parameters:\\n      - {name: generate-random-number-2-output}\\n    name: condition-5\\n  - dag:\\n      tasks:\\n      - arguments:\\n          parameters:\\n          - {name: generate-random-number-2-output, value: \\'{{inputs.parameters.generate-random-number-2-output}}\\'}\\n        name: print-4\\n        template: print-4\\n    inputs:\\n      parameters:\\n      - {name: generate-random-number-2-output}\\n    name: condition-6\\n  - dag:\\n      tasks:\\n      - dependencies: [flip-coin]\\n        name: condition-1\\n        template: condition-1\\n        when: \\'\"{{tasks.flip-coin.outputs.parameters.flip-coin-output}}\" == \"heads\"\\'\\n      - dependencies: [flip-coin]\\n        name: condition-4\\n        template: condition-4\\n        when: \\'\"{{tasks.flip-coin.outputs.parameters.flip-coin-output}}\" == \"tails\"\\'\\n      - {name: flip-coin, template: flip-coin}\\n    name: conditional-execution-pipeline\\n  - container:\\n      args: [\\'python -c \"import random; result = \\'\\'heads\\'\\' if random.randint(0,1)\\n          == 0 else \\'\\'tails\\'\\'; print(result)\" | tee /tmp/output\\']\\n      command: [sh, -c]\\n      image: python:alpine3.6\\n    name: flip-coin\\n    outputs:\\n      artifacts:\\n      - {name: flip-coin-output, path: /tmp/output}\\n      parameters:\\n      - name: flip-coin-output\\n        valueFrom: {path: /tmp/output}\\n  - container:\\n      args: [\\'python -c \"import random; print(random.randint($0, $1))\" | tee $2\\',\\n        \\'0\\', \\'9\\', /tmp/output]\\n      command: [sh, -c]\\n      image: python:alpine3.6\\n    name: generate-random-number\\n    outputs:\\n      artifacts:\\n      - {name: generate-random-number-output, path: /tmp/output}\\n      parameters:\\n      - name: generate-random-number-output\\n        valueFrom: {path: /tmp/output}\\n  - container:\\n      args: [\\'python -c \"import random; print(random.randint($0, $1))\" | tee $2\\',\\n        \\'10\\', \\'19\\', /tmp/output]\\n      command: [sh, -c]\\n      image: python:alpine3.6\\n    name: generate-random-number-2\\n    outputs:\\n      artifacts:\\n      - {name: generate-random-number-2-output, path: /tmp/output}\\n      parameters:\\n      - name: generate-random-number-2-output\\n        valueFrom: {path: /tmp/output}\\n  - container:\\n      command: [echo, \\'heads and {{inputs.parameters.generate-random-number-output}}\\n          > 5!\\']\\n      image: alpine:3.6\\n    inputs:\\n      parameters:\\n      - {name: generate-random-number-output}\\n    name: print\\n  - container:\\n      command: [echo, \\'heads and {{inputs.parameters.generate-random-number-output}}\\n          <= 5!\\']\\n      image: alpine:3.6\\n    inputs:\\n      parameters:\\n      - {name: generate-random-number-output}\\n    name: print-2\\n  - container:\\n      command: [echo, \\'tails and {{inputs.parameters.generate-random-number-2-output}}\\n          > 15!\\']\\n      image: alpine:3.6\\n    inputs:\\n      parameters:\\n      - {name: generate-random-number-2-output}\\n    name: print-3\\n  - container:\\n      command: [echo, \\'tails and {{inputs.parameters.generate-random-number-2-output}}\\n          <= 15!\\']\\n      image: alpine:3.6\\n    inputs:\\n      parameters:\\n      - {name: generate-random-number-2-output}\\n    name: print-4\\n'}],\n",
       "   'spec': {'arguments': {'parameters': [{'name': 'datetime'},\n",
       "      {'name': 'pipeline_yaml'}]},\n",
       "    'entrypoint': 'kfp',\n",
       "    'templates': [{'container': {'args': ['--datetime',\n",
       "        '{{inputs.parameters.datetime}}',\n",
       "        '--pipeline_yaml',\n",
       "        '{{inputs.parameters.pipeline_yaml}}',\n",
       "        '--name',\n",
       "        'conditional-execution-pipeline'],\n",
       "       'command': ['python', 'swf_kfp_runner.py'],\n",
       "       'image': 'swf-kfp:3'},\n",
       "      'inputs': {'parameters': [{'name': 'datetime'},\n",
       "        {'name': 'pipeline_yaml'}]},\n",
       "      'name': 'kfp'}]}}}}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swf.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>createdAt</th>\n",
       "      <th>finishedAt</th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>namespace</th>\n",
       "      <th>phase</th>\n",
       "      <th>scheduledAt</th>\n",
       "      <th>selfLink</th>\n",
       "      <th>startedAt</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-09-30 03:43:57+00:00</td>\n",
       "      <td>2019-09-30 03:44:33+00:00</td>\n",
       "      <td>34</td>\n",
       "      <td>swf-conditional-execution-pipeline-34-1284205302</td>\n",
       "      <td>default</td>\n",
       "      <td>Succeeded</td>\n",
       "      <td>2019-09-30 00:00:00+00:00</td>\n",
       "      <td>/apis/argoproj.io/v1alpha1/namespaces/default/...</td>\n",
       "      <td>2019-09-30 03:43:57+00:00</td>\n",
       "      <td>557af601-0af5-4537-b29f-b4b856114883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-09-30 03:43:47+00:00</td>\n",
       "      <td>2019-09-30 03:44:22+00:00</td>\n",
       "      <td>33</td>\n",
       "      <td>swf-conditional-execution-pipeline-33-1334538159</td>\n",
       "      <td>default</td>\n",
       "      <td>Succeeded</td>\n",
       "      <td>2019-09-29 23:00:00+00:00</td>\n",
       "      <td>/apis/argoproj.io/v1alpha1/namespaces/default/...</td>\n",
       "      <td>2019-09-30 03:43:47+00:00</td>\n",
       "      <td>cb461448-62cb-47ef-942f-c80d640306b2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-09-30 03:43:37+00:00</td>\n",
       "      <td>2019-09-30 03:44:11+00:00</td>\n",
       "      <td>32</td>\n",
       "      <td>swf-conditional-execution-pipeline-32-1317760540</td>\n",
       "      <td>default</td>\n",
       "      <td>Succeeded</td>\n",
       "      <td>2019-09-29 22:00:00+00:00</td>\n",
       "      <td>/apis/argoproj.io/v1alpha1/namespaces/default/...</td>\n",
       "      <td>2019-09-30 03:43:37+00:00</td>\n",
       "      <td>54e27532-319d-499e-b4f6-efdc44e609ad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-09-30 03:43:27+00:00</td>\n",
       "      <td>2019-09-30 03:44:03+00:00</td>\n",
       "      <td>31</td>\n",
       "      <td>swf-conditional-execution-pipeline-31-1368093397</td>\n",
       "      <td>default</td>\n",
       "      <td>Succeeded</td>\n",
       "      <td>2019-09-29 21:00:00+00:00</td>\n",
       "      <td>/apis/argoproj.io/v1alpha1/namespaces/default/...</td>\n",
       "      <td>2019-09-30 03:43:27+00:00</td>\n",
       "      <td>874ee017-0387-4608-acd8-e0f6a15b2514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-09-30 03:43:17+00:00</td>\n",
       "      <td>2019-09-30 03:43:53+00:00</td>\n",
       "      <td>30</td>\n",
       "      <td>swf-conditional-execution-pipeline-30-1351315778</td>\n",
       "      <td>default</td>\n",
       "      <td>Succeeded</td>\n",
       "      <td>2019-09-29 20:00:00+00:00</td>\n",
       "      <td>/apis/argoproj.io/v1alpha1/namespaces/default/...</td>\n",
       "      <td>2019-09-30 03:43:17+00:00</td>\n",
       "      <td>e011998d-0c99-4a5b-bf8d-e1025893ab10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-09-30 03:43:07+00:00</td>\n",
       "      <td>2019-09-30 03:43:42+00:00</td>\n",
       "      <td>29</td>\n",
       "      <td>swf-conditional-execution-pipeline-29-1301130016</td>\n",
       "      <td>default</td>\n",
       "      <td>Succeeded</td>\n",
       "      <td>2019-09-29 19:00:00+00:00</td>\n",
       "      <td>/apis/argoproj.io/v1alpha1/namespaces/default/...</td>\n",
       "      <td>2019-09-30 03:43:07+00:00</td>\n",
       "      <td>81318487-842a-4241-858b-49ab0755037d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2019-09-30 03:42:57+00:00</td>\n",
       "      <td>2019-09-30 03:43:32+00:00</td>\n",
       "      <td>28</td>\n",
       "      <td>swf-conditional-execution-pipeline-28-1317907635</td>\n",
       "      <td>default</td>\n",
       "      <td>Succeeded</td>\n",
       "      <td>2019-09-29 18:00:00+00:00</td>\n",
       "      <td>/apis/argoproj.io/v1alpha1/namespaces/default/...</td>\n",
       "      <td>2019-09-30 03:42:57+00:00</td>\n",
       "      <td>17c684b2-fe3f-4e02-9d91-798c897e009a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2019-09-30 03:42:47+00:00</td>\n",
       "      <td>2019-09-30 03:43:21+00:00</td>\n",
       "      <td>27</td>\n",
       "      <td>swf-conditional-execution-pipeline-27-1536016682</td>\n",
       "      <td>default</td>\n",
       "      <td>Succeeded</td>\n",
       "      <td>2019-09-29 17:00:00+00:00</td>\n",
       "      <td>/apis/argoproj.io/v1alpha1/namespaces/default/...</td>\n",
       "      <td>2019-09-30 03:42:47+00:00</td>\n",
       "      <td>00398be3-8efc-4933-8abf-7255e3e3411a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2019-09-30 03:42:37+00:00</td>\n",
       "      <td>2019-09-30 03:43:12+00:00</td>\n",
       "      <td>26</td>\n",
       "      <td>swf-conditional-execution-pipeline-26-1552794301</td>\n",
       "      <td>default</td>\n",
       "      <td>Succeeded</td>\n",
       "      <td>2019-09-29 16:00:00+00:00</td>\n",
       "      <td>/apis/argoproj.io/v1alpha1/namespaces/default/...</td>\n",
       "      <td>2019-09-30 03:42:37+00:00</td>\n",
       "      <td>f073bd7b-4610-4881-9329-1b58fa731173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2019-09-30 03:42:27+00:00</td>\n",
       "      <td>2019-09-30 03:43:01+00:00</td>\n",
       "      <td>25</td>\n",
       "      <td>swf-conditional-execution-pipeline-25-1502461444</td>\n",
       "      <td>default</td>\n",
       "      <td>Succeeded</td>\n",
       "      <td>2019-09-29 15:00:00+00:00</td>\n",
       "      <td>/apis/argoproj.io/v1alpha1/namespaces/default/...</td>\n",
       "      <td>2019-09-30 03:42:27+00:00</td>\n",
       "      <td>d92d39c4-8cc9-4a19-b859-56dffaa97d64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  createdAt                finishedAt  index  \\\n",
       "0 2019-09-30 03:43:57+00:00 2019-09-30 03:44:33+00:00     34   \n",
       "1 2019-09-30 03:43:47+00:00 2019-09-30 03:44:22+00:00     33   \n",
       "2 2019-09-30 03:43:37+00:00 2019-09-30 03:44:11+00:00     32   \n",
       "3 2019-09-30 03:43:27+00:00 2019-09-30 03:44:03+00:00     31   \n",
       "4 2019-09-30 03:43:17+00:00 2019-09-30 03:43:53+00:00     30   \n",
       "5 2019-09-30 03:43:07+00:00 2019-09-30 03:43:42+00:00     29   \n",
       "6 2019-09-30 03:42:57+00:00 2019-09-30 03:43:32+00:00     28   \n",
       "7 2019-09-30 03:42:47+00:00 2019-09-30 03:43:21+00:00     27   \n",
       "8 2019-09-30 03:42:37+00:00 2019-09-30 03:43:12+00:00     26   \n",
       "9 2019-09-30 03:42:27+00:00 2019-09-30 03:43:01+00:00     25   \n",
       "\n",
       "                                               name namespace      phase  \\\n",
       "0  swf-conditional-execution-pipeline-34-1284205302   default  Succeeded   \n",
       "1  swf-conditional-execution-pipeline-33-1334538159   default  Succeeded   \n",
       "2  swf-conditional-execution-pipeline-32-1317760540   default  Succeeded   \n",
       "3  swf-conditional-execution-pipeline-31-1368093397   default  Succeeded   \n",
       "4  swf-conditional-execution-pipeline-30-1351315778   default  Succeeded   \n",
       "5  swf-conditional-execution-pipeline-29-1301130016   default  Succeeded   \n",
       "6  swf-conditional-execution-pipeline-28-1317907635   default  Succeeded   \n",
       "7  swf-conditional-execution-pipeline-27-1536016682   default  Succeeded   \n",
       "8  swf-conditional-execution-pipeline-26-1552794301   default  Succeeded   \n",
       "9  swf-conditional-execution-pipeline-25-1502461444   default  Succeeded   \n",
       "\n",
       "                scheduledAt  \\\n",
       "0 2019-09-30 00:00:00+00:00   \n",
       "1 2019-09-29 23:00:00+00:00   \n",
       "2 2019-09-29 22:00:00+00:00   \n",
       "3 2019-09-29 21:00:00+00:00   \n",
       "4 2019-09-29 20:00:00+00:00   \n",
       "5 2019-09-29 19:00:00+00:00   \n",
       "6 2019-09-29 18:00:00+00:00   \n",
       "7 2019-09-29 17:00:00+00:00   \n",
       "8 2019-09-29 16:00:00+00:00   \n",
       "9 2019-09-29 15:00:00+00:00   \n",
       "\n",
       "                                            selfLink  \\\n",
       "0  /apis/argoproj.io/v1alpha1/namespaces/default/...   \n",
       "1  /apis/argoproj.io/v1alpha1/namespaces/default/...   \n",
       "2  /apis/argoproj.io/v1alpha1/namespaces/default/...   \n",
       "3  /apis/argoproj.io/v1alpha1/namespaces/default/...   \n",
       "4  /apis/argoproj.io/v1alpha1/namespaces/default/...   \n",
       "5  /apis/argoproj.io/v1alpha1/namespaces/default/...   \n",
       "6  /apis/argoproj.io/v1alpha1/namespaces/default/...   \n",
       "7  /apis/argoproj.io/v1alpha1/namespaces/default/...   \n",
       "8  /apis/argoproj.io/v1alpha1/namespaces/default/...   \n",
       "9  /apis/argoproj.io/v1alpha1/namespaces/default/...   \n",
       "\n",
       "                  startedAt                                   uid  \n",
       "0 2019-09-30 03:43:57+00:00  557af601-0af5-4537-b29f-b4b856114883  \n",
       "1 2019-09-30 03:43:47+00:00  cb461448-62cb-47ef-942f-c80d640306b2  \n",
       "2 2019-09-30 03:43:37+00:00  54e27532-319d-499e-b4f6-efdc44e609ad  \n",
       "3 2019-09-30 03:43:27+00:00  874ee017-0387-4608-acd8-e0f6a15b2514  \n",
       "4 2019-09-30 03:43:17+00:00  e011998d-0c99-4a5b-bf8d-e1025893ab10  \n",
       "5 2019-09-30 03:43:07+00:00  81318487-842a-4241-858b-49ab0755037d  \n",
       "6 2019-09-30 03:42:57+00:00  17c684b2-fe3f-4e02-9d91-798c897e009a  \n",
       "7 2019-09-30 03:42:47+00:00  00398be3-8efc-4933-8abf-7255e3e3411a  \n",
       "8 2019-09-30 03:42:37+00:00  f073bd7b-4610-4881-9329-1b58fa731173  \n",
       "9 2019-09-30 03:42:27+00:00  d92d39c4-8cc9-4a19-b859-56dffaa97d64  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swf.completed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update (\"patch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apiVersion': 'kubeflow.org/v1beta1',\n",
       " 'kind': 'ScheduledWorkflow',\n",
       " 'metadata': {'creationTimestamp': '2019-09-30T03:29:48Z',\n",
       "  'generation': 46,\n",
       "  'labels': {'scheduledworkflows.kubeflow.org/enabled': 'true',\n",
       "   'scheduledworkflows.kubeflow.org/status': 'Enabled'},\n",
       "  'name': 'swf-conditional-execution-pipeline',\n",
       "  'namespace': 'default',\n",
       "  'resourceVersion': '289273',\n",
       "  'selfLink': '/apis/kubeflow.org/v1beta1/namespaces/default/scheduledworkflows/swf-conditional-execution-pipeline',\n",
       "  'uid': 'c91da570-0a32-4101-885f-21404ea8375f'},\n",
       " 'spec': {'description': 'ScheduledWorkflow (cron: 0 0 * * * *, start: 2019-09-29, end: 2019-09-30): Shows how to use dsl.Condition().',\n",
       "  'enabled': True,\n",
       "  'maxConcurrency': 10,\n",
       "  'maxHistory': 10,\n",
       "  'name': 'swf-conditional-execution-pipeline',\n",
       "  'trigger': {'cronSchedule': {'cron': '0 0 * * * *',\n",
       "    'endTime': '2019-09-30T00:00:00+00:00',\n",
       "    'startTime': '2019-09-29T00:00:00+00:00'}},\n",
       "  'workflow': {'parameters': [{'name': 'datetime',\n",
       "     'value': '[[ScheduledTime.20060102-15:04:05]]'},\n",
       "    {'name': 'pipeline_yaml',\n",
       "     'value': 'apiVersion: argoproj.io/v1alpha1\\nkind: Workflow\\nmetadata:\\n  annotations: {pipelines.kubeflow.org/pipeline_spec: \\'{\"description\": \"Shows how\\n      to use dsl.Condition().\", \"name\": \"Conditional execution pipeline\"}\\'}\\n  generateName: conditional-execution-pipeline-\\nspec:\\n  arguments:\\n    parameters: []\\n  entrypoint: conditional-execution-pipeline\\n  serviceAccountName: pipeline-runner\\n  templates:\\n  - dag:\\n      tasks:\\n      - arguments:\\n          parameters:\\n          - {name: generate-random-number-output, value: \\'{{tasks.generate-random-number.outputs.parameters.generate-random-number-output}}\\'}\\n        dependencies: [generate-random-number]\\n        name: condition-2\\n        template: condition-2\\n        when: \\'{{tasks.generate-random-number.outputs.parameters.generate-random-number-output}}\\n          > 5\\'\\n      - arguments:\\n          parameters:\\n          - {name: generate-random-number-output, value: \\'{{tasks.generate-random-number.outputs.parameters.generate-random-number-output}}\\'}\\n        dependencies: [generate-random-number]\\n        name: condition-3\\n        template: condition-3\\n        when: \\'{{tasks.generate-random-number.outputs.parameters.generate-random-number-output}}\\n          <= 5\\'\\n      - {name: generate-random-number, template: generate-random-number}\\n    name: condition-1\\n  - dag:\\n      tasks:\\n      - arguments:\\n          parameters:\\n          - {name: generate-random-number-output, value: \\'{{inputs.parameters.generate-random-number-output}}\\'}\\n        name: print\\n        template: print\\n    inputs:\\n      parameters:\\n      - {name: generate-random-number-output}\\n    name: condition-2\\n  - dag:\\n      tasks:\\n      - arguments:\\n          parameters:\\n          - {name: generate-random-number-output, value: \\'{{inputs.parameters.generate-random-number-output}}\\'}\\n        name: print-2\\n        template: print-2\\n    inputs:\\n      parameters:\\n      - {name: generate-random-number-output}\\n    name: condition-3\\n  - dag:\\n      tasks:\\n      - arguments:\\n          parameters:\\n          - {name: generate-random-number-2-output, value: \\'{{tasks.generate-random-number-2.outputs.parameters.generate-random-number-2-output}}\\'}\\n        dependencies: [generate-random-number-2]\\n        name: condition-5\\n        template: condition-5\\n        when: \\'{{tasks.generate-random-number-2.outputs.parameters.generate-random-number-2-output}}\\n          > 15\\'\\n      - arguments:\\n          parameters:\\n          - {name: generate-random-number-2-output, value: \\'{{tasks.generate-random-number-2.outputs.parameters.generate-random-number-2-output}}\\'}\\n        dependencies: [generate-random-number-2]\\n        name: condition-6\\n        template: condition-6\\n        when: \\'{{tasks.generate-random-number-2.outputs.parameters.generate-random-number-2-output}}\\n          <= 15\\'\\n      - {name: generate-random-number-2, template: generate-random-number-2}\\n    name: condition-4\\n  - dag:\\n      tasks:\\n      - arguments:\\n          parameters:\\n          - {name: generate-random-number-2-output, value: \\'{{inputs.parameters.generate-random-number-2-output}}\\'}\\n        name: print-3\\n        template: print-3\\n    inputs:\\n      parameters:\\n      - {name: generate-random-number-2-output}\\n    name: condition-5\\n  - dag:\\n      tasks:\\n      - arguments:\\n          parameters:\\n          - {name: generate-random-number-2-output, value: \\'{{inputs.parameters.generate-random-number-2-output}}\\'}\\n        name: print-4\\n        template: print-4\\n    inputs:\\n      parameters:\\n      - {name: generate-random-number-2-output}\\n    name: condition-6\\n  - dag:\\n      tasks:\\n      - dependencies: [flip-coin]\\n        name: condition-1\\n        template: condition-1\\n        when: \\'\"{{tasks.flip-coin.outputs.parameters.flip-coin-output}}\" == \"heads\"\\'\\n      - dependencies: [flip-coin]\\n        name: condition-4\\n        template: condition-4\\n        when: \\'\"{{tasks.flip-coin.outputs.parameters.flip-coin-output}}\" == \"tails\"\\'\\n      - {name: flip-coin, template: flip-coin}\\n    name: conditional-execution-pipeline\\n  - container:\\n      args: [\\'python -c \"import random; result = \\'\\'heads\\'\\' if random.randint(0,1)\\n          == 0 else \\'\\'tails\\'\\'; print(result)\" | tee /tmp/output\\']\\n      command: [sh, -c]\\n      image: python:alpine3.6\\n    name: flip-coin\\n    outputs:\\n      artifacts:\\n      - {name: flip-coin-output, path: /tmp/output}\\n      parameters:\\n      - name: flip-coin-output\\n        valueFrom: {path: /tmp/output}\\n  - container:\\n      args: [\\'python -c \"import random; print(random.randint($0, $1))\" | tee $2\\',\\n        \\'0\\', \\'9\\', /tmp/output]\\n      command: [sh, -c]\\n      image: python:alpine3.6\\n    name: generate-random-number\\n    outputs:\\n      artifacts:\\n      - {name: generate-random-number-output, path: /tmp/output}\\n      parameters:\\n      - name: generate-random-number-output\\n        valueFrom: {path: /tmp/output}\\n  - container:\\n      args: [\\'python -c \"import random; print(random.randint($0, $1))\" | tee $2\\',\\n        \\'10\\', \\'19\\', /tmp/output]\\n      command: [sh, -c]\\n      image: python:alpine3.6\\n    name: generate-random-number-2\\n    outputs:\\n      artifacts:\\n      - {name: generate-random-number-2-output, path: /tmp/output}\\n      parameters:\\n      - name: generate-random-number-2-output\\n        valueFrom: {path: /tmp/output}\\n  - container:\\n      command: [echo, \\'heads and {{inputs.parameters.generate-random-number-output}}\\n          > 5!\\']\\n      image: alpine:3.6\\n    inputs:\\n      parameters:\\n      - {name: generate-random-number-output}\\n    name: print\\n  - container:\\n      command: [echo, \\'heads and {{inputs.parameters.generate-random-number-output}}\\n          <= 5!\\']\\n      image: alpine:3.6\\n    inputs:\\n      parameters:\\n      - {name: generate-random-number-output}\\n    name: print-2\\n  - container:\\n      command: [echo, \\'tails and {{inputs.parameters.generate-random-number-2-output}}\\n          > 15!\\']\\n      image: alpine:3.6\\n    inputs:\\n      parameters:\\n      - {name: generate-random-number-2-output}\\n    name: print-3\\n  - container:\\n      command: [echo, \\'tails and {{inputs.parameters.generate-random-number-2-output}}\\n          <= 15!\\']\\n      image: alpine:3.6\\n    inputs:\\n      parameters:\\n      - {name: generate-random-number-2-output}\\n    name: print-4\\n'}],\n",
       "   'spec': {'arguments': {'parameters': [{'name': 'datetime'},\n",
       "      {'name': 'pipeline_yaml'}]},\n",
       "    'entrypoint': 'kfp',\n",
       "    'templates': [{'container': {'args': ['--datetime',\n",
       "        '{{inputs.parameters.datetime}}',\n",
       "        '--pipeline_yaml',\n",
       "        '{{inputs.parameters.pipeline_yaml}}',\n",
       "        '--name',\n",
       "        'conditional-execution-pipeline'],\n",
       "       'command': ['python', 'swf_kfp_runner.py'],\n",
       "       'image': 'swf-kfp:3'},\n",
       "      'inputs': {'parameters': [{'name': 'datetime'},\n",
       "        {'name': 'pipeline_yaml'}]},\n",
       "      'name': 'kfp'}]}}},\n",
       " 'status': {'conditions': [{'lastHeartbeatTime': '2019-09-30T03:39:48Z',\n",
       "    'lastTransitionTime': '2019-09-30T03:39:48Z',\n",
       "    'message': 'The schedule is enabled.',\n",
       "    'reason': 'Enabled',\n",
       "    'status': 'True',\n",
       "    'type': 'Enabled'}],\n",
       "  'trigger': {'lastTriggeredTime': '2019-09-29T00:10:00Z',\n",
       "   'lastWorkflowIndex': 10},\n",
       "  'workflowHistory': {'completed': [{'createdAt': '2019-09-30T03:31:28Z',\n",
       "     'finishedAt': '2019-09-30T03:32:02Z',\n",
       "     'index': 10,\n",
       "     'name': 'swf-conditional-execution-pipeline-10-3297122224',\n",
       "     'namespace': 'default',\n",
       "     'phase': 'Succeeded',\n",
       "     'scheduledAt': '2019-09-29T00:10:00Z',\n",
       "     'selfLink': '/apis/argoproj.io/v1alpha1/namespaces/default/workflows/swf-conditional-execution-pipeline-10-3297122224',\n",
       "     'startedAt': '2019-09-30T03:31:28Z',\n",
       "     'uid': '66bfe3a1-9990-4ef0-8660-b02935d35c6b'},\n",
       "    {'createdAt': '2019-09-30T03:31:18Z',\n",
       "     'finishedAt': '2019-09-30T03:31:53Z',\n",
       "     'index': 9,\n",
       "     'name': 'swf-conditional-execution-pipeline-9-2193302584',\n",
       "     'namespace': 'default',\n",
       "     'phase': 'Succeeded',\n",
       "     'scheduledAt': '2019-09-29T00:09:00Z',\n",
       "     'selfLink': '/apis/argoproj.io/v1alpha1/namespaces/default/workflows/swf-conditional-execution-pipeline-9-2193302584',\n",
       "     'startedAt': '2019-09-30T03:31:18Z',\n",
       "     'uid': '7d11124d-22b6-495b-b38a-a49fa478b23b'},\n",
       "    {'createdAt': '2019-09-30T03:31:08Z',\n",
       "     'finishedAt': '2019-09-30T03:31:42Z',\n",
       "     'index': 8,\n",
       "     'name': 'swf-conditional-execution-pipeline-8-2210080203',\n",
       "     'namespace': 'default',\n",
       "     'phase': 'Succeeded',\n",
       "     'scheduledAt': '2019-09-29T00:08:00Z',\n",
       "     'selfLink': '/apis/argoproj.io/v1alpha1/namespaces/default/workflows/swf-conditional-execution-pipeline-8-2210080203',\n",
       "     'startedAt': '2019-09-30T03:31:08Z',\n",
       "     'uid': '9c21ccbd-d038-469e-b863-50c8fc803148'},\n",
       "    {'createdAt': '2019-09-30T03:30:58Z',\n",
       "     'finishedAt': '2019-09-30T03:31:31Z',\n",
       "     'index': 7,\n",
       "     'name': 'swf-conditional-execution-pipeline-7-2159747346',\n",
       "     'namespace': 'default',\n",
       "     'phase': 'Succeeded',\n",
       "     'scheduledAt': '2019-09-29T00:07:00Z',\n",
       "     'selfLink': '/apis/argoproj.io/v1alpha1/namespaces/default/workflows/swf-conditional-execution-pipeline-7-2159747346',\n",
       "     'startedAt': '2019-09-30T03:30:58Z',\n",
       "     'uid': 'e0f7fd71-85af-4dfe-b798-c26dcf332e70'},\n",
       "    {'createdAt': '2019-09-30T03:30:48Z',\n",
       "     'finishedAt': '2019-09-30T03:31:17Z',\n",
       "     'index': 6,\n",
       "     'name': 'swf-conditional-execution-pipeline-6-2176524965',\n",
       "     'namespace': 'default',\n",
       "     'phase': 'Succeeded',\n",
       "     'scheduledAt': '2019-09-29T00:06:00Z',\n",
       "     'selfLink': '/apis/argoproj.io/v1alpha1/namespaces/default/workflows/swf-conditional-execution-pipeline-6-2176524965',\n",
       "     'startedAt': '2019-09-30T03:30:48Z',\n",
       "     'uid': '04da3540-cdfe-4672-963e-c958fe333f44'},\n",
       "    {'createdAt': '2019-09-30T03:30:38Z',\n",
       "     'finishedAt': '2019-09-30T03:31:12Z',\n",
       "     'index': 5,\n",
       "     'name': 'swf-conditional-execution-pipeline-5-2126192108',\n",
       "     'namespace': 'default',\n",
       "     'phase': 'Succeeded',\n",
       "     'scheduledAt': '2019-09-29T00:05:00Z',\n",
       "     'selfLink': '/apis/argoproj.io/v1alpha1/namespaces/default/workflows/swf-conditional-execution-pipeline-5-2126192108',\n",
       "     'startedAt': '2019-09-30T03:30:38Z',\n",
       "     'uid': '5331881e-773c-4bda-9267-301e2f1e329f'},\n",
       "    {'createdAt': '2019-09-30T03:30:28Z',\n",
       "     'finishedAt': '2019-09-30T03:30:57Z',\n",
       "     'index': 4,\n",
       "     'name': 'swf-conditional-execution-pipeline-4-2142969727',\n",
       "     'namespace': 'default',\n",
       "     'phase': 'Succeeded',\n",
       "     'scheduledAt': '2019-09-29T00:04:00Z',\n",
       "     'selfLink': '/apis/argoproj.io/v1alpha1/namespaces/default/workflows/swf-conditional-execution-pipeline-4-2142969727',\n",
       "     'startedAt': '2019-09-30T03:30:28Z',\n",
       "     'uid': '5b1275f0-02aa-4fe3-af28-f3f46afc278c'},\n",
       "    {'createdAt': '2019-09-30T03:30:18Z',\n",
       "     'finishedAt': '2019-09-30T03:30:52Z',\n",
       "     'index': 3,\n",
       "     'name': 'swf-conditional-execution-pipeline-3-2092636870',\n",
       "     'namespace': 'default',\n",
       "     'phase': 'Succeeded',\n",
       "     'scheduledAt': '2019-09-29T00:03:00Z',\n",
       "     'selfLink': '/apis/argoproj.io/v1alpha1/namespaces/default/workflows/swf-conditional-execution-pipeline-3-2092636870',\n",
       "     'startedAt': '2019-09-30T03:30:18Z',\n",
       "     'uid': 'beb4bea8-d517-4c12-bb35-8828961659fa'},\n",
       "    {'createdAt': '2019-09-30T03:30:08Z',\n",
       "     'finishedAt': '2019-09-30T03:30:42Z',\n",
       "     'index': 2,\n",
       "     'name': 'swf-conditional-execution-pipeline-2-2109414489',\n",
       "     'namespace': 'default',\n",
       "     'phase': 'Succeeded',\n",
       "     'scheduledAt': '2019-09-29T00:02:00Z',\n",
       "     'selfLink': '/apis/argoproj.io/v1alpha1/namespaces/default/workflows/swf-conditional-execution-pipeline-2-2109414489',\n",
       "     'startedAt': '2019-09-30T03:30:08Z',\n",
       "     'uid': '83e1ce2a-cb8a-4b28-91fb-6add695ee44a'},\n",
       "    {'createdAt': '2019-09-30T03:29:58Z',\n",
       "     'finishedAt': '2019-09-30T03:30:33Z',\n",
       "     'index': 1,\n",
       "     'name': 'swf-conditional-execution-pipeline-1-2059081632',\n",
       "     'namespace': 'default',\n",
       "     'phase': 'Succeeded',\n",
       "     'scheduledAt': '2019-09-29T00:01:00Z',\n",
       "     'selfLink': '/apis/argoproj.io/v1alpha1/namespaces/default/workflows/swf-conditional-execution-pipeline-1-2059081632',\n",
       "     'startedAt': '2019-09-30T03:29:58Z',\n",
       "     'uid': 'd521dbaa-1844-4e74-8551-88c407bfc88b'}]}}}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make any desired change to the ScheduledWorkflow body here:\n",
    "swf.patch(cron=\"0 0 * * * *\", start='2019-09-29', end='2019-09-30')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apiVersion': 'v1',\n",
       " 'details': {'group': 'kubeflow.org',\n",
       "  'kind': 'scheduledworkflows',\n",
       "  'name': 'swf-conditional-execution-pipeline',\n",
       "  'uid': 'c91da570-0a32-4101-885f-21404ea8375f'},\n",
       " 'kind': 'Status',\n",
       " 'metadata': {},\n",
       " 'status': 'Success'}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swf.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `coin.tar.gz`\n",
    "This example runs the same \"coin flip\" pipeline, but fetching it from Google Cloud Storage in a couple of ways, and exercising `ScheduledWorkflows`'s scheduling parameters more:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### via `gs`-scheme URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ as env\n",
    "env['GOOGLE_APPLICATION_CREDENTIALS'] = '/Users/ryan/.gcloud/kubeflow-232704@appspot.gserviceaccount.com.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need at least 1.17.0 to download a blob directly without storage.buckets.get access to its bucket\n",
    "!{python} -m pip install --upgrade -q google-cloud-storage==1.17.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'gs://ml-pipeline-playground/coin.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "swf = KfpSwf(url, cron=\"0 * * * * *\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apiVersion': 'kubeflow.org/v1beta1',\n",
       " 'kind': 'ScheduledWorkflow',\n",
       " 'metadata': {'creationTimestamp': '2019-09-30T04:01:19Z',\n",
       "  'generation': 1,\n",
       "  'name': 'swf-pipeline-flip-coin',\n",
       "  'namespace': 'default',\n",
       "  'resourceVersion': '293869',\n",
       "  'selfLink': '/apis/kubeflow.org/v1beta1/namespaces/default/scheduledworkflows/swf-pipeline-flip-coin',\n",
       "  'uid': '0d67ff01-147f-4a39-ae8d-0881ac3b34f1'},\n",
       " 'spec': {'description': 'ScheduledWorkflow (cron: 0 * * * * *): ',\n",
       "  'enabled': True,\n",
       "  'maxConcurrency': 10,\n",
       "  'maxHistory': 10,\n",
       "  'name': 'swf-pipeline-flip-coin',\n",
       "  'trigger': {'cronSchedule': {'cron': '0 * * * * *'}},\n",
       "  'workflow': {'parameters': [{'name': 'datetime',\n",
       "     'value': '[[ScheduledTime.20060102-15:04:05]]'},\n",
       "    {'name': 'pipeline_yaml',\n",
       "     'value': 'apiVersion: argoproj.io/v1alpha1\\nkind: Workflow\\nmetadata: {generateName: pipeline-flip-coin-}\\nspec:\\n  arguments:\\n    parameters: []\\n  entrypoint: pipeline-flip-coin\\n  serviceAccountName: pipeline-runner\\n  templates:\\n  - inputs:\\n      parameters:\\n      - {name: flip-output}\\n    name: condition-1\\n    steps:\\n    - - arguments:\\n          parameters:\\n          - {name: flip-output, value: \\'{{inputs.parameters.flip-output}}\\'}\\n        name: condition-1-child\\n        template: condition-1-child\\n        when: \\'{{inputs.parameters.flip-output}} == heads\\'\\n  - dag:\\n      tasks:\\n      - arguments:\\n          parameters:\\n          - {name: flip-again-output, value: \\'{{tasks.flip-again.outputs.parameters.flip-again-output}}\\'}\\n          - {name: flip-output, value: \\'{{inputs.parameters.flip-output}}\\'}\\n        dependencies: [flip-again]\\n        name: condition-2\\n        template: condition-2\\n      - arguments:\\n          parameters:\\n          - {name: flip-output, value: \\'{{inputs.parameters.flip-output}}\\'}\\n        name: flip-again\\n        template: flip-again\\n    inputs:\\n      parameters:\\n      - {name: flip-output}\\n    name: condition-1-child\\n  - inputs:\\n      parameters:\\n      - {name: flip-again-output}\\n      - {name: flip-output}\\n    name: condition-2\\n    steps:\\n    - - arguments:\\n          parameters:\\n          - {name: flip-again-output, value: \\'{{inputs.parameters.flip-again-output}}\\'}\\n          - {name: flip-output, value: \\'{{inputs.parameters.flip-output}}\\'}\\n        name: condition-2-child\\n        template: condition-2-child\\n        when: \\'{{inputs.parameters.flip-again-output}} == tails\\'\\n  - dag:\\n      tasks:\\n      - arguments:\\n          parameters:\\n          - {name: flip-again-output, value: \\'{{inputs.parameters.flip-again-output}}\\'}\\n          - {name: flip-output, value: \\'{{inputs.parameters.flip-output}}\\'}\\n        name: print1\\n        template: print1\\n    inputs:\\n      parameters:\\n      - {name: flip-again-output}\\n      - {name: flip-output}\\n    name: condition-2-child\\n  - inputs:\\n      parameters:\\n      - {name: flip-output}\\n    name: condition-3\\n    steps:\\n    - - arguments:\\n          parameters:\\n          - {name: flip-output, value: \\'{{inputs.parameters.flip-output}}\\'}\\n        name: condition-3-child\\n        template: condition-3-child\\n        when: \\'{{inputs.parameters.flip-output}} == tails\\'\\n  - dag:\\n      tasks:\\n      - arguments:\\n          parameters:\\n          - {name: flip-output, value: \\'{{inputs.parameters.flip-output}}\\'}\\n        name: print2\\n        template: print2\\n    inputs:\\n      parameters:\\n      - {name: flip-output}\\n    name: condition-3-child\\n  - container:\\n      args: [\\'python -c \"import random; result = \\'\\'heads\\'\\' if random.randint(0,1)\\n          == 0 else \\'\\'tails\\'\\'; print(result)\" | tee /tmp/output\\']\\n      command: [sh, -c]\\n      image: python:alpine3.6\\n    name: flip\\n    outputs:\\n      artifacts:\\n      - name: mlpipeline-ui-metadata\\n        path: /mlpipeline-ui-metadata.json\\n        s3:\\n          accessKeySecret: {key: accesskey, name: mlpipeline-minio-artifact}\\n          bucket: mlpipeline\\n          endpoint: minio-service.kubeflow:9000\\n          insecure: true\\n          key: runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-ui-metadata.tgz\\n          secretKeySecret: {key: secretkey, name: mlpipeline-minio-artifact}\\n      - name: mlpipeline-metrics\\n        path: /mlpipeline-metrics.json\\n        s3:\\n          accessKeySecret: {key: accesskey, name: mlpipeline-minio-artifact}\\n          bucket: mlpipeline\\n          endpoint: minio-service.kubeflow:9000\\n          insecure: true\\n          key: runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-metrics.tgz\\n          secretKeySecret: {key: secretkey, name: mlpipeline-minio-artifact}\\n      parameters:\\n      - name: flip-output\\n        valueFrom: {path: /tmp/output}\\n  - container:\\n      args: [\\'python -c \"import random; result = \\'\\'heads\\'\\' if random.randint(0,1)\\n          == 0 else \\'\\'tails\\'\\'; print(result)\" | tee /tmp/output\\']\\n      command: [sh, -c]\\n      image: python:alpine3.6\\n    name: flip-again\\n    outputs:\\n      artifacts:\\n      - name: mlpipeline-ui-metadata\\n        path: /mlpipeline-ui-metadata.json\\n        s3:\\n          accessKeySecret: {key: accesskey, name: mlpipeline-minio-artifact}\\n          bucket: mlpipeline\\n          endpoint: minio-service.kubeflow:9000\\n          insecure: true\\n          key: runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-ui-metadata.tgz\\n          secretKeySecret: {key: secretkey, name: mlpipeline-minio-artifact}\\n      - name: mlpipeline-metrics\\n        path: /mlpipeline-metrics.json\\n        s3:\\n          accessKeySecret: {key: accesskey, name: mlpipeline-minio-artifact}\\n          bucket: mlpipeline\\n          endpoint: minio-service.kubeflow:9000\\n          insecure: true\\n          key: runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-metrics.tgz\\n          secretKeySecret: {key: secretkey, name: mlpipeline-minio-artifact}\\n      parameters:\\n      - name: flip-again-output\\n        valueFrom: {path: /tmp/output}\\n  - dag:\\n      tasks:\\n      - arguments:\\n          parameters:\\n          - {name: flip-output, value: \\'{{tasks.flip.outputs.parameters.flip-output}}\\'}\\n        dependencies: [flip]\\n        name: condition-1\\n        template: condition-1\\n      - arguments:\\n          parameters:\\n          - {name: flip-output, value: \\'{{tasks.flip.outputs.parameters.flip-output}}\\'}\\n        dependencies: [flip]\\n        name: condition-3\\n        template: condition-3\\n      - {name: flip, template: flip}\\n    name: pipeline-flip-coin\\n  - container:\\n      command: [echo, \\'\"it was tail\"\\']\\n      image: alpine:3.6\\n    name: print1\\n    outputs:\\n      artifacts:\\n      - name: mlpipeline-ui-metadata\\n        path: /mlpipeline-ui-metadata.json\\n        s3:\\n          accessKeySecret: {key: accesskey, name: mlpipeline-minio-artifact}\\n          bucket: mlpipeline\\n          endpoint: minio-service.kubeflow:9000\\n          insecure: true\\n          key: runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-ui-metadata.tgz\\n          secretKeySecret: {key: secretkey, name: mlpipeline-minio-artifact}\\n      - name: mlpipeline-metrics\\n        path: /mlpipeline-metrics.json\\n        s3:\\n          accessKeySecret: {key: accesskey, name: mlpipeline-minio-artifact}\\n          bucket: mlpipeline\\n          endpoint: minio-service.kubeflow:9000\\n          insecure: true\\n          key: runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-metrics.tgz\\n          secretKeySecret: {key: secretkey, name: mlpipeline-minio-artifact}\\n  - container:\\n      command: [echo, \\'\"it was tail\"\\']\\n      image: alpine:3.6\\n    name: print2\\n    outputs:\\n      artifacts:\\n      - name: mlpipeline-ui-metadata\\n        path: /mlpipeline-ui-metadata.json\\n        s3:\\n          accessKeySecret: {key: accesskey, name: mlpipeline-minio-artifact}\\n          bucket: mlpipeline\\n          endpoint: minio-service.kubeflow:9000\\n          insecure: true\\n          key: runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-ui-metadata.tgz\\n          secretKeySecret: {key: secretkey, name: mlpipeline-minio-artifact}\\n      - name: mlpipeline-metrics\\n        path: /mlpipeline-metrics.json\\n        s3:\\n          accessKeySecret: {key: accesskey, name: mlpipeline-minio-artifact}\\n          bucket: mlpipeline\\n          endpoint: minio-service.kubeflow:9000\\n          insecure: true\\n          key: runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-metrics.tgz\\n          secretKeySecret: {key: secretkey, name: mlpipeline-minio-artifact}\\n'}],\n",
       "   'spec': {'arguments': {'parameters': [{'name': 'datetime'},\n",
       "      {'name': 'pipeline_yaml'}]},\n",
       "    'entrypoint': 'kfp',\n",
       "    'templates': [{'container': {'args': ['--datetime',\n",
       "        '{{inputs.parameters.datetime}}',\n",
       "        '--pipeline_yaml',\n",
       "        '{{inputs.parameters.pipeline_yaml}}',\n",
       "        '--name',\n",
       "        'pipeline-flip-coin'],\n",
       "       'command': ['python', 'swf_kfp_runner.py'],\n",
       "       'image': 'runsascoded/kfp:swf'},\n",
       "      'inputs': {'parameters': [{'name': 'datetime'},\n",
       "        {'name': 'pipeline_yaml'}]},\n",
       "      'name': 'kfp'}]}}}}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swf.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>createdAt</th>\n",
       "      <th>finishedAt</th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>namespace</th>\n",
       "      <th>phase</th>\n",
       "      <th>scheduledAt</th>\n",
       "      <th>selfLink</th>\n",
       "      <th>startedAt</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-09-30 04:04:28+00:00</td>\n",
       "      <td>2019-09-30 04:04:47+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>swf-pipeline-flip-coin-3-759420850</td>\n",
       "      <td>default</td>\n",
       "      <td>Succeeded</td>\n",
       "      <td>2019-09-30 04:04:00+00:00</td>\n",
       "      <td>/apis/argoproj.io/v1alpha1/namespaces/default/...</td>\n",
       "      <td>2019-09-30 04:04:28+00:00</td>\n",
       "      <td>003eb3e3-8ba1-4898-8f6b-9ab4a65f5651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-09-30 04:03:08+00:00</td>\n",
       "      <td>2019-09-30 04:03:42+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>swf-pipeline-flip-coin-2-776198469</td>\n",
       "      <td>default</td>\n",
       "      <td>Succeeded</td>\n",
       "      <td>2019-09-30 04:03:00+00:00</td>\n",
       "      <td>/apis/argoproj.io/v1alpha1/namespaces/default/...</td>\n",
       "      <td>2019-09-30 04:03:08+00:00</td>\n",
       "      <td>0fdc7e2c-1d92-4181-b97a-81fcfbb0d0ee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-09-30 04:02:28+00:00</td>\n",
       "      <td>2019-09-30 04:03:11+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>swf-pipeline-flip-coin-1-725865612</td>\n",
       "      <td>default</td>\n",
       "      <td>Succeeded</td>\n",
       "      <td>2019-09-30 04:02:00+00:00</td>\n",
       "      <td>/apis/argoproj.io/v1alpha1/namespaces/default/...</td>\n",
       "      <td>2019-09-30 04:02:28+00:00</td>\n",
       "      <td>64bad254-06fb-467f-a56e-a67011272c82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  createdAt                finishedAt  index  \\\n",
       "0 2019-09-30 04:04:28+00:00 2019-09-30 04:04:47+00:00      3   \n",
       "1 2019-09-30 04:03:08+00:00 2019-09-30 04:03:42+00:00      2   \n",
       "2 2019-09-30 04:02:28+00:00 2019-09-30 04:03:11+00:00      1   \n",
       "\n",
       "                                 name namespace      phase  \\\n",
       "0  swf-pipeline-flip-coin-3-759420850   default  Succeeded   \n",
       "1  swf-pipeline-flip-coin-2-776198469   default  Succeeded   \n",
       "2  swf-pipeline-flip-coin-1-725865612   default  Succeeded   \n",
       "\n",
       "                scheduledAt  \\\n",
       "0 2019-09-30 04:04:00+00:00   \n",
       "1 2019-09-30 04:03:00+00:00   \n",
       "2 2019-09-30 04:02:00+00:00   \n",
       "\n",
       "                                            selfLink  \\\n",
       "0  /apis/argoproj.io/v1alpha1/namespaces/default/...   \n",
       "1  /apis/argoproj.io/v1alpha1/namespaces/default/...   \n",
       "2  /apis/argoproj.io/v1alpha1/namespaces/default/...   \n",
       "\n",
       "                  startedAt                                   uid  \n",
       "0 2019-09-30 04:04:28+00:00  003eb3e3-8ba1-4898-8f6b-9ab4a65f5651  \n",
       "1 2019-09-30 04:03:08+00:00  0fdc7e2c-1d92-4181-b97a-81fcfbb0d0ee  \n",
       "2 2019-09-30 04:02:28+00:00  64bad254-06fb-467f-a56e-a67011272c82  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swf.completed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apiVersion': 'v1',\n",
       " 'details': {'group': 'kubeflow.org',\n",
       "  'kind': 'scheduledworkflows',\n",
       "  'name': 'swf-pipeline-flip-coin',\n",
       "  'uid': '0d67ff01-147f-4a39-ae8d-0881ac3b34f1'},\n",
       " 'kind': 'Status',\n",
       " 'metadata': {},\n",
       " 'status': 'Success'}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swf.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### via `storage.googleapis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http = 'https://storage.googleapis.com/ml-pipeline-playground/coin.tar.gz'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kf-pipelines-py3",
   "language": "python",
   "name": "kf-pipelines-py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
